{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#from icecream import ic \n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Env import CabDriver\n",
    "env=CabDriver()\n",
    "action_space, state_space, state = env.reset()\n",
    "action_size = len(env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 24, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 2.,  3.,  3.,  5.,  7.,  0.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 9.,  7.,  9.,  7.,  8.,  5.,  6.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 4.,  7.,  6.,  4.,  3.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.],\n",
       "        [ 2.,  3.,  6.,  2.,  7.,  4.,  2.]],\n",
       "\n",
       "       [[ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 2.,  6.,  5.,  3.,  3.,  7.,  7.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 6.,  6.,  6.,  6.,  5.,  7.,  6.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 2.,  3.,  1.,  2.,  3.,  4.,  3.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.],\n",
       "        [ 6.,  2.,  8.,  5.,  4.,  5.,  5.]],\n",
       "\n",
       "       [[10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [10.,  6.,  8.,  5.,  7.,  4.,  6.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 3.,  3.,  8.,  6.,  1.,  6.,  3.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 2.,  1.,  2.,  5.,  3.,  4.,  0.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.],\n",
       "        [ 0.,  1.,  2.,  3.,  1.,  3.,  3.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 1.,  1.,  3.,  2.,  0.,  0.,  3.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 3.,  1.,  1.,  0.,  4.,  0.,  1.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.],\n",
       "        [ 6.,  4.,  7.,  6.,  3.,  1.,  8.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[2][1][12][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.poisson(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01  \n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay = -0.005 \n",
    "        self.epsilon_min = 0.000001\n",
    "        self.epsilon = 1\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.states_tracked=[]\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "                \n",
    "        model.add(Dense(50, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        # the output layer: output is of size num_actions\n",
    "        \n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state, act_idx):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment  \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # in case of cartpole this will randomly choose an action between 0 and 1\n",
    "            return random.choice(act_idx)\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = np.array(env.state_encod_arch1(state)).reshape(1,36)\n",
    "            q_value = self.model.predict(state)\n",
    "            # check for q values whose requests are possible on given day and time\n",
    "            avail_q=[q_value[0][k] for k in act_idx]\n",
    "            return act_idx[np.argmax(avail_q)] \n",
    "        \n",
    "    def append_sample(self, state, action, reward, next_state):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "        \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            #[(s,a,r,s'),(s,a,r,s') .... ]\n",
    "            update_output = np.zeros((self.batch_size,self.state_size))# write here\n",
    "            update_input = np.zeros((self.batch_size,self.state_size))# write here\n",
    "            actions, rewards = [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1.  Update your 'update_output' and 'update_input' batch\n",
    "                update_input[i] = env.state_encod_arch1(state)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "\n",
    "            q_vals = self.model.predict(update_output) ## (batchsize,len(action_space))\n",
    "            target = self.model.predict(update_input)\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                target[i][actions[i]] = rewards[i]+self.discount_factor*max(q_vals[i])\n",
    "            # 4. Fit your model and track the loss values\n",
    "\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0 )\n",
    "            \n",
    "    def save_tracking_states(self):\n",
    "        \n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "        \n",
    "    def save_test_states(self):\n",
    "        \n",
    "        # Use the model to predict the q_value of the state we are tacking.\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        \n",
    "        # Grab the q_value of the action index that we are tracking.\n",
    "        self.states_test.append(q_value[0][2])\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "        \n",
    "    def save_pbj(self, name):\n",
    "        with open(name + '.pkl', 'wb') as file:  \n",
    "            pickle.dump(self.model, file,pickle.HIGHEST_PROTOCOL)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Episodes = 5000\n",
    "episode_time = 24*30\n",
    "episode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "state_size = 36 # m + t + d value\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "rewards_per_episode, episodes = [], []\n",
    "reward_initial_stat=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward -77.0, memory_length 135, epsilon 0.9999 total_time 721.0\n",
      "Saving Model 0\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1, reward 171.0, memory_length 301, epsilon 0.9949129779447631 total_time 722.0\n",
      "episode 2, reward -73.0, memory_length 437, epsilon 0.9899508287657932 total_time 726.0\n",
      "episode 3, reward -67.0, memory_length 570, epsilon 0.9850134284091023 total_time 721.0\n",
      "episode 4, reward -167.0, memory_length 702, epsilon 0.9801006534394245 total_time 734.0\n",
      "episode 5, reward -43.0, memory_length 834, epsilon 0.9752123810371298 total_time 724.0\n",
      "episode 6, reward 59.0, memory_length 960, epsilon 0.9703484889951534 total_time 728.0\n",
      "episode 7, reward -88.0, memory_length 1087, epsilon 0.9655088557159407 total_time 731.0\n",
      "episode 8, reward -27.0, memory_length 1222, epsilon 0.960693360208408 total_time 721.0\n",
      "episode 9, reward -32.0, memory_length 1355, epsilon 0.9559018820849167 total_time 725.0\n",
      "episode 10, reward -245.0, memory_length 1475, epsilon 0.951134301558264 total_time 727.0\n",
      "Saving Model 10\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 11, reward -80.0, memory_length 1621, epsilon 0.9463904994386885 total_time 723.0\n",
      "episode 12, reward -366.0, memory_length 1743, epsilon 0.9416703571308903 total_time 728.0\n",
      "episode 13, reward -81.0, memory_length 1860, epsilon 0.9369737566310657 total_time 721.0\n",
      "episode 14, reward -53.0, memory_length 1995, epsilon 0.9323005805239577 total_time 728.0\n",
      "episode 15, reward -448.0, memory_length 2000, epsilon 0.92765071197992 total_time 725.0\n",
      "episode 16, reward -124.0, memory_length 2000, epsilon 0.9230240347519971 total_time 722.0\n",
      "episode 17, reward -279.0, memory_length 2000, epsilon 0.9184204331730172 total_time 734.0\n",
      "episode 18, reward -189.0, memory_length 2000, epsilon 0.9138397921527011 total_time 723.0\n",
      "episode 19, reward -128.0, memory_length 2000, epsilon 0.9092819971747846 total_time 730.0\n",
      "episode 20, reward -97.0, memory_length 2000, epsilon 0.904746934294156 total_time 729.0\n",
      "Saving Model 20\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 21, reward -367.0, memory_length 2000, epsilon 0.900234490134007 total_time 727.0\n",
      "episode 22, reward -173.0, memory_length 2000, epsilon 0.8957445518829986 total_time 722.0\n",
      "episode 23, reward -384.0, memory_length 2000, epsilon 0.8912770072924406 total_time 731.0\n",
      "episode 24, reward 200.0, memory_length 2000, epsilon 0.8868317446734858 total_time 723.0\n",
      "episode 25, reward 44.0, memory_length 2000, epsilon 0.882408652894337 total_time 723.0\n",
      "episode 26, reward 283.0, memory_length 2000, epsilon 0.8780076213774692 total_time 724.0\n",
      "episode 27, reward 315.0, memory_length 2000, epsilon 0.8736285400968656 total_time 721.0\n",
      "episode 28, reward -201.0, memory_length 2000, epsilon 0.8692712995752659 total_time 721.0\n",
      "episode 29, reward -187.0, memory_length 2000, epsilon 0.8649357908814302 total_time 725.0\n",
      "episode 30, reward -18.0, memory_length 2000, epsilon 0.8606219056274154 total_time 727.0\n",
      "Saving Model 30\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 31, reward 17.0, memory_length 2000, epsilon 0.8563295359658651 total_time 730.0\n",
      "episode 32, reward 147.0, memory_length 2000, epsilon 0.8520585745873147 total_time 726.0\n",
      "episode 33, reward -303.0, memory_length 2000, epsilon 0.8478089147175071 total_time 728.0\n",
      "episode 34, reward -201.0, memory_length 2000, epsilon 0.843580450114724 total_time 721.0\n",
      "episode 35, reward 316.0, memory_length 2000, epsilon 0.8393730750671304 total_time 725.0\n",
      "episode 36, reward 77.0, memory_length 2000, epsilon 0.8351866843901309 total_time 723.0\n",
      "episode 37, reward 62.0, memory_length 2000, epsilon 0.8310211734237405 total_time 726.0\n",
      "episode 38, reward -124.0, memory_length 2000, epsilon 0.8268764380299679 total_time 727.0\n",
      "episode 39, reward 23.0, memory_length 2000, epsilon 0.8227523745902128 total_time 724.0\n",
      "episode 40, reward 351.0, memory_length 2000, epsilon 0.818648880002674 total_time 727.0\n",
      "Saving Model 40\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 41, reward 68.0, memory_length 2000, epsilon 0.8145658516797734 total_time 721.0\n",
      "episode 42, reward 78.0, memory_length 2000, epsilon 0.81050318754559 total_time 725.0\n",
      "episode 43, reward -72.0, memory_length 2000, epsilon 0.8064607860333092 total_time 728.0\n",
      "episode 44, reward -94.0, memory_length 2000, epsilon 0.8024385460826823 total_time 724.0\n",
      "episode 45, reward -200.0, memory_length 2000, epsilon 0.7984363671375011 total_time 733.0\n",
      "episode 46, reward -122.0, memory_length 2000, epsilon 0.7944541491430838 total_time 723.0\n",
      "episode 47, reward 127.0, memory_length 2000, epsilon 0.7904917925437727 total_time 722.0\n",
      "episode 48, reward 157.0, memory_length 2000, epsilon 0.7865491982804468 total_time 734.0\n",
      "episode 49, reward 123.0, memory_length 2000, epsilon 0.782626267788044 total_time 725.0\n",
      "episode 50, reward -13.0, memory_length 2000, epsilon 0.7787229029930978 total_time 721.0\n",
      "Saving Model 50\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 51, reward 256.0, memory_length 2000, epsilon 0.7748390063112849 total_time 732.0\n",
      "episode 52, reward 309.0, memory_length 2000, epsilon 0.7709744806449859 total_time 722.0\n",
      "episode 53, reward -48.0, memory_length 2000, epsilon 0.7671292293808581 total_time 721.0\n",
      "episode 54, reward 64.0, memory_length 2000, epsilon 0.7633031563874195 total_time 722.0\n",
      "episode 55, reward -350.0, memory_length 2000, epsilon 0.759496166012646 total_time 721.0\n",
      "episode 56, reward -107.0, memory_length 2000, epsilon 0.75570816308158 total_time 722.0\n",
      "episode 57, reward -232.0, memory_length 2000, epsilon 0.7519390528939507 total_time 723.0\n",
      "episode 58, reward 270.0, memory_length 2000, epsilon 0.7481887412218075 total_time 727.0\n",
      "episode 59, reward 15.0, memory_length 2000, epsilon 0.7444571343071629 total_time 724.0\n",
      "episode 60, reward 158.0, memory_length 2000, epsilon 0.7407441388596497 total_time 733.0\n",
      "Saving Model 60\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 61, reward 162.0, memory_length 2000, epsilon 0.7370496620541886 total_time 722.0\n",
      "episode 62, reward 10.0, memory_length 2000, epsilon 0.7333736115286669 total_time 724.0\n",
      "episode 63, reward -297.0, memory_length 2000, epsilon 0.72971589538163 total_time 728.0\n",
      "episode 64, reward -165.0, memory_length 2000, epsilon 0.7260764221699836 total_time 723.0\n",
      "episode 65, reward 81.0, memory_length 2000, epsilon 0.7224551009067081 total_time 725.0\n",
      "episode 66, reward 176.0, memory_length 2000, epsilon 0.718851841058583 total_time 730.0\n",
      "episode 67, reward 13.0, memory_length 2000, epsilon 0.7152665525439247 total_time 724.0\n",
      "episode 68, reward 69.0, memory_length 2000, epsilon 0.7116991457303334 total_time 732.0\n",
      "episode 69, reward -106.0, memory_length 2000, epsilon 0.7081495314324532 total_time 727.0\n",
      "episode 70, reward 237.0, memory_length 2000, epsilon 0.7046176209097416 total_time 721.0\n",
      "Saving Model 70\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 71, reward -38.0, memory_length 2000, epsilon 0.7011033258642516 total_time 725.0\n",
      "episode 72, reward 181.0, memory_length 2000, epsilon 0.6976065584384239 total_time 723.0\n",
      "episode 73, reward 161.0, memory_length 2000, epsilon 0.6941272312128911 total_time 727.0\n",
      "episode 74, reward 110.0, memory_length 2000, epsilon 0.690665257204291 total_time 727.0\n",
      "episode 75, reward 98.0, memory_length 2000, epsilon 0.6872205498630931 total_time 727.0\n",
      "episode 76, reward 91.0, memory_length 2000, epsilon 0.6837930230714346 total_time 721.0\n",
      "episode 77, reward 644.0, memory_length 2000, epsilon 0.6803825911409672 total_time 728.0\n",
      "episode 78, reward 310.0, memory_length 2000, epsilon 0.6769891688107148 total_time 721.0\n",
      "episode 79, reward 68.0, memory_length 2000, epsilon 0.6736126712449427 total_time 726.0\n",
      "episode 80, reward 382.0, memory_length 2000, epsilon 0.6702530140310358 total_time 725.0\n",
      "Saving Model 80\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 81, reward 62.0, memory_length 2000, epsilon 0.6669101131773886 total_time 732.0\n",
      "episode 82, reward -101.0, memory_length 2000, epsilon 0.6635838851113057 total_time 727.0\n",
      "episode 83, reward -190.0, memory_length 2000, epsilon 0.6602742466769124 total_time 729.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 84, reward 240.0, memory_length 2000, epsilon 0.6569811151330752 total_time 729.0\n",
      "episode 85, reward 137.0, memory_length 2000, epsilon 0.6537044081513343 total_time 725.0\n",
      "episode 86, reward 340.0, memory_length 2000, epsilon 0.6504440438138442 total_time 728.0\n",
      "episode 87, reward 3.0, memory_length 2000, epsilon 0.6471999406113269 total_time 730.0\n",
      "episode 88, reward 391.0, memory_length 2000, epsilon 0.643972017441033 total_time 725.0\n",
      "episode 89, reward 24.0, memory_length 2000, epsilon 0.6407601936047155 total_time 722.0\n",
      "episode 90, reward 14.0, memory_length 2000, epsilon 0.6375643888066111 total_time 724.0\n",
      "Saving Model 90\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 91, reward 174.0, memory_length 2000, epsilon 0.6343845231514335 total_time 732.0\n",
      "episode 92, reward 378.0, memory_length 2000, epsilon 0.6312205171423753 total_time 724.0\n",
      "episode 93, reward 26.0, memory_length 2000, epsilon 0.6280722916791218 total_time 729.0\n",
      "episode 94, reward -44.0, memory_length 2000, epsilon 0.6249397680558725 total_time 724.0\n",
      "episode 95, reward 161.0, memory_length 2000, epsilon 0.6218228679593735 total_time 721.0\n",
      "episode 96, reward 42.0, memory_length 2000, epsilon 0.6187215134669602 total_time 726.0\n",
      "episode 97, reward 99.0, memory_length 2000, epsilon 0.6156356270446087 total_time 723.0\n",
      "episode 98, reward 389.0, memory_length 2000, epsilon 0.6125651315449977 total_time 724.0\n",
      "episode 99, reward 29.0, memory_length 2000, epsilon 0.6095099502055796 total_time 729.0\n",
      "episode 100, reward 466.0, memory_length 2000, epsilon 0.6064700066466622 total_time 721.0\n",
      "Saving Model 100\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 101, reward 11.0, memory_length 2000, epsilon 0.6034452248694978 total_time 725.0\n",
      "episode 102, reward 348.0, memory_length 2000, epsilon 0.6004355292543847 total_time 725.0\n",
      "episode 103, reward 14.0, memory_length 2000, epsilon 0.5974408445587757 total_time 721.0\n",
      "episode 104, reward 325.0, memory_length 2000, epsilon 0.5944610959153974 total_time 729.0\n",
      "episode 105, reward 76.0, memory_length 2000, epsilon 0.5914962088303785 total_time 726.0\n",
      "episode 106, reward 82.0, memory_length 2000, epsilon 0.5885461091813874 total_time 726.0\n",
      "episode 107, reward 270.0, memory_length 2000, epsilon 0.5856107232157792 total_time 729.0\n",
      "episode 108, reward 212.0, memory_length 2000, epsilon 0.5826899775487523 total_time 724.0\n",
      "episode 109, reward 642.0, memory_length 2000, epsilon 0.5797837991615123 total_time 724.0\n",
      "episode 110, reward 288.0, memory_length 2000, epsilon 0.5768921153994486 total_time 727.0\n",
      "Saving Model 110\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 111, reward -113.0, memory_length 2000, epsilon 0.5740148539703163 total_time 722.0\n",
      "episode 112, reward 115.0, memory_length 2000, epsilon 0.57115194294243 total_time 722.0\n",
      "episode 113, reward 156.0, memory_length 2000, epsilon 0.5683033107428647 total_time 721.0\n",
      "episode 114, reward 492.0, memory_length 2000, epsilon 0.5654688861556671 total_time 722.0\n",
      "episode 115, reward 374.0, memory_length 2000, epsilon 0.562648598320075 total_time 728.0\n",
      "episode 116, reward 230.0, memory_length 2000, epsilon 0.5598423767287455 total_time 721.0\n",
      "episode 117, reward 240.0, memory_length 2000, epsilon 0.5570501512259927 total_time 728.0\n",
      "episode 118, reward 606.0, memory_length 2000, epsilon 0.5542718520060337 total_time 727.0\n",
      "episode 119, reward -46.0, memory_length 2000, epsilon 0.551507409611243 total_time 724.0\n",
      "episode 120, reward 280.0, memory_length 2000, epsilon 0.5487567549304171 total_time 726.0\n",
      "Saving Model 120\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 121, reward 62.0, memory_length 2000, epsilon 0.5460198191970455 total_time 722.0\n",
      "episode 122, reward 442.0, memory_length 2000, epsilon 0.5432965339875924 total_time 724.0\n",
      "episode 123, reward 478.0, memory_length 2000, epsilon 0.5405868312197857 total_time 721.0\n",
      "episode 124, reward 322.0, memory_length 2000, epsilon 0.5378906431509151 total_time 725.0\n",
      "episode 125, reward 214.0, memory_length 2000, epsilon 0.5352079023761384 total_time 723.0\n",
      "episode 126, reward 204.0, memory_length 2000, epsilon 0.5325385418267965 total_time 726.0\n",
      "episode 127, reward -3.0, memory_length 2000, epsilon 0.5298824947687368 total_time 722.0\n",
      "episode 128, reward 247.0, memory_length 2000, epsilon 0.5272396948006443 total_time 724.0\n",
      "episode 129, reward -136.0, memory_length 2000, epsilon 0.5246100758523823 total_time 723.0\n",
      "episode 130, reward 331.0, memory_length 2000, epsilon 0.52199357218334 total_time 721.0\n",
      "Saving Model 130\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 131, reward 609.0, memory_length 2000, epsilon 0.5193901183807895 total_time 722.0\n",
      "episode 132, reward 284.0, memory_length 2000, epsilon 0.51679964935825 total_time 723.0\n",
      "episode 133, reward -123.0, memory_length 2000, epsilon 0.5142221003538613 total_time 724.0\n",
      "episode 134, reward 359.0, memory_length 2000, epsilon 0.5116574069287638 total_time 721.0\n",
      "episode 135, reward 477.0, memory_length 2000, epsilon 0.5091055049654885 total_time 723.0\n",
      "episode 136, reward -49.0, memory_length 2000, epsilon 0.506566330666353 total_time 732.0\n",
      "episode 137, reward 98.0, memory_length 2000, epsilon 0.504039820551868 total_time 724.0\n",
      "episode 138, reward 244.0, memory_length 2000, epsilon 0.5015259114591488 total_time 732.0\n",
      "episode 139, reward 17.0, memory_length 2000, epsilon 0.49902454054033746 total_time 723.0\n",
      "episode 140, reward 163.0, memory_length 2000, epsilon 0.49653564526103033 total_time 721.0\n",
      "Saving Model 140\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 141, reward 43.0, memory_length 2000, epsilon 0.4940591633987161 total_time 727.0\n",
      "episode 142, reward 169.0, memory_length 2000, epsilon 0.491595033041219 total_time 722.0\n",
      "episode 143, reward 28.0, memory_length 2000, epsilon 0.48914319258515193 total_time 725.0\n",
      "episode 144, reward -15.0, memory_length 2000, epsilon 0.4867035807343757 total_time 725.0\n",
      "episode 145, reward 158.0, memory_length 2000, epsilon 0.48427613649846696 total_time 722.0\n",
      "episode 146, reward 182.0, memory_length 2000, epsilon 0.4818607991911934 total_time 722.0\n",
      "episode 147, reward 276.0, memory_length 2000, epsilon 0.47945750842899665 total_time 721.0\n",
      "episode 148, reward 394.0, memory_length 2000, epsilon 0.4770662041294823 total_time 721.0\n",
      "episode 149, reward 322.0, memory_length 2000, epsilon 0.4746868265099184 total_time 723.0\n",
      "episode 150, reward 509.0, memory_length 2000, epsilon 0.47231931608574057 total_time 721.0\n",
      "Saving Model 150\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 151, reward -52.0, memory_length 2000, epsilon 0.4699636136690649 total_time 723.0\n",
      "episode 152, reward 403.0, memory_length 2000, epsilon 0.46761966036720826 total_time 729.0\n",
      "episode 153, reward 239.0, memory_length 2000, epsilon 0.465287397581216 total_time 721.0\n",
      "episode 154, reward 357.0, memory_length 2000, epsilon 0.46296676700439693 total_time 724.0\n",
      "episode 155, reward 267.0, memory_length 2000, epsilon 0.4606577106208659 total_time 726.0\n",
      "episode 156, reward 437.0, memory_length 2000, epsilon 0.458360170704093 total_time 732.0\n",
      "episode 157, reward 408.0, memory_length 2000, epsilon 0.45607408981546066 total_time 722.0\n",
      "episode 158, reward -135.0, memory_length 2000, epsilon 0.4537994108028276 total_time 721.0\n",
      "episode 159, reward 160.0, memory_length 2000, epsilon 0.45153607679909996 total_time 728.0\n",
      "episode 160, reward 422.0, memory_length 2000, epsilon 0.44928403122080984 total_time 726.0\n",
      "Saving Model 160\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 161, reward 495.0, memory_length 2000, epsilon 0.4470432177667005 total_time 727.0\n",
      "episode 162, reward 235.0, memory_length 2000, epsilon 0.4448135804163188 total_time 733.0\n",
      "episode 163, reward 432.0, memory_length 2000, epsilon 0.44259506342861493 total_time 729.0\n",
      "episode 164, reward 349.0, memory_length 2000, epsilon 0.44038761134054866 total_time 730.0\n",
      "episode 165, reward 266.0, memory_length 2000, epsilon 0.4381911689657027 total_time 729.0\n",
      "episode 166, reward -40.0, memory_length 2000, epsilon 0.4360056813929034 total_time 723.0\n",
      "episode 167, reward 447.0, memory_length 2000, epsilon 0.4338310939848476 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 168, reward 257.0, memory_length 2000, epsilon 0.4316673523767368 total_time 727.0\n",
      "episode 169, reward 267.0, memory_length 2000, epsilon 0.42951440247491807 total_time 722.0\n",
      "episode 170, reward 220.0, memory_length 2000, epsilon 0.4273721904555318 total_time 727.0\n",
      "Saving Model 170\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 171, reward 405.0, memory_length 2000, epsilon 0.4252406627631659 total_time 721.0\n",
      "episode 172, reward 673.0, memory_length 2000, epsilon 0.42311976610951707 total_time 728.0\n",
      "episode 173, reward 244.0, memory_length 2000, epsilon 0.4210094474720585 total_time 726.0\n",
      "episode 174, reward 422.0, memory_length 2000, epsilon 0.41890965409271425 total_time 727.0\n",
      "episode 175, reward 528.0, memory_length 2000, epsilon 0.4168203334765405 total_time 723.0\n",
      "episode 176, reward 339.0, memory_length 2000, epsilon 0.41474143339041325 total_time 726.0\n",
      "episode 177, reward 257.0, memory_length 2000, epsilon 0.4126729018617218 total_time 722.0\n",
      "episode 178, reward 375.0, memory_length 2000, epsilon 0.4106146871770703 total_time 721.0\n",
      "episode 179, reward 618.0, memory_length 2000, epsilon 0.40856673788098435 total_time 724.0\n",
      "episode 180, reward 283.0, memory_length 2000, epsilon 0.40652900277462506 total_time 726.0\n",
      "Saving Model 180\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 181, reward 378.0, memory_length 2000, epsilon 0.4045014309145085 total_time 723.0\n",
      "episode 182, reward 754.0, memory_length 2000, epsilon 0.4024839716112326 total_time 726.0\n",
      "episode 183, reward 120.0, memory_length 2000, epsilon 0.4004765744282097 total_time 724.0\n",
      "episode 184, reward 137.0, memory_length 2000, epsilon 0.3984791891804057 total_time 721.0\n",
      "episode 185, reward 162.0, memory_length 2000, epsilon 0.3964917659330853 total_time 727.0\n",
      "episode 186, reward 591.0, memory_length 2000, epsilon 0.3945142550005639 total_time 725.0\n",
      "episode 187, reward 523.0, memory_length 2000, epsilon 0.39254660694496524 total_time 723.0\n",
      "episode 188, reward 523.0, memory_length 2000, epsilon 0.39058877257498525 total_time 728.0\n",
      "episode 189, reward 678.0, memory_length 2000, epsilon 0.3886407029446628 total_time 725.0\n",
      "episode 190, reward 418.0, memory_length 2000, epsilon 0.38670234935215575 total_time 725.0\n",
      "Saving Model 190\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 191, reward 182.0, memory_length 2000, epsilon 0.38477366333852325 total_time 723.0\n",
      "episode 192, reward 229.0, memory_length 2000, epsilon 0.38285459668651456 total_time 725.0\n",
      "episode 193, reward 366.0, memory_length 2000, epsilon 0.38094510141936333 total_time 725.0\n",
      "episode 194, reward 147.0, memory_length 2000, epsilon 0.3790451297995885 total_time 729.0\n",
      "episode 195, reward 357.0, memory_length 2000, epsilon 0.3771546343278006 total_time 726.0\n",
      "episode 196, reward 394.0, memory_length 2000, epsilon 0.37527356774151444 total_time 726.0\n",
      "episode 197, reward 242.0, memory_length 2000, epsilon 0.37340188301396726 total_time 724.0\n",
      "episode 198, reward 613.0, memory_length 2000, epsilon 0.3715395333529435 total_time 730.0\n",
      "episode 199, reward 384.0, memory_length 2000, epsilon 0.3696864721996046 total_time 722.0\n",
      "episode 200, reward 303.0, memory_length 2000, epsilon 0.3678426532273252 total_time 722.0\n",
      "Saving Model 200\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 201, reward 316.0, memory_length 2000, epsilon 0.3660080303405349 total_time 727.0\n",
      "episode 202, reward 386.0, memory_length 2000, epsilon 0.36418255767356617 total_time 723.0\n",
      "episode 203, reward 446.0, memory_length 2000, epsilon 0.362366189589507 total_time 728.0\n",
      "episode 204, reward 255.0, memory_length 2000, epsilon 0.360558880679061 total_time 726.0\n",
      "episode 205, reward -51.0, memory_length 2000, epsilon 0.358760585759411 total_time 732.0\n",
      "episode 206, reward 580.0, memory_length 2000, epsilon 0.3569712598730905 total_time 723.0\n",
      "episode 207, reward 216.0, memory_length 2000, epsilon 0.35519085828685903 total_time 723.0\n",
      "episode 208, reward 28.0, memory_length 2000, epsilon 0.35341933649058427 total_time 725.0\n",
      "episode 209, reward 290.0, memory_length 2000, epsilon 0.35165665019612913 total_time 721.0\n",
      "episode 210, reward -3.0, memory_length 2000, epsilon 0.3499027553362442 total_time 725.0\n",
      "Saving Model 210\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 211, reward 112.0, memory_length 2000, epsilon 0.34815760806346696 total_time 721.0\n",
      "episode 212, reward -112.0, memory_length 2000, epsilon 0.3464211647490244 total_time 727.0\n",
      "episode 213, reward 111.0, memory_length 2000, epsilon 0.3446933819817435 total_time 724.0\n",
      "episode 214, reward 299.0, memory_length 2000, epsilon 0.34297421656696475 total_time 721.0\n",
      "episode 215, reward -118.0, memory_length 2000, epsilon 0.34126362552546363 total_time 726.0\n",
      "episode 216, reward -235.0, memory_length 2000, epsilon 0.33956156609237464 total_time 721.0\n",
      "episode 217, reward 172.0, memory_length 2000, epsilon 0.3378679957161236 total_time 727.0\n",
      "episode 218, reward -224.0, memory_length 2000, epsilon 0.33618287205736264 total_time 724.0\n",
      "episode 219, reward -84.0, memory_length 2000, epsilon 0.33450615298791275 total_time 727.0\n",
      "episode 220, reward 45.0, memory_length 2000, epsilon 0.33283779658970974 total_time 724.0\n",
      "Saving Model 220\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 221, reward 29.0, memory_length 2000, epsilon 0.3311777611537568 total_time 726.0\n",
      "episode 222, reward -55.0, memory_length 2000, epsilon 0.32952600517908154 total_time 723.0\n",
      "episode 223, reward -155.0, memory_length 2000, epsilon 0.3278824873716986 total_time 730.0\n",
      "episode 224, reward -132.0, memory_length 2000, epsilon 0.32624716664357717 total_time 723.0\n",
      "episode 225, reward 108.0, memory_length 2000, epsilon 0.3246200021116139 total_time 721.0\n",
      "episode 226, reward 46.0, memory_length 2000, epsilon 0.32300095309661064 total_time 725.0\n",
      "episode 227, reward 163.0, memory_length 2000, epsilon 0.3213899791222579 total_time 728.0\n",
      "episode 228, reward 165.0, memory_length 2000, epsilon 0.3197870399141222 total_time 725.0\n",
      "episode 229, reward 22.0, memory_length 2000, epsilon 0.3181920953986401 total_time 722.0\n",
      "episode 230, reward -99.0, memory_length 2000, epsilon 0.31660510570211525 total_time 722.0\n",
      "Saving Model 230\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 231, reward -15.0, memory_length 2000, epsilon 0.315026031149723 total_time 721.0\n",
      "episode 232, reward -6.0, memory_length 2000, epsilon 0.3134548322645171 total_time 723.0\n",
      "episode 233, reward -143.0, memory_length 2000, epsilon 0.3118914697664435 total_time 728.0\n",
      "episode 234, reward 287.0, memory_length 2000, epsilon 0.3103359045713585 total_time 724.0\n",
      "episode 235, reward 375.0, memory_length 2000, epsilon 0.30878809779005106 total_time 733.0\n",
      "episode 236, reward 669.0, memory_length 2000, epsilon 0.30724801072727115 total_time 730.0\n",
      "episode 237, reward 341.0, memory_length 2000, epsilon 0.3057156048807619 total_time 728.0\n",
      "episode 238, reward 34.0, memory_length 2000, epsilon 0.3041908419402974 total_time 726.0\n",
      "episode 239, reward 492.0, memory_length 2000, epsilon 0.30267368378672466 total_time 728.0\n",
      "episode 240, reward 205.0, memory_length 2000, epsilon 0.3011640924910109 total_time 721.0\n",
      "Saving Model 240\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 241, reward 428.0, memory_length 2000, epsilon 0.299662030313295 total_time 724.0\n",
      "episode 242, reward 538.0, memory_length 2000, epsilon 0.2981674597019444 total_time 722.0\n",
      "episode 243, reward 662.0, memory_length 2000, epsilon 0.29668034329261583 total_time 728.0\n",
      "episode 244, reward 479.0, memory_length 2000, epsilon 0.2952006439073218 total_time 726.0\n",
      "episode 245, reward 565.0, memory_length 2000, epsilon 0.2937283245535004 total_time 722.0\n",
      "episode 246, reward 497.0, memory_length 2000, epsilon 0.2922633484230913 total_time 725.0\n",
      "episode 247, reward 730.0, memory_length 2000, epsilon 0.2908056788916148 total_time 724.0\n",
      "episode 248, reward 687.0, memory_length 2000, epsilon 0.2893552795172567 total_time 724.0\n",
      "episode 249, reward 519.0, memory_length 2000, epsilon 0.28791211403995715 total_time 722.0\n",
      "episode 250, reward 417.0, memory_length 2000, epsilon 0.28647614638050406 total_time 726.0\n",
      "Saving Model 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 251, reward 382.0, memory_length 2000, epsilon 0.2850473406396311 total_time 724.0\n",
      "episode 252, reward 517.0, memory_length 2000, epsilon 0.2836256610971204 total_time 728.0\n",
      "episode 253, reward 469.0, memory_length 2000, epsilon 0.28221107221090924 total_time 721.0\n",
      "episode 254, reward 446.0, memory_length 2000, epsilon 0.28080353861620194 total_time 722.0\n",
      "episode 255, reward 752.0, memory_length 2000, epsilon 0.27940302512458515 total_time 723.0\n",
      "episode 256, reward 596.0, memory_length 2000, epsilon 0.27800949672314884 total_time 729.0\n",
      "episode 257, reward 218.0, memory_length 2000, epsilon 0.2766229185736102 total_time 721.0\n",
      "episode 258, reward 699.0, memory_length 2000, epsilon 0.27524325601144334 total_time 724.0\n",
      "episode 259, reward 598.0, memory_length 2000, epsilon 0.27387047454501245 total_time 727.0\n",
      "episode 260, reward 392.0, memory_length 2000, epsilon 0.2725045398547092 total_time 721.0\n",
      "Saving Model 260\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 261, reward 706.0, memory_length 2000, epsilon 0.27114541779209533 total_time 723.0\n",
      "episode 262, reward 656.0, memory_length 2000, epsilon 0.26979307437904837 total_time 726.0\n",
      "episode 263, reward 543.0, memory_length 2000, epsilon 0.2684474758069127 total_time 727.0\n",
      "episode 264, reward 734.0, memory_length 2000, epsilon 0.26710858843565377 total_time 722.0\n",
      "episode 265, reward 436.0, memory_length 2000, epsilon 0.2657763787930177 total_time 731.0\n",
      "episode 266, reward 435.0, memory_length 2000, epsilon 0.264450813573694 total_time 726.0\n",
      "episode 267, reward 842.0, memory_length 2000, epsilon 0.2631318596384831 total_time 722.0\n",
      "episode 268, reward 758.0, memory_length 2000, epsilon 0.26181948401346794 total_time 722.0\n",
      "episode 269, reward 558.0, memory_length 2000, epsilon 0.2605136538891896 total_time 725.0\n",
      "episode 270, reward 455.0, memory_length 2000, epsilon 0.2592143366198269 total_time 724.0\n",
      "Saving Model 270\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 271, reward 604.0, memory_length 2000, epsilon 0.2579214997223805 total_time 721.0\n",
      "episode 272, reward 1131.0, memory_length 2000, epsilon 0.25663511087586055 total_time 723.0\n",
      "episode 273, reward 777.0, memory_length 2000, epsilon 0.25535513792047887 total_time 725.0\n",
      "episode 274, reward 590.0, memory_length 2000, epsilon 0.254081548856845 total_time 729.0\n",
      "episode 275, reward 622.0, memory_length 2000, epsilon 0.252814311845166 total_time 723.0\n",
      "episode 276, reward 969.0, memory_length 2000, epsilon 0.25155339520445047 total_time 730.0\n",
      "episode 277, reward 440.0, memory_length 2000, epsilon 0.25029876741171697 total_time 722.0\n",
      "episode 278, reward 743.0, memory_length 2000, epsilon 0.249050397101205 total_time 723.0\n",
      "episode 279, reward 863.0, memory_length 2000, epsilon 0.24780825306359203 total_time 726.0\n",
      "episode 280, reward 622.0, memory_length 2000, epsilon 0.2465723042452123 total_time 727.0\n",
      "Saving Model 280\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 281, reward 438.0, memory_length 2000, epsilon 0.24534251974728105 total_time 721.0\n",
      "episode 282, reward 472.0, memory_length 2000, epsilon 0.24411886882512177 total_time 726.0\n",
      "episode 283, reward 768.0, memory_length 2000, epsilon 0.24290132088739758 total_time 725.0\n",
      "episode 284, reward 746.0, memory_length 2000, epsilon 0.24168984549534675 total_time 722.0\n",
      "episode 285, reward 600.0, memory_length 2000, epsilon 0.24048441236202128 total_time 721.0\n",
      "episode 286, reward 850.0, memory_length 2000, epsilon 0.23928499135153017 total_time 725.0\n",
      "episode 287, reward 210.0, memory_length 2000, epsilon 0.23809155247828556 total_time 724.0\n",
      "episode 288, reward 455.0, memory_length 2000, epsilon 0.23690406590625354 total_time 723.0\n",
      "episode 289, reward 597.0, memory_length 2000, epsilon 0.23572250194820793 total_time 726.0\n",
      "episode 290, reward 726.0, memory_length 2000, epsilon 0.23454683106498828 total_time 734.0\n",
      "Saving Model 290\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 291, reward 727.0, memory_length 2000, epsilon 0.2333770238647612 total_time 728.0\n",
      "episode 292, reward 335.0, memory_length 2000, epsilon 0.23221305110228585 total_time 723.0\n",
      "episode 293, reward 600.0, memory_length 2000, epsilon 0.23105488367818244 total_time 724.0\n",
      "episode 294, reward 510.0, memory_length 2000, epsilon 0.22990249263820517 total_time 727.0\n",
      "episode 295, reward 120.0, memory_length 2000, epsilon 0.2287558491725179 total_time 732.0\n",
      "episode 296, reward 459.0, memory_length 2000, epsilon 0.22761492461497435 total_time 724.0\n",
      "episode 297, reward 413.0, memory_length 2000, epsilon 0.2264796904424011 total_time 724.0\n",
      "episode 298, reward 339.0, memory_length 2000, epsilon 0.2253501182738848 total_time 726.0\n",
      "episode 299, reward 597.0, memory_length 2000, epsilon 0.22422617987006227 total_time 723.0\n",
      "episode 300, reward 451.0, memory_length 2000, epsilon 0.22310784713241497 total_time 729.0\n",
      "Saving Model 300\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 301, reward 398.0, memory_length 2000, epsilon 0.22199509210256618 total_time 722.0\n",
      "episode 302, reward 606.0, memory_length 2000, epsilon 0.22088788696158226 total_time 722.0\n",
      "episode 303, reward 400.0, memory_length 2000, epsilon 0.2197862040292769 total_time 723.0\n",
      "episode 304, reward 495.0, memory_length 2000, epsilon 0.2186900157635195 total_time 723.0\n",
      "episode 305, reward 780.0, memory_length 2000, epsilon 0.2175992947595463 total_time 727.0\n",
      "episode 306, reward 789.0, memory_length 2000, epsilon 0.21651401374927548 total_time 726.0\n",
      "episode 307, reward 567.0, memory_length 2000, epsilon 0.21543414560062507 total_time 721.0\n",
      "episode 308, reward 573.0, memory_length 2000, epsilon 0.21435966331683526 total_time 730.0\n",
      "episode 309, reward 630.0, memory_length 2000, epsilon 0.21329054003579295 total_time 727.0\n",
      "episode 310, reward 793.0, memory_length 2000, epsilon 0.21222674902936037 total_time 726.0\n",
      "Saving Model 310\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 311, reward 540.0, memory_length 2000, epsilon 0.21116826370270708 total_time 721.0\n",
      "episode 312, reward 244.0, memory_length 2000, epsilon 0.21011505759364466 total_time 722.0\n",
      "episode 313, reward 917.0, memory_length 2000, epsilon 0.2090671043719656 total_time 722.0\n",
      "episode 314, reward 605.0, memory_length 2000, epsilon 0.20802437783878477 total_time 724.0\n",
      "episode 315, reward 565.0, memory_length 2000, epsilon 0.20698685192588454 total_time 721.0\n",
      "episode 316, reward 633.0, memory_length 2000, epsilon 0.20595450069506296 total_time 724.0\n",
      "episode 317, reward 899.0, memory_length 2000, epsilon 0.20492729833748563 total_time 721.0\n",
      "episode 318, reward 851.0, memory_length 2000, epsilon 0.20390521917304 total_time 727.0\n",
      "episode 319, reward 780.0, memory_length 2000, epsilon 0.20288823764969383 total_time 722.0\n",
      "episode 320, reward 581.0, memory_length 2000, epsilon 0.20187632834285593 total_time 729.0\n",
      "Saving Model 320\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 321, reward 734.0, memory_length 2000, epsilon 0.20086946595474106 total_time 727.0\n",
      "episode 322, reward 904.0, memory_length 2000, epsilon 0.19986762531373697 total_time 726.0\n",
      "episode 323, reward 1011.0, memory_length 2000, epsilon 0.19887078137377553 total_time 723.0\n",
      "episode 324, reward 604.0, memory_length 2000, epsilon 0.1978789092137063 total_time 725.0\n",
      "episode 325, reward 610.0, memory_length 2000, epsilon 0.19689198403667363 total_time 726.0\n",
      "episode 326, reward 1088.0, memory_length 2000, epsilon 0.19590998116949665 total_time 735.0\n",
      "episode 327, reward 1014.0, memory_length 2000, epsilon 0.1949328760620526 total_time 724.0\n",
      "episode 328, reward 751.0, memory_length 2000, epsilon 0.1939606442866628 total_time 721.0\n",
      "episode 329, reward 1019.0, memory_length 2000, epsilon 0.19299326153748234 total_time 723.0\n",
      "episode 330, reward 572.0, memory_length 2000, epsilon 0.192030703629892 total_time 726.0\n",
      "Saving Model 330\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 331, reward 869.0, memory_length 2000, epsilon 0.1910729464998941 total_time 723.0\n",
      "episode 332, reward 600.0, memory_length 2000, epsilon 0.19011996620351035 total_time 722.0\n",
      "episode 333, reward 1016.0, memory_length 2000, epsilon 0.18917173891618383 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 334, reward 851.0, memory_length 2000, epsilon 0.18822824093218293 total_time 724.0\n",
      "episode 335, reward 517.0, memory_length 2000, epsilon 0.18728944866400882 total_time 728.0\n",
      "episode 336, reward 715.0, memory_length 2000, epsilon 0.18635533864180603 total_time 735.0\n",
      "episode 337, reward 246.0, memory_length 2000, epsilon 0.18542588751277528 total_time 725.0\n",
      "episode 338, reward 786.0, memory_length 2000, epsilon 0.18450107204058996 total_time 724.0\n",
      "episode 339, reward 891.0, memory_length 2000, epsilon 0.18358086910481508 total_time 724.0\n",
      "episode 340, reward 823.0, memory_length 2000, epsilon 0.1826652557003294 total_time 731.0\n",
      "Saving Model 340\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 341, reward 594.0, memory_length 2000, epsilon 0.18175420893674998 total_time 728.0\n",
      "episode 342, reward 697.0, memory_length 2000, epsilon 0.18084770603786038 total_time 728.0\n",
      "episode 343, reward 458.0, memory_length 2000, epsilon 0.17994572434104086 total_time 723.0\n",
      "episode 344, reward 795.0, memory_length 2000, epsilon 0.17904824129670208 total_time 727.0\n",
      "episode 345, reward 388.0, memory_length 2000, epsilon 0.17815523446772114 total_time 729.0\n",
      "episode 346, reward 575.0, memory_length 2000, epsilon 0.17726668152888084 total_time 728.0\n",
      "episode 347, reward 555.0, memory_length 2000, epsilon 0.17638256026631136 total_time 726.0\n",
      "episode 348, reward 610.0, memory_length 2000, epsilon 0.17550284857693516 total_time 727.0\n",
      "episode 349, reward 680.0, memory_length 2000, epsilon 0.17462752446791419 total_time 732.0\n",
      "episode 350, reward 828.0, memory_length 2000, epsilon 0.1737565660561001 total_time 727.0\n",
      "Saving Model 350\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 351, reward 710.0, memory_length 2000, epsilon 0.17288995156748718 total_time 724.0\n",
      "episode 352, reward 619.0, memory_length 2000, epsilon 0.17202765933666822 total_time 723.0\n",
      "episode 353, reward 447.0, memory_length 2000, epsilon 0.17116966780629242 total_time 723.0\n",
      "episode 354, reward 443.0, memory_length 2000, epsilon 0.1703159555265269 total_time 721.0\n",
      "episode 355, reward 719.0, memory_length 2000, epsilon 0.1694665011545201 total_time 722.0\n",
      "episode 356, reward 626.0, memory_length 2000, epsilon 0.16862128345386865 total_time 731.0\n",
      "episode 357, reward 405.0, memory_length 2000, epsilon 0.16778028129408584 total_time 728.0\n",
      "episode 358, reward 668.0, memory_length 2000, epsilon 0.166943473650074 total_time 725.0\n",
      "episode 359, reward 600.0, memory_length 2000, epsilon 0.1661108396015984 total_time 721.0\n",
      "episode 360, reward 305.0, memory_length 2000, epsilon 0.16528235833276436 total_time 725.0\n",
      "Saving Model 360\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 361, reward 724.0, memory_length 2000, epsilon 0.1644580091314972 total_time 723.0\n",
      "episode 362, reward 508.0, memory_length 2000, epsilon 0.16363777138902377 total_time 728.0\n",
      "episode 363, reward 895.0, memory_length 2000, epsilon 0.16282162459935795 total_time 723.0\n",
      "episode 364, reward 570.0, memory_length 2000, epsilon 0.16200954835878736 total_time 726.0\n",
      "episode 365, reward 557.0, memory_length 2000, epsilon 0.16120152236536378 total_time 725.0\n",
      "episode 366, reward 1332.0, memory_length 2000, epsilon 0.16039752641839522 total_time 725.0\n",
      "episode 367, reward 528.0, memory_length 2000, epsilon 0.15959754041794122 total_time 729.0\n",
      "episode 368, reward 1016.0, memory_length 2000, epsilon 0.15880154436431 total_time 721.0\n",
      "episode 369, reward 787.0, memory_length 2000, epsilon 0.15800951835755883 total_time 721.0\n",
      "episode 370, reward 827.0, memory_length 2000, epsilon 0.15722144259699625 total_time 723.0\n",
      "Saving Model 370\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 371, reward 913.0, memory_length 2000, epsilon 0.15643729738068726 total_time 728.0\n",
      "episode 372, reward 1316.0, memory_length 2000, epsilon 0.1556570631049605 total_time 728.0\n",
      "episode 373, reward 1018.0, memory_length 2000, epsilon 0.15488072026391855 total_time 730.0\n",
      "episode 374, reward 828.0, memory_length 2000, epsilon 0.15410824944894988 total_time 728.0\n",
      "episode 375, reward 1085.0, memory_length 2000, epsilon 0.15333963134824397 total_time 722.0\n",
      "episode 376, reward 955.0, memory_length 2000, epsilon 0.15257484674630817 total_time 721.0\n",
      "episode 377, reward 932.0, memory_length 2000, epsilon 0.15181387652348766 total_time 724.0\n",
      "episode 378, reward 710.0, memory_length 2000, epsilon 0.1510567016554872 total_time 721.0\n",
      "episode 379, reward 605.0, memory_length 2000, epsilon 0.1503033032128957 total_time 727.0\n",
      "episode 380, reward 324.0, memory_length 2000, epsilon 0.14955366236071277 total_time 727.0\n",
      "Saving Model 380\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 381, reward 633.0, memory_length 2000, epsilon 0.14880776035787815 total_time 724.0\n",
      "episode 382, reward 749.0, memory_length 2000, epsilon 0.14806557855680288 total_time 721.0\n",
      "episode 383, reward 411.0, memory_length 2000, epsilon 0.1473270984029033 total_time 725.0\n",
      "episode 384, reward 617.0, memory_length 2000, epsilon 0.14659230143413712 total_time 730.0\n",
      "episode 385, reward 452.0, memory_length 2000, epsilon 0.14586116928054174 total_time 731.0\n",
      "episode 386, reward 653.0, memory_length 2000, epsilon 0.14513368366377538 total_time 723.0\n",
      "episode 387, reward 625.0, memory_length 2000, epsilon 0.1444098263966596 total_time 723.0\n",
      "episode 388, reward 755.0, memory_length 2000, epsilon 0.14368957938272517 total_time 725.0\n",
      "episode 389, reward 845.0, memory_length 2000, epsilon 0.14297292461575908 total_time 722.0\n",
      "episode 390, reward 614.0, memory_length 2000, epsilon 0.14225984417935494 total_time 729.0\n",
      "Saving Model 390\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 391, reward 1053.0, memory_length 2000, epsilon 0.1415503202464646 total_time 721.0\n",
      "episode 392, reward 892.0, memory_length 2000, epsilon 0.1408443350789529 total_time 723.0\n",
      "episode 393, reward 680.0, memory_length 2000, epsilon 0.14014187102715378 total_time 721.0\n",
      "episode 394, reward 567.0, memory_length 2000, epsilon 0.13944291052942945 total_time 728.0\n",
      "episode 395, reward 775.0, memory_length 2000, epsilon 0.13874743611173093 total_time 736.0\n",
      "episode 396, reward 582.0, memory_length 2000, epsilon 0.13805543038716173 total_time 722.0\n",
      "episode 397, reward 643.0, memory_length 2000, epsilon 0.13736687605554254 total_time 731.0\n",
      "episode 398, reward 948.0, memory_length 2000, epsilon 0.1366817559029793 total_time 727.0\n",
      "episode 399, reward 1005.0, memory_length 2000, epsilon 0.13600005280143249 total_time 732.0\n",
      "episode 400, reward 688.0, memory_length 2000, epsilon 0.13532174970828903 total_time 721.0\n",
      "Saving Model 400\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 401, reward 812.0, memory_length 2000, epsilon 0.1346468296659363 total_time 721.0\n",
      "episode 402, reward 313.0, memory_length 2000, epsilon 0.13397527580133806 total_time 721.0\n",
      "episode 403, reward 490.0, memory_length 2000, epsilon 0.13330707132561276 total_time 724.0\n",
      "episode 404, reward 892.0, memory_length 2000, epsilon 0.1326421995336137 total_time 728.0\n",
      "episode 405, reward 696.0, memory_length 2000, epsilon 0.13198064380351143 total_time 722.0\n",
      "episode 406, reward 819.0, memory_length 2000, epsilon 0.13132238759637818 total_time 723.0\n",
      "episode 407, reward 582.0, memory_length 2000, epsilon 0.13066741445577462 total_time 723.0\n",
      "episode 408, reward 812.0, memory_length 2000, epsilon 0.13001570800733805 total_time 725.0\n",
      "episode 409, reward 603.0, memory_length 2000, epsilon 0.12936725195837334 total_time 728.0\n",
      "episode 410, reward 810.0, memory_length 2000, epsilon 0.12872203009744546 total_time 723.0\n",
      "Saving Model 410\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 411, reward 492.0, memory_length 2000, epsilon 0.12808002629397422 total_time 725.0\n",
      "episode 412, reward 1455.0, memory_length 2000, epsilon 0.12744122449783127 total_time 723.0\n",
      "episode 413, reward 792.0, memory_length 2000, epsilon 0.12680560873893829 total_time 728.0\n",
      "episode 414, reward 561.0, memory_length 2000, epsilon 0.12617316312686827 total_time 730.0\n",
      "episode 415, reward 770.0, memory_length 2000, epsilon 0.12554387185044788 total_time 721.0\n",
      "episode 416, reward 789.0, memory_length 2000, epsilon 0.12491771917736255 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 417, reward 829.0, memory_length 2000, epsilon 0.1242946894537628 total_time 724.0\n",
      "episode 418, reward 657.0, memory_length 2000, epsilon 0.12367476710387308 total_time 728.0\n",
      "episode 419, reward 780.0, memory_length 2000, epsilon 0.12305793662960231 total_time 722.0\n",
      "episode 420, reward 970.0, memory_length 2000, epsilon 0.1224441826101566 total_time 726.0\n",
      "Saving Model 420\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 421, reward 723.0, memory_length 2000, epsilon 0.12183348970165345 total_time 721.0\n",
      "episode 422, reward 995.0, memory_length 2000, epsilon 0.12122584263673834 total_time 725.0\n",
      "episode 423, reward 865.0, memory_length 2000, epsilon 0.12062122622420295 total_time 724.0\n",
      "episode 424, reward 515.0, memory_length 2000, epsilon 0.12001962534860558 total_time 734.0\n",
      "episode 425, reward 281.0, memory_length 2000, epsilon 0.11942102496989294 total_time 726.0\n",
      "episode 426, reward 878.0, memory_length 2000, epsilon 0.11882541012302442 total_time 726.0\n",
      "episode 427, reward 651.0, memory_length 2000, epsilon 0.11823276591759774 total_time 728.0\n",
      "episode 428, reward 400.0, memory_length 2000, epsilon 0.117643077537477 total_time 721.0\n",
      "episode 429, reward 642.0, memory_length 2000, epsilon 0.11705633024042196 total_time 724.0\n",
      "episode 430, reward 968.0, memory_length 2000, epsilon 0.11647250935771962 total_time 729.0\n",
      "Saving Model 430\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 431, reward 748.0, memory_length 2000, epsilon 0.11589160029381745 total_time 723.0\n",
      "episode 432, reward 746.0, memory_length 2000, epsilon 0.11531358852595872 total_time 724.0\n",
      "episode 433, reward 679.0, memory_length 2000, epsilon 0.11473845960381902 total_time 727.0\n",
      "episode 434, reward 735.0, memory_length 2000, epsilon 0.11416619914914541 total_time 726.0\n",
      "episode 435, reward 383.0, memory_length 2000, epsilon 0.11359679285539663 total_time 725.0\n",
      "episode 436, reward 1096.0, memory_length 2000, epsilon 0.11303022648738581 total_time 722.0\n",
      "episode 437, reward 847.0, memory_length 2000, epsilon 0.11246648588092414 total_time 723.0\n",
      "episode 438, reward 1081.0, memory_length 2000, epsilon 0.11190555694246715 total_time 731.0\n",
      "episode 439, reward 675.0, memory_length 2000, epsilon 0.11134742564876213 total_time 721.0\n",
      "episode 440, reward 932.0, memory_length 2000, epsilon 0.11079207804649764 total_time 721.0\n",
      "Saving Model 440\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 441, reward 863.0, memory_length 2000, epsilon 0.11023950025195477 total_time 721.0\n",
      "episode 442, reward 1147.0, memory_length 2000, epsilon 0.10968967845065986 total_time 725.0\n",
      "episode 443, reward 927.0, memory_length 2000, epsilon 0.10914259889703921 total_time 731.0\n",
      "episode 444, reward 732.0, memory_length 2000, epsilon 0.10859824791407546 total_time 726.0\n",
      "episode 445, reward 748.0, memory_length 2000, epsilon 0.10805661189296578 total_time 725.0\n",
      "episode 446, reward 703.0, memory_length 2000, epsilon 0.10751767729278137 total_time 723.0\n",
      "episode 447, reward 812.0, memory_length 2000, epsilon 0.10698143064012917 total_time 723.0\n",
      "episode 448, reward 389.0, memory_length 2000, epsilon 0.10644785852881489 total_time 721.0\n",
      "episode 449, reward 976.0, memory_length 2000, epsilon 0.10591694761950801 total_time 721.0\n",
      "episode 450, reward 405.0, memory_length 2000, epsilon 0.10538868463940815 total_time 721.0\n",
      "Saving Model 450\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 451, reward 692.0, memory_length 2000, epsilon 0.10486305638191327 total_time 730.0\n",
      "episode 452, reward 530.0, memory_length 2000, epsilon 0.10434004970628952 total_time 726.0\n",
      "episode 453, reward 810.0, memory_length 2000, epsilon 0.10381965153734285 total_time 721.0\n",
      "episode 454, reward 1174.0, memory_length 2000, epsilon 0.10330184886509189 total_time 723.0\n",
      "episode 455, reward 533.0, memory_length 2000, epsilon 0.10278662874444287 total_time 731.0\n",
      "episode 456, reward 569.0, memory_length 2000, epsilon 0.10227397829486588 total_time 731.0\n",
      "episode 457, reward 1014.0, memory_length 2000, epsilon 0.1017638847000731 total_time 725.0\n",
      "episode 458, reward 741.0, memory_length 2000, epsilon 0.10125633520769801 total_time 725.0\n",
      "episode 459, reward 1138.0, memory_length 2000, epsilon 0.1007513171289769 total_time 721.0\n",
      "episode 460, reward 452.0, memory_length 2000, epsilon 0.10024881783843143 total_time 729.0\n",
      "Saving Model 460\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 461, reward 956.0, memory_length 2000, epsilon 0.09974882477355326 total_time 724.0\n",
      "episode 462, reward 862.0, memory_length 2000, epsilon 0.0992513254344897 total_time 722.0\n",
      "episode 463, reward 802.0, memory_length 2000, epsilon 0.09875630738373133 total_time 727.0\n",
      "episode 464, reward 568.0, memory_length 2000, epsilon 0.09826375824580111 total_time 729.0\n",
      "episode 465, reward 1117.0, memory_length 2000, epsilon 0.09777366570694491 total_time 727.0\n",
      "episode 466, reward 1218.0, memory_length 2000, epsilon 0.09728601751482381 total_time 724.0\n",
      "episode 467, reward 643.0, memory_length 2000, epsilon 0.09680080147820756 total_time 721.0\n",
      "episode 468, reward 872.0, memory_length 2000, epsilon 0.09631800546666999 total_time 723.0\n",
      "episode 469, reward 478.0, memory_length 2000, epsilon 0.0958376174102856 total_time 724.0\n",
      "episode 470, reward 693.0, memory_length 2000, epsilon 0.09535962529932807 total_time 721.0\n",
      "Saving Model 470\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 471, reward 873.0, memory_length 2000, epsilon 0.09488401718396965 total_time 732.0\n",
      "episode 472, reward 944.0, memory_length 2000, epsilon 0.09441078117398272 total_time 725.0\n",
      "episode 473, reward 973.0, memory_length 2000, epsilon 0.09393990543844233 total_time 724.0\n",
      "episode 474, reward 715.0, memory_length 2000, epsilon 0.09347137820543067 total_time 727.0\n",
      "episode 475, reward 821.0, memory_length 2000, epsilon 0.09300518776174242 total_time 723.0\n",
      "episode 476, reward 512.0, memory_length 2000, epsilon 0.09254132245259225 total_time 725.0\n",
      "episode 477, reward 960.0, memory_length 2000, epsilon 0.09207977068132323 total_time 722.0\n",
      "episode 478, reward 745.0, memory_length 2000, epsilon 0.09162052090911708 total_time 724.0\n",
      "episode 479, reward 792.0, memory_length 2000, epsilon 0.0911635616547056 total_time 724.0\n",
      "episode 480, reward 920.0, memory_length 2000, epsilon 0.09070888149408357 total_time 725.0\n",
      "Saving Model 480\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 481, reward 874.0, memory_length 2000, epsilon 0.09025646906022329 total_time 726.0\n",
      "episode 482, reward 755.0, memory_length 2000, epsilon 0.08980631304279041 total_time 721.0\n",
      "episode 483, reward 715.0, memory_length 2000, epsilon 0.08935840218786102 total_time 723.0\n",
      "episode 484, reward 867.0, memory_length 2000, epsilon 0.08891272529764041 total_time 726.0\n",
      "episode 485, reward 1001.0, memory_length 2000, epsilon 0.08846927123018307 total_time 725.0\n",
      "episode 486, reward 757.0, memory_length 2000, epsilon 0.08802802889911432 total_time 722.0\n",
      "episode 487, reward 1005.0, memory_length 2000, epsilon 0.08758898727335282 total_time 724.0\n",
      "episode 488, reward 962.0, memory_length 2000, epsilon 0.0871521353768351 total_time 729.0\n",
      "episode 489, reward 796.0, memory_length 2000, epsilon 0.08671746228824097 total_time 725.0\n",
      "episode 490, reward 542.0, memory_length 2000, epsilon 0.08628495714072056 total_time 723.0\n",
      "Saving Model 490\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 491, reward 446.0, memory_length 2000, epsilon 0.08585460912162271 total_time 726.0\n",
      "episode 492, reward 874.0, memory_length 2000, epsilon 0.0854264074722245 total_time 722.0\n",
      "episode 493, reward 601.0, memory_length 2000, epsilon 0.0850003414874624 total_time 724.0\n",
      "episode 494, reward 874.0, memory_length 2000, epsilon 0.08457640051566453 total_time 723.0\n",
      "episode 495, reward 968.0, memory_length 2000, epsilon 0.08415457395828463 total_time 724.0\n",
      "episode 496, reward 855.0, memory_length 2000, epsilon 0.08373485126963674 total_time 721.0\n",
      "episode 497, reward 612.0, memory_length 2000, epsilon 0.08331722195663178 total_time 722.0\n",
      "episode 498, reward 671.0, memory_length 2000, epsilon 0.08290167557851515 total_time 729.0\n",
      "episode 499, reward 695.0, memory_length 2000, epsilon 0.0824882017466058 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 500, reward 337.0, memory_length 2000, epsilon 0.08207679012403642 total_time 721.0\n",
      "Saving Model 500\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 501, reward 820.0, memory_length 2000, epsilon 0.08166743042549493 total_time 724.0\n",
      "episode 502, reward 723.0, memory_length 2000, epsilon 0.08126011241696758 total_time 724.0\n",
      "episode 503, reward 783.0, memory_length 2000, epsilon 0.080854825915483 total_time 724.0\n",
      "episode 504, reward 911.0, memory_length 2000, epsilon 0.08045156078885748 total_time 725.0\n",
      "episode 505, reward 850.0, memory_length 2000, epsilon 0.08005030695544187 total_time 721.0\n",
      "episode 506, reward 615.0, memory_length 2000, epsilon 0.07965105438386942 total_time 721.0\n",
      "episode 507, reward 886.0, memory_length 2000, epsilon 0.07925379309280507 total_time 724.0\n",
      "episode 508, reward 1074.0, memory_length 2000, epsilon 0.07885851315069588 total_time 722.0\n",
      "episode 509, reward 593.0, memory_length 2000, epsilon 0.07846520467552266 total_time 722.0\n",
      "episode 510, reward 804.0, memory_length 2000, epsilon 0.078073857834553 total_time 731.0\n",
      "Saving Model 510\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 511, reward 988.0, memory_length 2000, epsilon 0.07768446284409562 total_time 731.0\n",
      "episode 512, reward 952.0, memory_length 2000, epsilon 0.07729700996925541 total_time 729.0\n",
      "episode 513, reward 1184.0, memory_length 2000, epsilon 0.07691148952369033 total_time 727.0\n",
      "episode 514, reward 848.0, memory_length 2000, epsilon 0.07652789186936912 total_time 723.0\n",
      "episode 515, reward 600.0, memory_length 2000, epsilon 0.07614620741633046 total_time 722.0\n",
      "episode 516, reward 774.0, memory_length 2000, epsilon 0.07576642662244319 total_time 724.0\n",
      "episode 517, reward 856.0, memory_length 2000, epsilon 0.07538853999316765 total_time 726.0\n",
      "episode 518, reward 807.0, memory_length 2000, epsilon 0.07501253808131844 total_time 723.0\n",
      "episode 519, reward 804.0, memory_length 2000, epsilon 0.07463841148682812 total_time 722.0\n",
      "episode 520, reward 599.0, memory_length 2000, epsilon 0.07426615085651245 total_time 727.0\n",
      "Saving Model 520\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 521, reward 704.0, memory_length 2000, epsilon 0.0738957468838362 total_time 731.0\n",
      "episode 522, reward 656.0, memory_length 2000, epsilon 0.0735271903086808 total_time 722.0\n",
      "episode 523, reward 642.0, memory_length 2000, epsilon 0.07316047191711261 total_time 722.0\n",
      "episode 524, reward 521.0, memory_length 2000, epsilon 0.07279558254115284 total_time 722.0\n",
      "episode 525, reward 629.0, memory_length 2000, epsilon 0.07243251305854803 total_time 724.0\n",
      "episode 526, reward 812.0, memory_length 2000, epsilon 0.07207125439254222 total_time 722.0\n",
      "episode 527, reward 762.0, memory_length 2000, epsilon 0.07171179751164991 total_time 724.0\n",
      "episode 528, reward 846.0, memory_length 2000, epsilon 0.07135413342943042 total_time 722.0\n",
      "episode 529, reward 870.0, memory_length 2000, epsilon 0.07099825320426302 total_time 722.0\n",
      "episode 530, reward 1150.0, memory_length 2000, epsilon 0.07064414793912355 total_time 721.0\n",
      "Saving Model 530\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 531, reward 428.0, memory_length 2000, epsilon 0.07029180878136192 total_time 722.0\n",
      "episode 532, reward 911.0, memory_length 2000, epsilon 0.06994122692248089 total_time 721.0\n",
      "episode 533, reward 905.0, memory_length 2000, epsilon 0.06959239359791569 total_time 724.0\n",
      "episode 534, reward 612.0, memory_length 2000, epsilon 0.06924530008681506 total_time 725.0\n",
      "episode 535, reward 796.0, memory_length 2000, epsilon 0.0688999377118231 total_time 724.0\n",
      "episode 536, reward 819.0, memory_length 2000, epsilon 0.06855629783886248 total_time 726.0\n",
      "episode 537, reward 1370.0, memory_length 2000, epsilon 0.06821437187691849 total_time 728.0\n",
      "episode 538, reward 1193.0, memory_length 2000, epsilon 0.06787415127782427 total_time 727.0\n",
      "episode 539, reward 1050.0, memory_length 2000, epsilon 0.0675356275360471 total_time 722.0\n",
      "episode 540, reward 1221.0, memory_length 2000, epsilon 0.06719879218847578 total_time 723.0\n",
      "Saving Model 540\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 541, reward 396.0, memory_length 2000, epsilon 0.06686363681420915 total_time 724.0\n",
      "episode 542, reward 1167.0, memory_length 2000, epsilon 0.06653015303434535 total_time 725.0\n",
      "episode 543, reward 1355.0, memory_length 2000, epsilon 0.06619833251177254 total_time 725.0\n",
      "episode 544, reward 1082.0, memory_length 2000, epsilon 0.0658681669509603 total_time 721.0\n",
      "episode 545, reward 863.0, memory_length 2000, epsilon 0.06553964809775253 total_time 726.0\n",
      "episode 546, reward 692.0, memory_length 2000, epsilon 0.06521276773916071 total_time 723.0\n",
      "episode 547, reward 710.0, memory_length 2000, epsilon 0.06488751770315888 total_time 728.0\n",
      "episode 548, reward 1009.0, memory_length 2000, epsilon 0.06456388985847915 total_time 721.0\n",
      "episode 549, reward 943.0, memory_length 2000, epsilon 0.06424187611440862 total_time 730.0\n",
      "episode 550, reward 824.0, memory_length 2000, epsilon 0.0639214684205869 total_time 723.0\n",
      "Saving Model 550\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 551, reward 789.0, memory_length 2000, epsilon 0.06360265876680493 total_time 722.0\n",
      "episode 552, reward 821.0, memory_length 2000, epsilon 0.06328543918280474 total_time 727.0\n",
      "episode 553, reward 971.0, memory_length 2000, epsilon 0.06296980173808027 total_time 726.0\n",
      "episode 554, reward 673.0, memory_length 2000, epsilon 0.06265573854167894 total_time 723.0\n",
      "episode 555, reward 913.0, memory_length 2000, epsilon 0.062343241742004465 total_time 721.0\n",
      "episode 556, reward 1217.0, memory_length 2000, epsilon 0.06203230352662056 total_time 721.0\n",
      "episode 557, reward 707.0, memory_length 2000, epsilon 0.061722916122055695 total_time 730.0\n",
      "episode 558, reward 1016.0, memory_length 2000, epsilon 0.061415071793608625 total_time 722.0\n",
      "episode 559, reward 1070.0, memory_length 2000, epsilon 0.0611087628451551 total_time 722.0\n",
      "episode 560, reward 1031.0, memory_length 2000, epsilon 0.06080398161895543 total_time 722.0\n",
      "Saving Model 560\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 561, reward 936.0, memory_length 2000, epsilon 0.06050072049546313 total_time 724.0\n",
      "episode 562, reward 495.0, memory_length 2000, epsilon 0.060198971893134307 total_time 721.0\n",
      "episode 563, reward 919.0, memory_length 2000, epsilon 0.05989872826823817 total_time 721.0\n",
      "episode 564, reward 779.0, memory_length 2000, epsilon 0.05959998211466847 total_time 726.0\n",
      "episode 565, reward 951.0, memory_length 2000, epsilon 0.05930272596375578 total_time 724.0\n",
      "episode 566, reward 1117.0, memory_length 2000, epsilon 0.0590069523840809 total_time 721.0\n",
      "episode 567, reward 935.0, memory_length 2000, epsilon 0.0587126539812889 total_time 730.0\n",
      "episode 568, reward 799.0, memory_length 2000, epsilon 0.05841982339790438 total_time 735.0\n",
      "episode 569, reward 1224.0, memory_length 2000, epsilon 0.058128453313147484 total_time 727.0\n",
      "episode 570, reward 861.0, memory_length 2000, epsilon 0.05783853644275097 total_time 732.0\n",
      "Saving Model 570\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 571, reward 846.0, memory_length 2000, epsilon 0.05755006553877796 total_time 728.0\n",
      "episode 572, reward 1083.0, memory_length 2000, epsilon 0.05726303338944081 total_time 724.0\n",
      "episode 573, reward 732.0, memory_length 2000, epsilon 0.056977432818920835 total_time 725.0\n",
      "episode 574, reward 902.0, memory_length 2000, epsilon 0.05669325668718892 total_time 721.0\n",
      "episode 575, reward 924.0, memory_length 2000, epsilon 0.05641049788982697 total_time 730.0\n",
      "episode 576, reward 910.0, memory_length 2000, epsilon 0.056129149357850315 total_time 730.0\n",
      "episode 577, reward 1290.0, memory_length 2000, epsilon 0.05584920405753097 total_time 728.0\n",
      "episode 578, reward 961.0, memory_length 2000, epsilon 0.05557065499022191 total_time 724.0\n",
      "episode 579, reward 1136.0, memory_length 2000, epsilon 0.055293495192181914 total_time 721.0\n",
      "episode 580, reward 750.0, memory_length 2000, epsilon 0.05501771773440159 total_time 727.0\n",
      "Saving Model 580\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 581, reward 873.0, memory_length 2000, epsilon 0.054743315722430116 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 582, reward 1135.0, memory_length 2000, epsilon 0.05447028229620294 total_time 724.0\n",
      "episode 583, reward 974.0, memory_length 2000, epsilon 0.054198610629870164 total_time 723.0\n",
      "episode 584, reward 977.0, memory_length 2000, epsilon 0.05392829393162599 total_time 722.0\n",
      "episode 585, reward 674.0, memory_length 2000, epsilon 0.05365932544353883 total_time 728.0\n",
      "episode 586, reward 1090.0, memory_length 2000, epsilon 0.053391698441382564 total_time 726.0\n",
      "episode 587, reward 985.0, memory_length 2000, epsilon 0.05312540623446814 total_time 723.0\n",
      "episode 588, reward 969.0, memory_length 2000, epsilon 0.052860442165476536 total_time 723.0\n",
      "episode 589, reward 1071.0, memory_length 2000, epsilon 0.05259679961029221 total_time 723.0\n",
      "episode 590, reward 1023.0, memory_length 2000, epsilon 0.05233447197783754 total_time 738.0\n",
      "Saving Model 590\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 591, reward 428.0, memory_length 2000, epsilon 0.0520734527099081 total_time 729.0\n",
      "episode 592, reward 784.0, memory_length 2000, epsilon 0.05181373528100856 total_time 723.0\n",
      "episode 593, reward 1213.0, memory_length 2000, epsilon 0.051555313198189685 total_time 721.0\n",
      "episode 594, reward 830.0, memory_length 2000, epsilon 0.051298180000885915 total_time 723.0\n",
      "episode 595, reward 1080.0, memory_length 2000, epsilon 0.05104232926075398 total_time 721.0\n",
      "episode 596, reward 736.0, memory_length 2000, epsilon 0.05078775458151202 total_time 726.0\n",
      "episode 597, reward 773.0, memory_length 2000, epsilon 0.050534449598779785 total_time 723.0\n",
      "episode 598, reward 804.0, memory_length 2000, epsilon 0.05028240797991951 total_time 724.0\n",
      "episode 599, reward 959.0, memory_length 2000, epsilon 0.050031623423877625 total_time 731.0\n",
      "episode 600, reward 685.0, memory_length 2000, epsilon 0.04978208966102716 total_time 723.0\n",
      "Saving Model 600\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 601, reward 1056.0, memory_length 2000, epsilon 0.049533800453011034 total_time 721.0\n",
      "episode 602, reward 1182.0, memory_length 2000, epsilon 0.0492867495925861 total_time 725.0\n",
      "episode 603, reward 776.0, memory_length 2000, epsilon 0.049040930903468026 total_time 727.0\n",
      "episode 604, reward 660.0, memory_length 2000, epsilon 0.04879633824017676 total_time 721.0\n",
      "episode 605, reward 1285.0, memory_length 2000, epsilon 0.048552965487882974 total_time 727.0\n",
      "episode 606, reward 1016.0, memory_length 2000, epsilon 0.048310806562255164 total_time 724.0\n",
      "episode 607, reward 943.0, memory_length 2000, epsilon 0.04806985540930762 total_time 725.0\n",
      "episode 608, reward 832.0, memory_length 2000, epsilon 0.04783010600524895 total_time 721.0\n",
      "episode 609, reward 894.0, memory_length 2000, epsilon 0.047591552356331564 total_time 721.0\n",
      "episode 610, reward 1050.0, memory_length 2000, epsilon 0.047354188498701794 total_time 727.0\n",
      "Saving Model 610\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 611, reward 1038.0, memory_length 2000, epsilon 0.04711800849825088 total_time 721.0\n",
      "episode 612, reward 876.0, memory_length 2000, epsilon 0.04688300645046649 total_time 730.0\n",
      "episode 613, reward 1038.0, memory_length 2000, epsilon 0.04664917648028518 total_time 721.0\n",
      "episode 614, reward 678.0, memory_length 2000, epsilon 0.046416512741945505 total_time 723.0\n",
      "episode 615, reward 897.0, memory_length 2000, epsilon 0.04618500941884193 total_time 726.0\n",
      "episode 616, reward 1117.0, memory_length 2000, epsilon 0.0459546607233793 total_time 727.0\n",
      "episode 617, reward 513.0, memory_length 2000, epsilon 0.04572546089682823 total_time 727.0\n",
      "episode 618, reward 1128.0, memory_length 2000, epsilon 0.04549740420918111 total_time 740.0\n",
      "episode 619, reward 698.0, memory_length 2000, epsilon 0.04527048495900886 total_time 721.0\n",
      "episode 620, reward 1532.0, memory_length 2000, epsilon 0.04504469747331845 total_time 730.0\n",
      "Saving Model 620\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 621, reward 1013.0, memory_length 2000, epsilon 0.04482003610741094 total_time 728.0\n",
      "episode 622, reward 684.0, memory_length 2000, epsilon 0.044596495244740506 total_time 726.0\n",
      "episode 623, reward 1043.0, memory_length 2000, epsilon 0.0443740692967739 total_time 723.0\n",
      "episode 624, reward 925.0, memory_length 2000, epsilon 0.04415275270285089 total_time 721.0\n",
      "episode 625, reward 764.0, memory_length 2000, epsilon 0.04393253993004508 total_time 722.0\n",
      "episode 626, reward 886.0, memory_length 2000, epsilon 0.04371342547302567 total_time 725.0\n",
      "episode 627, reward 883.0, memory_length 2000, epsilon 0.043495403853919805 total_time 726.0\n",
      "episode 628, reward 604.0, memory_length 2000, epsilon 0.0432784696221757 total_time 722.0\n",
      "episode 629, reward 659.0, memory_length 2000, epsilon 0.043062617354426236 total_time 722.0\n",
      "episode 630, reward 609.0, memory_length 2000, epsilon 0.042847841654353486 total_time 721.0\n",
      "Saving Model 630\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 631, reward 804.0, memory_length 2000, epsilon 0.04263413715255372 total_time 725.0\n",
      "episode 632, reward 1607.0, memory_length 2000, epsilon 0.04242149850640334 total_time 725.0\n",
      "episode 633, reward 838.0, memory_length 2000, epsilon 0.042209920399925056 total_time 725.0\n",
      "episode 634, reward 1218.0, memory_length 2000, epsilon 0.041999397543655205 total_time 721.0\n",
      "episode 635, reward 634.0, memory_length 2000, epsilon 0.041789924674511404 total_time 723.0\n",
      "episode 636, reward 805.0, memory_length 2000, epsilon 0.04158149655566105 total_time 724.0\n",
      "episode 637, reward 961.0, memory_length 2000, epsilon 0.04137410797639028 total_time 729.0\n",
      "episode 638, reward 1027.0, memory_length 2000, epsilon 0.04116775375197383 total_time 724.0\n",
      "episode 639, reward 1219.0, memory_length 2000, epsilon 0.040962428723545316 total_time 723.0\n",
      "episode 640, reward 695.0, memory_length 2000, epsilon 0.040758127757968374 total_time 727.0\n",
      "Saving Model 640\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 641, reward 744.0, memory_length 2000, epsilon 0.0405548457477082 total_time 724.0\n",
      "episode 642, reward 624.0, memory_length 2000, epsilon 0.040352577610703946 total_time 725.0\n",
      "episode 643, reward 546.0, memory_length 2000, epsilon 0.04015131829024166 total_time 725.0\n",
      "episode 644, reward 1082.0, memory_length 2000, epsilon 0.03995106275482783 total_time 723.0\n",
      "episode 645, reward 987.0, memory_length 2000, epsilon 0.03975180599806368 total_time 722.0\n",
      "episode 646, reward 773.0, memory_length 2000, epsilon 0.039553543038519885 total_time 723.0\n",
      "episode 647, reward 622.0, memory_length 2000, epsilon 0.039356268919612136 total_time 722.0\n",
      "episode 648, reward 501.0, memory_length 2000, epsilon 0.03915997870947717 total_time 724.0\n",
      "episode 649, reward 959.0, memory_length 2000, epsilon 0.03896466750084953 total_time 728.0\n",
      "episode 650, reward 827.0, memory_length 2000, epsilon 0.03877033041093884 total_time 722.0\n",
      "Saving Model 650\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 651, reward 1290.0, memory_length 2000, epsilon 0.0385769625813077 total_time 728.0\n",
      "episode 652, reward 1124.0, memory_length 2000, epsilon 0.0383845591777503 total_time 723.0\n",
      "episode 653, reward 1177.0, memory_length 2000, epsilon 0.038193115390171554 total_time 724.0\n",
      "episode 654, reward 656.0, memory_length 2000, epsilon 0.038002626432466796 total_time 722.0\n",
      "episode 655, reward 1111.0, memory_length 2000, epsilon 0.03781308754240215 total_time 723.0\n",
      "episode 656, reward 802.0, memory_length 2000, epsilon 0.037624493981495484 total_time 728.0\n",
      "episode 657, reward 769.0, memory_length 2000, epsilon 0.03743684103489798 total_time 722.0\n",
      "episode 658, reward 880.0, memory_length 2000, epsilon 0.03725012401127619 total_time 721.0\n",
      "episode 659, reward 684.0, memory_length 2000, epsilon 0.03706433824269478 total_time 722.0\n",
      "episode 660, reward 792.0, memory_length 2000, epsilon 0.03687947908449987 total_time 725.0\n",
      "Saving Model 660\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 661, reward 925.0, memory_length 2000, epsilon 0.03669554191520289 total_time 726.0\n",
      "episode 662, reward 951.0, memory_length 2000, epsilon 0.03651252213636503 total_time 728.0\n",
      "episode 663, reward 861.0, memory_length 2000, epsilon 0.03633041517248226 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 664, reward 878.0, memory_length 2000, epsilon 0.03614921647087101 total_time 722.0\n",
      "episode 665, reward 863.0, memory_length 2000, epsilon 0.03596892150155431 total_time 722.0\n",
      "episode 666, reward 629.0, memory_length 2000, epsilon 0.035789525757148534 total_time 723.0\n",
      "episode 667, reward 827.0, memory_length 2000, epsilon 0.03561102475275072 total_time 725.0\n",
      "episode 668, reward 1195.0, memory_length 2000, epsilon 0.03543341402582648 total_time 731.0\n",
      "episode 669, reward 1038.0, memory_length 2000, epsilon 0.03525668913609836 total_time 729.0\n",
      "episode 670, reward 979.0, memory_length 2000, epsilon 0.03508084566543494 total_time 722.0\n",
      "Saving Model 670\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 671, reward 884.0, memory_length 2000, epsilon 0.034905879217740285 total_time 722.0\n",
      "episode 672, reward 688.0, memory_length 2000, epsilon 0.03473178541884409 total_time 725.0\n",
      "episode 673, reward 797.0, memory_length 2000, epsilon 0.0345585599163923 total_time 725.0\n",
      "episode 674, reward 1038.0, memory_length 2000, epsilon 0.034386198379738366 total_time 728.0\n",
      "episode 675, reward 1108.0, memory_length 2000, epsilon 0.034214696499834864 total_time 721.0\n",
      "episode 676, reward 790.0, memory_length 2000, epsilon 0.034044049989125885 total_time 721.0\n",
      "episode 677, reward 838.0, memory_length 2000, epsilon 0.03387425458143975 total_time 723.0\n",
      "episode 678, reward 695.0, memory_length 2000, epsilon 0.03370530603188244 total_time 724.0\n",
      "episode 679, reward 528.0, memory_length 2000, epsilon 0.03353720011673142 total_time 721.0\n",
      "episode 680, reward 788.0, memory_length 2000, epsilon 0.033369932633330046 total_time 727.0\n",
      "Saving Model 680\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 681, reward 833.0, memory_length 2000, epsilon 0.03320349939998252 total_time 724.0\n",
      "episode 682, reward 1003.0, memory_length 2000, epsilon 0.033037896255849346 total_time 732.0\n",
      "episode 683, reward 1101.0, memory_length 2000, epsilon 0.032873119060843295 total_time 728.0\n",
      "episode 684, reward 807.0, memory_length 2000, epsilon 0.032709163695525914 total_time 722.0\n",
      "episode 685, reward 1371.0, memory_length 2000, epsilon 0.032546026061004506 total_time 729.0\n",
      "episode 686, reward 865.0, memory_length 2000, epsilon 0.03238370207882975 total_time 725.0\n",
      "episode 687, reward 831.0, memory_length 2000, epsilon 0.03222218769089361 total_time 724.0\n",
      "episode 688, reward 1072.0, memory_length 2000, epsilon 0.03206147885932798 total_time 721.0\n",
      "episode 689, reward 965.0, memory_length 2000, epsilon 0.0319015715664037 total_time 729.0\n",
      "episode 690, reward 788.0, memory_length 2000, epsilon 0.031742461814430134 total_time 722.0\n",
      "Saving Model 690\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 691, reward 1112.0, memory_length 2000, epsilon 0.031584145625655174 total_time 726.0\n",
      "episode 692, reward 710.0, memory_length 2000, epsilon 0.03142661904216587 total_time 730.0\n",
      "episode 693, reward 689.0, memory_length 2000, epsilon 0.03126987812578943 total_time 722.0\n",
      "episode 694, reward 978.0, memory_length 2000, epsilon 0.031113918957994754 total_time 730.0\n",
      "episode 695, reward 771.0, memory_length 2000, epsilon 0.030958737639794565 total_time 725.0\n",
      "episode 696, reward 654.0, memory_length 2000, epsilon 0.0308043302916478 total_time 724.0\n",
      "episode 697, reward 810.0, memory_length 2000, epsilon 0.030650693053362727 total_time 724.0\n",
      "episode 698, reward 837.0, memory_length 2000, epsilon 0.030497822084000363 total_time 727.0\n",
      "episode 699, reward 826.0, memory_length 2000, epsilon 0.03034571356177854 total_time 727.0\n",
      "episode 700, reward 866.0, memory_length 2000, epsilon 0.03019436368397627 total_time 725.0\n",
      "Saving Model 700\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 701, reward 562.0, memory_length 2000, epsilon 0.03004376866683872 total_time 726.0\n",
      "episode 702, reward 956.0, memory_length 2000, epsilon 0.029893924745482615 total_time 727.0\n",
      "episode 703, reward 996.0, memory_length 2000, epsilon 0.029744828173802133 total_time 721.0\n",
      "episode 704, reward 941.0, memory_length 2000, epsilon 0.02959647522437521 total_time 726.0\n",
      "episode 705, reward 1199.0, memory_length 2000, epsilon 0.02944886218837038 total_time 727.0\n",
      "episode 706, reward 1067.0, memory_length 2000, epsilon 0.029301985375454042 total_time 727.0\n",
      "episode 707, reward 877.0, memory_length 2000, epsilon 0.02915584111369825 total_time 730.0\n",
      "episode 708, reward 1111.0, memory_length 2000, epsilon 0.029010425749488835 total_time 721.0\n",
      "episode 709, reward 999.0, memory_length 2000, epsilon 0.028865735647434117 total_time 727.0\n",
      "episode 710, reward 302.0, memory_length 2000, epsilon 0.028721767190274 total_time 727.0\n",
      "Saving Model 710\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 711, reward 1097.0, memory_length 2000, epsilon 0.028578516778789576 total_time 724.0\n",
      "episode 712, reward 777.0, memory_length 2000, epsilon 0.028435980831713087 total_time 724.0\n",
      "episode 713, reward 1004.0, memory_length 2000, epsilon 0.028294155785638434 total_time 728.0\n",
      "episode 714, reward 916.0, memory_length 2000, epsilon 0.028153038094932067 total_time 724.0\n",
      "episode 715, reward 1316.0, memory_length 2000, epsilon 0.028012624231644388 total_time 726.0\n",
      "episode 716, reward 793.0, memory_length 2000, epsilon 0.02787291068542149 total_time 732.0\n",
      "episode 717, reward 623.0, memory_length 2000, epsilon 0.02773389396341745 total_time 725.0\n",
      "episode 718, reward 1174.0, memory_length 2000, epsilon 0.027595570590206963 total_time 730.0\n",
      "episode 719, reward 789.0, memory_length 2000, epsilon 0.02745793710769849 total_time 723.0\n",
      "episode 720, reward 826.0, memory_length 2000, epsilon 0.02732099007504783 total_time 721.0\n",
      "Saving Model 720\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 721, reward 628.0, memory_length 2000, epsilon 0.027184726068572012 total_time 721.0\n",
      "episode 722, reward 1051.0, memory_length 2000, epsilon 0.02704914168166378 total_time 721.0\n",
      "episode 723, reward 1154.0, memory_length 2000, epsilon 0.02691423352470639 total_time 726.0\n",
      "episode 724, reward 946.0, memory_length 2000, epsilon 0.026779998224988912 total_time 727.0\n",
      "episode 725, reward 913.0, memory_length 2000, epsilon 0.02664643242662185 total_time 727.0\n",
      "episode 726, reward 688.0, memory_length 2000, epsilon 0.026513532790453292 total_time 721.0\n",
      "episode 727, reward 1234.0, memory_length 2000, epsilon 0.026381295993985397 total_time 722.0\n",
      "episode 728, reward 1383.0, memory_length 2000, epsilon 0.026249718731291394 total_time 728.0\n",
      "episode 729, reward 1147.0, memory_length 2000, epsilon 0.02611879771293284 total_time 721.0\n",
      "episode 730, reward 935.0, memory_length 2000, epsilon 0.02598852966587747 total_time 723.0\n",
      "Saving Model 730\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 731, reward 838.0, memory_length 2000, epsilon 0.025858911333417306 total_time 721.0\n",
      "episode 732, reward 792.0, memory_length 2000, epsilon 0.025729939475087303 total_time 730.0\n",
      "episode 733, reward 912.0, memory_length 2000, epsilon 0.025601610866584284 total_time 723.0\n",
      "episode 734, reward 745.0, memory_length 2000, epsilon 0.025473922299686348 total_time 721.0\n",
      "episode 735, reward 520.0, memory_length 2000, epsilon 0.025346870582172658 total_time 721.0\n",
      "episode 736, reward 752.0, memory_length 2000, epsilon 0.02522045253774369 total_time 726.0\n",
      "episode 737, reward 1123.0, memory_length 2000, epsilon 0.02509466500594173 total_time 722.0\n",
      "episode 738, reward 884.0, memory_length 2000, epsilon 0.024969504842071926 total_time 721.0\n",
      "episode 739, reward 1350.0, memory_length 2000, epsilon 0.024844968917123667 total_time 726.0\n",
      "episode 740, reward 949.0, memory_length 2000, epsilon 0.024721054117692355 total_time 723.0\n",
      "Saving Model 740\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 741, reward 999.0, memory_length 2000, epsilon 0.024597757345901538 total_time 728.0\n",
      "episode 742, reward 967.0, memory_length 2000, epsilon 0.024475075519325505 total_time 724.0\n",
      "episode 743, reward 540.0, memory_length 2000, epsilon 0.024353005570912203 total_time 721.0\n",
      "episode 744, reward 863.0, memory_length 2000, epsilon 0.024231544448906545 total_time 721.0\n",
      "episode 745, reward 938.0, memory_length 2000, epsilon 0.024110689116774185 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 746, reward 934.0, memory_length 2000, epsilon 0.023990436553125504 total_time 734.0\n",
      "episode 747, reward 701.0, memory_length 2000, epsilon 0.02387078375164016 total_time 730.0\n",
      "episode 748, reward 1069.0, memory_length 2000, epsilon 0.023751727720991867 total_time 721.0\n",
      "episode 749, reward 640.0, memory_length 2000, epsilon 0.023633265484773677 total_time 722.0\n",
      "episode 750, reward 858.0, memory_length 2000, epsilon 0.023515394081423505 total_time 721.0\n",
      "Saving Model 750\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 751, reward 1048.0, memory_length 2000, epsilon 0.023398110564150136 total_time 722.0\n",
      "episode 752, reward 834.0, memory_length 2000, epsilon 0.02328141200085951 total_time 729.0\n",
      "episode 753, reward 753.0, memory_length 2000, epsilon 0.02316529547408149 total_time 722.0\n",
      "episode 754, reward 1001.0, memory_length 2000, epsilon 0.02304975808089685 total_time 730.0\n",
      "episode 755, reward 1545.0, memory_length 2000, epsilon 0.022934796932864737 total_time 729.0\n",
      "episode 756, reward 948.0, memory_length 2000, epsilon 0.02282040915595046 total_time 726.0\n",
      "episode 757, reward 1082.0, memory_length 2000, epsilon 0.02270659189045366 total_time 731.0\n",
      "episode 758, reward 745.0, memory_length 2000, epsilon 0.022593342290936753 total_time 726.0\n",
      "episode 759, reward 727.0, memory_length 2000, epsilon 0.022480657526153858 total_time 725.0\n",
      "episode 760, reward 741.0, memory_length 2000, epsilon 0.022368534778979973 total_time 721.0\n",
      "Saving Model 760\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 761, reward 779.0, memory_length 2000, epsilon 0.022256971246340605 total_time 722.0\n",
      "episode 762, reward 952.0, memory_length 2000, epsilon 0.022145964139141612 total_time 722.0\n",
      "episode 763, reward 1014.0, memory_length 2000, epsilon 0.02203551068219953 total_time 725.0\n",
      "episode 764, reward 838.0, memory_length 2000, epsilon 0.021925608114172185 total_time 721.0\n",
      "episode 765, reward 769.0, memory_length 2000, epsilon 0.02181625368748966 total_time 727.0\n",
      "episode 766, reward 943.0, memory_length 2000, epsilon 0.021707444668285586 total_time 721.0\n",
      "episode 767, reward 744.0, memory_length 2000, epsilon 0.021599178336328816 total_time 724.0\n",
      "episode 768, reward 574.0, memory_length 2000, epsilon 0.021491451984955414 total_time 728.0\n",
      "episode 769, reward 741.0, memory_length 2000, epsilon 0.021384262921000975 total_time 722.0\n",
      "episode 770, reward 874.0, memory_length 2000, epsilon 0.02127760846473333 total_time 730.0\n",
      "Saving Model 770\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 771, reward 1294.0, memory_length 2000, epsilon 0.021171485949785518 total_time 728.0\n",
      "episode 772, reward 862.0, memory_length 2000, epsilon 0.02106589272308913 total_time 721.0\n",
      "episode 773, reward 1229.0, memory_length 2000, epsilon 0.020960826144807994 total_time 721.0\n",
      "episode 774, reward 877.0, memory_length 2000, epsilon 0.020856283588272195 total_time 723.0\n",
      "episode 775, reward 766.0, memory_length 2000, epsilon 0.02075226243991237 total_time 725.0\n",
      "episode 776, reward 780.0, memory_length 2000, epsilon 0.020648760099194394 total_time 725.0\n",
      "episode 777, reward 531.0, memory_length 2000, epsilon 0.020545773978554345 total_time 728.0\n",
      "episode 778, reward 698.0, memory_length 2000, epsilon 0.020443301503333858 total_time 721.0\n",
      "episode 779, reward 802.0, memory_length 2000, epsilon 0.020341340111715716 total_time 730.0\n",
      "episode 780, reward 848.0, memory_length 2000, epsilon 0.020239887254659812 total_time 721.0\n",
      "Saving Model 780\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 781, reward 852.0, memory_length 2000, epsilon 0.02013894039583942 total_time 723.0\n",
      "episode 782, reward 899.0, memory_length 2000, epsilon 0.020038497011577845 total_time 725.0\n",
      "episode 783, reward 1076.0, memory_length 2000, epsilon 0.01993855459078523 total_time 727.0\n",
      "episode 784, reward 1336.0, memory_length 2000, epsilon 0.01983911063489585 total_time 722.0\n",
      "episode 785, reward 1191.0, memory_length 2000, epsilon 0.019740162657805625 total_time 721.0\n",
      "episode 786, reward 897.0, memory_length 2000, epsilon 0.019641708185809986 total_time 724.0\n",
      "episode 787, reward 954.0, memory_length 2000, epsilon 0.019543744757541996 total_time 725.0\n",
      "episode 788, reward 658.0, memory_length 2000, epsilon 0.019446269923910853 total_time 724.0\n",
      "episode 789, reward 631.0, memory_length 2000, epsilon 0.019349281248040626 total_time 722.0\n",
      "episode 790, reward 761.0, memory_length 2000, epsilon 0.01925277630520938 total_time 725.0\n",
      "Saving Model 790\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 791, reward 818.0, memory_length 2000, epsilon 0.01915675268278852 total_time 728.0\n",
      "episode 792, reward 891.0, memory_length 2000, epsilon 0.019061207980182477 total_time 725.0\n",
      "episode 793, reward 891.0, memory_length 2000, epsilon 0.018966139808768698 total_time 728.0\n",
      "episode 794, reward 1064.0, memory_length 2000, epsilon 0.01887154579183797 total_time 724.0\n",
      "episode 795, reward 675.0, memory_length 2000, epsilon 0.01877742356453493 total_time 724.0\n",
      "episode 796, reward 1203.0, memory_length 2000, epsilon 0.018683770773799 total_time 721.0\n",
      "episode 797, reward 967.0, memory_length 2000, epsilon 0.018590585078305525 total_time 728.0\n",
      "episode 798, reward 990.0, memory_length 2000, epsilon 0.01849786414840726 total_time 725.0\n",
      "episode 799, reward 1177.0, memory_length 2000, epsilon 0.018405605666076144 total_time 727.0\n",
      "episode 800, reward 781.0, memory_length 2000, epsilon 0.018313807324845305 total_time 721.0\n",
      "Saving Model 800\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 801, reward 479.0, memory_length 2000, epsilon 0.018222466829751434 total_time 727.0\n",
      "episode 802, reward 639.0, memory_length 2000, epsilon 0.018131581897277396 total_time 725.0\n",
      "episode 803, reward 490.0, memory_length 2000, epsilon 0.01804115025529514 total_time 724.0\n",
      "episode 804, reward 833.0, memory_length 2000, epsilon 0.0179511696430089 total_time 728.0\n",
      "episode 805, reward 733.0, memory_length 2000, epsilon 0.017861637810898702 total_time 721.0\n",
      "episode 806, reward 286.0, memory_length 2000, epsilon 0.017772552520664075 total_time 727.0\n",
      "episode 807, reward 1026.0, memory_length 2000, epsilon 0.01768391154516812 total_time 734.0\n",
      "episode 808, reward 916.0, memory_length 2000, epsilon 0.017595712668381832 total_time 724.0\n",
      "episode 809, reward 1338.0, memory_length 2000, epsilon 0.017507953685328696 total_time 726.0\n",
      "episode 810, reward 1201.0, memory_length 2000, epsilon 0.017420632402029564 total_time 728.0\n",
      "Saving Model 810\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 811, reward 1306.0, memory_length 2000, epsilon 0.017333746635447813 total_time 726.0\n",
      "episode 812, reward 1238.0, memory_length 2000, epsilon 0.01724729421343473 total_time 722.0\n",
      "episode 813, reward 784.0, memory_length 2000, epsilon 0.017161272974675294 total_time 724.0\n",
      "episode 814, reward 899.0, memory_length 2000, epsilon 0.017075680768634045 total_time 723.0\n",
      "episode 815, reward 1056.0, memory_length 2000, epsilon 0.01699051545550137 total_time 723.0\n",
      "episode 816, reward 1186.0, memory_length 2000, epsilon 0.01690577490614001 total_time 723.0\n",
      "episode 817, reward 1247.0, memory_length 2000, epsilon 0.016821457002031807 total_time 726.0\n",
      "episode 818, reward 731.0, memory_length 2000, epsilon 0.016737559635224775 total_time 722.0\n",
      "episode 819, reward 1204.0, memory_length 2000, epsilon 0.016654080708280374 total_time 722.0\n",
      "episode 820, reward 1034.0, memory_length 2000, epsilon 0.01657101813422108 total_time 722.0\n",
      "Saving Model 820\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 821, reward 1085.0, memory_length 2000, epsilon 0.0164883698364782 total_time 726.0\n",
      "episode 822, reward 900.0, memory_length 2000, epsilon 0.016406133748840014 total_time 738.0\n",
      "episode 823, reward 879.0, memory_length 2000, epsilon 0.016324307815400042 total_time 724.0\n",
      "episode 824, reward 1038.0, memory_length 2000, epsilon 0.016242889990505677 total_time 721.0\n",
      "episode 825, reward 1159.0, memory_length 2000, epsilon 0.01616187823870706 total_time 733.0\n",
      "episode 826, reward 871.0, memory_length 2000, epsilon 0.016081270534706173 total_time 722.0\n",
      "episode 827, reward 573.0, memory_length 2000, epsilon 0.016001064863306224 total_time 729.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 828, reward 978.0, memory_length 2000, epsilon 0.015921259219361248 total_time 732.0\n",
      "episode 829, reward 802.0, memory_length 2000, epsilon 0.01584185160772597 total_time 727.0\n",
      "episode 830, reward 1169.0, memory_length 2000, epsilon 0.015762840043206 total_time 724.0\n",
      "Saving Model 830\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 831, reward 1141.0, memory_length 2000, epsilon 0.01568422255050809 total_time 727.0\n",
      "episode 832, reward 1046.0, memory_length 2000, epsilon 0.015605997164190833 total_time 722.0\n",
      "episode 833, reward 650.0, memory_length 2000, epsilon 0.015528161928615492 total_time 721.0\n",
      "episode 834, reward 773.0, memory_length 2000, epsilon 0.015450714897897124 total_time 721.0\n",
      "episode 835, reward 1028.0, memory_length 2000, epsilon 0.015373654135855931 total_time 727.0\n",
      "episode 836, reward 818.0, memory_length 2000, epsilon 0.015296977715968847 total_time 724.0\n",
      "episode 837, reward 1017.0, memory_length 2000, epsilon 0.015220683721321366 total_time 728.0\n",
      "episode 838, reward 922.0, memory_length 2000, epsilon 0.015144770244559675 total_time 729.0\n",
      "episode 839, reward 1002.0, memory_length 2000, epsilon 0.015069235387842888 total_time 722.0\n",
      "episode 840, reward 749.0, memory_length 2000, epsilon 0.014994077262795655 total_time 721.0\n",
      "Saving Model 840\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 841, reward 696.0, memory_length 2000, epsilon 0.014919293990460936 total_time 730.0\n",
      "episode 842, reward 842.0, memory_length 2000, epsilon 0.014844883701253022 total_time 723.0\n",
      "episode 843, reward 848.0, memory_length 2000, epsilon 0.014770844534910815 total_time 728.0\n",
      "episode 844, reward 1270.0, memory_length 2000, epsilon 0.014697174640451293 total_time 735.0\n",
      "episode 845, reward 1173.0, memory_length 2000, epsilon 0.014623872176123263 total_time 724.0\n",
      "episode 846, reward 1268.0, memory_length 2000, epsilon 0.014550935309361282 total_time 721.0\n",
      "episode 847, reward 1126.0, memory_length 2000, epsilon 0.01447836221673991 total_time 721.0\n",
      "episode 848, reward 1052.0, memory_length 2000, epsilon 0.014406151083928039 total_time 725.0\n",
      "episode 849, reward 948.0, memory_length 2000, epsilon 0.014334300105643589 total_time 726.0\n",
      "episode 850, reward 1134.0, memory_length 2000, epsilon 0.014262807485608356 total_time 724.0\n",
      "Saving Model 850\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 851, reward 1140.0, memory_length 2000, epsilon 0.014191671436503118 total_time 728.0\n",
      "episode 852, reward 768.0, memory_length 2000, epsilon 0.014120890179922945 total_time 724.0\n",
      "episode 853, reward 1238.0, memory_length 2000, epsilon 0.014050461946332733 total_time 727.0\n",
      "episode 854, reward 825.0, memory_length 2000, epsilon 0.013980384975022962 total_time 721.0\n",
      "episode 855, reward 696.0, memory_length 2000, epsilon 0.013910657514065726 total_time 728.0\n",
      "episode 856, reward 998.0, memory_length 2000, epsilon 0.013841277820270854 total_time 732.0\n",
      "episode 857, reward 336.0, memory_length 2000, epsilon 0.013772244159142388 total_time 725.0\n",
      "episode 858, reward 494.0, memory_length 2000, epsilon 0.013703554804835209 total_time 731.0\n",
      "episode 859, reward 1440.0, memory_length 2000, epsilon 0.013635208040111877 total_time 725.0\n",
      "episode 860, reward 1244.0, memory_length 2000, epsilon 0.013567202156299713 total_time 723.0\n",
      "Saving Model 860\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 861, reward 1005.0, memory_length 2000, epsilon 0.013499535453248085 total_time 728.0\n",
      "episode 862, reward 1548.0, memory_length 2000, epsilon 0.013432206239285878 total_time 731.0\n",
      "episode 863, reward 1265.0, memory_length 2000, epsilon 0.013365212831179259 total_time 727.0\n",
      "episode 864, reward 814.0, memory_length 2000, epsilon 0.013298553554089524 total_time 721.0\n",
      "episode 865, reward 1042.0, memory_length 2000, epsilon 0.013232226741531274 total_time 724.0\n",
      "episode 866, reward 835.0, memory_length 2000, epsilon 0.013166230735330743 total_time 724.0\n",
      "episode 867, reward 895.0, memory_length 2000, epsilon 0.013100563885584338 total_time 729.0\n",
      "episode 868, reward 744.0, memory_length 2000, epsilon 0.013035224550617392 total_time 721.0\n",
      "episode 869, reward 1002.0, memory_length 2000, epsilon 0.012970211096943131 total_time 722.0\n",
      "episode 870, reward 1260.0, memory_length 2000, epsilon 0.012905521899221815 total_time 729.0\n",
      "Saving Model 870\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 871, reward 732.0, memory_length 2000, epsilon 0.012841155340220152 total_time 724.0\n",
      "episode 872, reward 1035.0, memory_length 2000, epsilon 0.012777109810770806 total_time 723.0\n",
      "episode 873, reward 1066.0, memory_length 2000, epsilon 0.012713383709732207 total_time 726.0\n",
      "episode 874, reward 793.0, memory_length 2000, epsilon 0.012649975443948505 total_time 726.0\n",
      "episode 875, reward 635.0, memory_length 2000, epsilon 0.012586883428209754 total_time 724.0\n",
      "episode 876, reward 698.0, memory_length 2000, epsilon 0.012524106085212278 total_time 723.0\n",
      "episode 877, reward 852.0, memory_length 2000, epsilon 0.012461641845519228 total_time 728.0\n",
      "episode 878, reward 813.0, memory_length 2000, epsilon 0.012399489147521361 total_time 724.0\n",
      "episode 879, reward 545.0, memory_length 2000, epsilon 0.01233764643739798 total_time 721.0\n",
      "episode 880, reward 820.0, memory_length 2000, epsilon 0.012276112169078129 total_time 727.0\n",
      "Saving Model 880\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 881, reward 1118.0, memory_length 2000, epsilon 0.012214884804201888 total_time 725.0\n",
      "episode 882, reward 1034.0, memory_length 2000, epsilon 0.012153962812081944 total_time 722.0\n",
      "episode 883, reward 684.0, memory_length 2000, epsilon 0.01209334466966532 total_time 722.0\n",
      "episode 884, reward 1077.0, memory_length 2000, epsilon 0.012033028861495302 total_time 731.0\n",
      "episode 885, reward 739.0, memory_length 2000, epsilon 0.011973013879673542 total_time 729.0\n",
      "episode 886, reward 797.0, memory_length 2000, epsilon 0.011913298223822368 total_time 723.0\n",
      "episode 887, reward 1116.0, memory_length 2000, epsilon 0.011853880401047264 total_time 728.0\n",
      "episode 888, reward 765.0, memory_length 2000, epsilon 0.011794758925899587 total_time 725.0\n",
      "episode 889, reward 688.0, memory_length 2000, epsilon 0.011735932320339367 total_time 721.0\n",
      "episode 890, reward 1072.0, memory_length 2000, epsilon 0.011677399113698403 total_time 724.0\n",
      "Saving Model 890\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 891, reward 1117.0, memory_length 2000, epsilon 0.01161915784264348 total_time 721.0\n",
      "episode 892, reward 764.0, memory_length 2000, epsilon 0.011561207051139789 total_time 726.0\n",
      "episode 893, reward 610.0, memory_length 2000, epsilon 0.011503545290414523 total_time 722.0\n",
      "episode 894, reward 415.0, memory_length 2000, epsilon 0.01144617111892066 total_time 721.0\n",
      "episode 895, reward 593.0, memory_length 2000, epsilon 0.011389083102300916 total_time 726.0\n",
      "episode 896, reward 881.0, memory_length 2000, epsilon 0.011332279813351921 total_time 725.0\n",
      "episode 897, reward 958.0, memory_length 2000, epsilon 0.011275759831988483 total_time 726.0\n",
      "episode 898, reward 848.0, memory_length 2000, epsilon 0.011219521745208126 total_time 722.0\n",
      "episode 899, reward 515.0, memory_length 2000, epsilon 0.011163564147055747 total_time 721.0\n",
      "episode 900, reward 585.0, memory_length 2000, epsilon 0.011107885638588482 total_time 727.0\n",
      "Saving Model 900\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 901, reward 1198.0, memory_length 2000, epsilon 0.011052484827840717 total_time 723.0\n",
      "episode 902, reward 1258.0, memory_length 2000, epsilon 0.010997360329789301 total_time 722.0\n",
      "episode 903, reward 780.0, memory_length 2000, epsilon 0.010942510766318908 total_time 724.0\n",
      "episode 904, reward 698.0, memory_length 2000, epsilon 0.010887934766187586 total_time 728.0\n",
      "episode 905, reward 461.0, memory_length 2000, epsilon 0.010833630964992508 total_time 726.0\n",
      "episode 906, reward 1017.0, memory_length 2000, epsilon 0.01077959800513581 total_time 728.0\n",
      "episode 907, reward 1019.0, memory_length 2000, epsilon 0.010725834535790676 total_time 730.0\n",
      "episode 908, reward 761.0, memory_length 2000, epsilon 0.010672339212867574 total_time 732.0\n",
      "episode 909, reward 598.0, memory_length 2000, epsilon 0.010619110698980645 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 910, reward 1228.0, memory_length 2000, epsilon 0.01056614766341427 total_time 730.0\n",
      "Saving Model 910\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 911, reward 272.0, memory_length 2000, epsilon 0.0105134487820898 total_time 722.0\n",
      "episode 912, reward 832.0, memory_length 2000, epsilon 0.010461012737532452 total_time 729.0\n",
      "episode 913, reward 936.0, memory_length 2000, epsilon 0.010408838218838394 total_time 722.0\n",
      "episode 914, reward 804.0, memory_length 2000, epsilon 0.010356923921641935 total_time 726.0\n",
      "episode 915, reward 790.0, memory_length 2000, epsilon 0.010305268548082941 total_time 723.0\n",
      "episode 916, reward 584.0, memory_length 2000, epsilon 0.010253870806774382 total_time 728.0\n",
      "episode 917, reward 1075.0, memory_length 2000, epsilon 0.010202729412770048 total_time 728.0\n",
      "episode 918, reward 1023.0, memory_length 2000, epsilon 0.010151843087532426 total_time 730.0\n",
      "episode 919, reward 1080.0, memory_length 2000, epsilon 0.010101210558900736 total_time 729.0\n",
      "episode 920, reward 1130.0, memory_length 2000, epsilon 0.010050830561059113 total_time 724.0\n",
      "Saving Model 920\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 921, reward 1066.0, memory_length 2000, epsilon 0.010000701834505007 total_time 729.0\n",
      "episode 922, reward 609.0, memory_length 2000, epsilon 0.009950823126017635 total_time 724.0\n",
      "episode 923, reward 905.0, memory_length 2000, epsilon 0.009901193188626685 total_time 723.0\n",
      "episode 924, reward 1182.0, memory_length 2000, epsilon 0.009851810781581139 total_time 729.0\n",
      "episode 925, reward 1127.0, memory_length 2000, epsilon 0.009802674670318246 total_time 727.0\n",
      "episode 926, reward 684.0, memory_length 2000, epsilon 0.00975378362643267 total_time 723.0\n",
      "episode 927, reward 1230.0, memory_length 2000, epsilon 0.009705136427645764 total_time 727.0\n",
      "episode 928, reward 778.0, memory_length 2000, epsilon 0.009656731857775023 total_time 724.0\n",
      "episode 929, reward 754.0, memory_length 2000, epsilon 0.009608568706703676 total_time 725.0\n",
      "episode 930, reward 969.0, memory_length 2000, epsilon 0.00956064577035045 total_time 723.0\n",
      "Saving Model 930\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 931, reward 1048.0, memory_length 2000, epsilon 0.009512961850639434 total_time 721.0\n",
      "episode 932, reward 662.0, memory_length 2000, epsilon 0.009465515755470152 total_time 724.0\n",
      "episode 933, reward 538.0, memory_length 2000, epsilon 0.009418306298687751 total_time 721.0\n",
      "episode 934, reward 965.0, memory_length 2000, epsilon 0.009371332300053357 total_time 723.0\n",
      "episode 935, reward 1012.0, memory_length 2000, epsilon 0.009324592585214554 total_time 726.0\n",
      "episode 936, reward 1063.0, memory_length 2000, epsilon 0.009278085985676037 total_time 724.0\n",
      "episode 937, reward 873.0, memory_length 2000, epsilon 0.009231811338770388 total_time 726.0\n",
      "episode 938, reward 864.0, memory_length 2000, epsilon 0.00918576748762904 total_time 728.0\n",
      "episode 939, reward 925.0, memory_length 2000, epsilon 0.009139953281153308 total_time 723.0\n",
      "episode 940, reward 741.0, memory_length 2000, epsilon 0.009094367573985646 total_time 727.0\n",
      "Saving Model 940\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 941, reward 739.0, memory_length 2000, epsilon 0.009049009226480999 total_time 721.0\n",
      "episode 942, reward 726.0, memory_length 2000, epsilon 0.009003877104678315 total_time 723.0\n",
      "episode 943, reward 1283.0, memory_length 2000, epsilon 0.008958970080272202 total_time 721.0\n",
      "episode 944, reward 816.0, memory_length 2000, epsilon 0.00891428703058471 total_time 728.0\n",
      "episode 945, reward 1265.0, memory_length 2000, epsilon 0.008869826838537258 total_time 733.0\n",
      "episode 946, reward 953.0, memory_length 2000, epsilon 0.00882558839262275 total_time 721.0\n",
      "episode 947, reward 776.0, memory_length 2000, epsilon 0.008781570586877724 total_time 726.0\n",
      "episode 948, reward 1032.0, memory_length 2000, epsilon 0.008737772320854743 total_time 721.0\n",
      "episode 949, reward 964.0, memory_length 2000, epsilon 0.008694192499594876 total_time 726.0\n",
      "episode 950, reward 926.0, memory_length 2000, epsilon 0.008650830033600322 total_time 724.0\n",
      "Saving Model 950\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 951, reward 953.0, memory_length 2000, epsilon 0.008607683838807173 total_time 722.0\n",
      "episode 952, reward 953.0, memory_length 2000, epsilon 0.00856475283655831 total_time 729.0\n",
      "episode 953, reward 898.0, memory_length 2000, epsilon 0.008522035953576444 total_time 723.0\n",
      "episode 954, reward 636.0, memory_length 2000, epsilon 0.008479532121937264 total_time 729.0\n",
      "episode 955, reward 907.0, memory_length 2000, epsilon 0.008437240279042786 total_time 727.0\n",
      "episode 956, reward 780.0, memory_length 2000, epsilon 0.008395159367594721 total_time 721.0\n",
      "episode 957, reward 964.0, memory_length 2000, epsilon 0.008353288335568096 total_time 721.0\n",
      "episode 958, reward 1153.0, memory_length 2000, epsilon 0.008311626136184927 total_time 727.0\n",
      "episode 959, reward 1024.0, memory_length 2000, epsilon 0.008270171727888059 total_time 726.0\n",
      "episode 960, reward 546.0, memory_length 2000, epsilon 0.008228924074315129 total_time 729.0\n",
      "Saving Model 960\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 961, reward 575.0, memory_length 2000, epsilon 0.008187882144272646 total_time 730.0\n",
      "episode 962, reward 875.0, memory_length 2000, epsilon 0.008147044911710213 total_time 729.0\n",
      "episode 963, reward 1123.0, memory_length 2000, epsilon 0.008106411355694908 total_time 721.0\n",
      "episode 964, reward 1013.0, memory_length 2000, epsilon 0.008065980460385704 total_time 726.0\n",
      "episode 965, reward 977.0, memory_length 2000, epsilon 0.008025751215008115 total_time 726.0\n",
      "episode 966, reward 774.0, memory_length 2000, epsilon 0.007985722613828907 total_time 722.0\n",
      "episode 967, reward 758.0, memory_length 2000, epsilon 0.007945893656130968 total_time 726.0\n",
      "episode 968, reward 630.0, memory_length 2000, epsilon 0.007906263346188283 total_time 725.0\n",
      "episode 969, reward 1037.0, memory_length 2000, epsilon 0.007866830693241036 total_time 731.0\n",
      "episode 970, reward 1335.0, memory_length 2000, epsilon 0.007827594711470844 total_time 722.0\n",
      "Saving Model 970\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 971, reward 696.0, memory_length 2000, epsilon 0.007788554419976135 total_time 728.0\n",
      "episode 972, reward 843.0, memory_length 2000, epsilon 0.0077497088427475784 total_time 727.0\n",
      "episode 973, reward 700.0, memory_length 2000, epsilon 0.007711057008643722 total_time 721.0\n",
      "episode 974, reward 472.0, memory_length 2000, epsilon 0.0076725979513667 total_time 726.0\n",
      "episode 975, reward 788.0, memory_length 2000, epsilon 0.007634330709438076 total_time 728.0\n",
      "episode 976, reward 1017.0, memory_length 2000, epsilon 0.00759625432617481 total_time 721.0\n",
      "episode 977, reward 781.0, memory_length 2000, epsilon 0.007558367849665337 total_time 727.0\n",
      "episode 978, reward 908.0, memory_length 2000, epsilon 0.007520670332745771 total_time 726.0\n",
      "episode 979, reward 977.0, memory_length 2000, epsilon 0.007483160832976218 total_time 723.0\n",
      "episode 980, reward 1001.0, memory_length 2000, epsilon 0.007445838412617246 total_time 729.0\n",
      "Saving Model 980\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 981, reward 704.0, memory_length 2000, epsilon 0.0074087021386063925 total_time 738.0\n",
      "episode 982, reward 695.0, memory_length 2000, epsilon 0.007371751082534875 total_time 725.0\n",
      "episode 983, reward 594.0, memory_length 2000, epsilon 0.007334984320624367 total_time 722.0\n",
      "episode 984, reward 579.0, memory_length 2000, epsilon 0.007298400933703904 total_time 730.0\n",
      "episode 985, reward 1002.0, memory_length 2000, epsilon 0.00726200000718691 total_time 721.0\n",
      "episode 986, reward 607.0, memory_length 2000, epsilon 0.007225780631048325 total_time 724.0\n",
      "episode 987, reward 940.0, memory_length 2000, epsilon 0.007189741899801852 total_time 723.0\n",
      "episode 988, reward 575.0, memory_length 2000, epsilon 0.0071538829124773474 total_time 721.0\n",
      "episode 989, reward 835.0, memory_length 2000, epsilon 0.007118202772598253 total_time 725.0\n",
      "episode 990, reward 915.0, memory_length 2000, epsilon 0.007082700588159213 total_time 724.0\n",
      "Saving Model 990\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 991, reward 1001.0, memory_length 2000, epsilon 0.007047375471603769 total_time 723.0\n",
      "episode 992, reward 1195.0, memory_length 2000, epsilon 0.007012226539802166 total_time 722.0\n",
      "episode 993, reward 1229.0, memory_length 2000, epsilon 0.006977252914029277 total_time 727.0\n",
      "episode 994, reward 822.0, memory_length 2000, epsilon 0.00694245371994264 total_time 724.0\n",
      "episode 995, reward 1110.0, memory_length 2000, epsilon 0.00690782808756058 total_time 721.0\n",
      "episode 996, reward 1195.0, memory_length 2000, epsilon 0.006873375151240499 total_time 721.0\n",
      "episode 997, reward 702.0, memory_length 2000, epsilon 0.006839094049657187 total_time 727.0\n",
      "episode 998, reward 630.0, memory_length 2000, epsilon 0.00680498392578132 total_time 726.0\n",
      "episode 999, reward 618.0, memory_length 2000, epsilon 0.006771043926858024 total_time 731.0\n",
      "episode 1000, reward 1003.0, memory_length 2000, epsilon 0.006737273204385558 total_time 722.0\n",
      "Saving Model 1000\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1001, reward 886.0, memory_length 2000, epsilon 0.006703670914094103 total_time 726.0\n",
      "episode 1002, reward 1413.0, memory_length 2000, epsilon 0.006670236215924648 total_time 724.0\n",
      "episode 1003, reward 1114.0, memory_length 2000, epsilon 0.006636968274008001 total_time 737.0\n",
      "episode 1004, reward 1149.0, memory_length 2000, epsilon 0.006603866256643874 total_time 726.0\n",
      "episode 1005, reward 557.0, memory_length 2000, epsilon 0.00657092933628012 total_time 730.0\n",
      "episode 1006, reward 761.0, memory_length 2000, epsilon 0.0065381566894920085 total_time 724.0\n",
      "episode 1007, reward 956.0, memory_length 2000, epsilon 0.006505547496961665 total_time 724.0\n",
      "episode 1008, reward 703.0, memory_length 2000, epsilon 0.006473100943457576 total_time 724.0\n",
      "episode 1009, reward 831.0, memory_length 2000, epsilon 0.006440816217814214 total_time 728.0\n",
      "episode 1010, reward 779.0, memory_length 2000, epsilon 0.006408692512911758 total_time 721.0\n",
      "Saving Model 1010\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1011, reward 951.0, memory_length 2000, epsilon 0.006376729025655909 total_time 721.0\n",
      "episode 1012, reward 885.0, memory_length 2000, epsilon 0.0063449249569578195 total_time 727.0\n",
      "episode 1013, reward 853.0, memory_length 2000, epsilon 0.006313279511714124 total_time 723.0\n",
      "episode 1014, reward 863.0, memory_length 2000, epsilon 0.006281791898787038 total_time 731.0\n",
      "episode 1015, reward 1316.0, memory_length 2000, epsilon 0.006250461330984599 total_time 725.0\n",
      "episode 1016, reward 479.0, memory_length 2000, epsilon 0.006219287025040978 total_time 723.0\n",
      "episode 1017, reward 1038.0, memory_length 2000, epsilon 0.006188268201596906 total_time 734.0\n",
      "episode 1018, reward 939.0, memory_length 2000, epsilon 0.006157404085180181 total_time 721.0\n",
      "episode 1019, reward 633.0, memory_length 2000, epsilon 0.006126693904186281 total_time 721.0\n",
      "episode 1020, reward 567.0, memory_length 2000, epsilon 0.006096136890859081 total_time 729.0\n",
      "Saving Model 1020\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1021, reward 722.0, memory_length 2000, epsilon 0.006065732281271666 total_time 726.0\n",
      "episode 1022, reward 920.0, memory_length 2000, epsilon 0.006035479315307205 total_time 728.0\n",
      "episode 1023, reward 762.0, memory_length 2000, epsilon 0.006005377236639975 total_time 723.0\n",
      "episode 1024, reward 552.0, memory_length 2000, epsilon 0.005975425292716443 total_time 725.0\n",
      "episode 1025, reward 1084.0, memory_length 2000, epsilon 0.005945622734736447 total_time 724.0\n",
      "episode 1026, reward 676.0, memory_length 2000, epsilon 0.005915968817634489 total_time 724.0\n",
      "episode 1027, reward 727.0, memory_length 2000, epsilon 0.005886462800061094 total_time 730.0\n",
      "episode 1028, reward 1017.0, memory_length 2000, epsilon 0.005857103944364289 total_time 724.0\n",
      "episode 1029, reward 717.0, memory_length 2000, epsilon 0.005827891516571145 total_time 724.0\n",
      "episode 1030, reward 625.0, memory_length 2000, epsilon 0.0057988247863694576 total_time 731.0\n",
      "Saving Model 1030\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1031, reward 781.0, memory_length 2000, epsilon 0.005769903027089451 total_time 724.0\n",
      "episode 1032, reward 875.0, memory_length 2000, epsilon 0.005741125515685637 total_time 721.0\n",
      "episode 1033, reward 471.0, memory_length 2000, epsilon 0.005712491532718733 total_time 723.0\n",
      "episode 1034, reward 483.0, memory_length 2000, epsilon 0.005684000362337673 total_time 721.0\n",
      "episode 1035, reward 575.0, memory_length 2000, epsilon 0.0056556512922617125 total_time 733.0\n",
      "episode 1036, reward 678.0, memory_length 2000, epsilon 0.005627443613762625 total_time 722.0\n",
      "episode 1037, reward 648.0, memory_length 2000, epsilon 0.005599376621646973 total_time 721.0\n",
      "episode 1038, reward 753.0, memory_length 2000, epsilon 0.0055714496142385 total_time 727.0\n",
      "episode 1039, reward 881.0, memory_length 2000, epsilon 0.005543661893360564 total_time 722.0\n",
      "episode 1040, reward 755.0, memory_length 2000, epsilon 0.005516012764318696 total_time 721.0\n",
      "Saving Model 1040\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1041, reward 487.0, memory_length 2000, epsilon 0.0054885015358832265 total_time 726.0\n",
      "episode 1042, reward 932.0, memory_length 2000, epsilon 0.005461127520272014 total_time 724.0\n",
      "episode 1043, reward 650.0, memory_length 2000, epsilon 0.005433890033133243 total_time 722.0\n",
      "episode 1044, reward 785.0, memory_length 2000, epsilon 0.005406788393528316 total_time 721.0\n",
      "episode 1045, reward 1019.0, memory_length 2000, epsilon 0.005379821923914825 total_time 729.0\n",
      "episode 1046, reward 736.0, memory_length 2000, epsilon 0.005352989950129637 total_time 722.0\n",
      "episode 1047, reward 1082.0, memory_length 2000, epsilon 0.005326291801372003 total_time 726.0\n",
      "episode 1048, reward 304.0, memory_length 2000, epsilon 0.0052997268101868155 total_time 731.0\n",
      "episode 1049, reward 1328.0, memory_length 2000, epsilon 0.005273294312447909 total_time 723.0\n",
      "episode 1050, reward 990.0, memory_length 2000, epsilon 0.005246993647341466 total_time 722.0\n",
      "Saving Model 1050\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1051, reward 1079.0, memory_length 2000, epsilon 0.005220824157349487 total_time 722.0\n",
      "episode 1052, reward 743.0, memory_length 2000, epsilon 0.005194785188233361 total_time 723.0\n",
      "episode 1053, reward 913.0, memory_length 2000, epsilon 0.005168876089017502 total_time 722.0\n",
      "episode 1054, reward 1090.0, memory_length 2000, epsilon 0.005143096211973076 total_time 725.0\n",
      "episode 1055, reward 723.0, memory_length 2000, epsilon 0.0051174449126018245 total_time 725.0\n",
      "episode 1056, reward 682.0, memory_length 2000, epsilon 0.005091921549619921 total_time 723.0\n",
      "episode 1057, reward 1021.0, memory_length 2000, epsilon 0.005066525484941962 total_time 721.0\n",
      "episode 1058, reward 900.0, memory_length 2000, epsilon 0.00504125608366501 total_time 725.0\n",
      "episode 1059, reward 797.0, memory_length 2000, epsilon 0.005016112714052714 total_time 721.0\n",
      "episode 1060, reward 845.0, memory_length 2000, epsilon 0.004991094747519526 total_time 726.0\n",
      "Saving Model 1060\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1061, reward 1190.0, memory_length 2000, epsilon 0.004966201558614979 total_time 730.0\n",
      "episode 1062, reward 1024.0, memory_length 2000, epsilon 0.00494143252500805 total_time 723.0\n",
      "episode 1063, reward 984.0, memory_length 2000, epsilon 0.004916787027471616 total_time 721.0\n",
      "episode 1064, reward 1316.0, memory_length 2000, epsilon 0.004892264449866952 total_time 737.0\n",
      "episode 1065, reward 1181.0, memory_length 2000, epsilon 0.00486786417912834 total_time 726.0\n",
      "episode 1066, reward 951.0, memory_length 2000, epsilon 0.004843585605247743 total_time 723.0\n",
      "episode 1067, reward 847.0, memory_length 2000, epsilon 0.004819428121259545 total_time 723.0\n",
      "episode 1068, reward 768.0, memory_length 2000, epsilon 0.004795391123225392 total_time 722.0\n",
      "episode 1069, reward 475.0, memory_length 2000, epsilon 0.0047714740102190786 total_time 721.0\n",
      "episode 1070, reward 141.0, memory_length 2000, epsilon 0.004747676184311532 total_time 723.0\n",
      "Saving Model 1070\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1071, reward 958.0, memory_length 2000, epsilon 0.004723997050555873 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1072, reward 428.0, memory_length 2000, epsilon 0.004700436016972518 total_time 722.0\n",
      "episode 1073, reward 733.0, memory_length 2000, epsilon 0.004676992494534403 total_time 727.0\n",
      "episode 1074, reward 346.0, memory_length 2000, epsilon 0.0046536658971522435 total_time 721.0\n",
      "episode 1075, reward 1033.0, memory_length 2000, epsilon 0.004630455641659892 total_time 730.0\n",
      "episode 1076, reward 955.0, memory_length 2000, epsilon 0.004607361147799752 total_time 725.0\n",
      "episode 1077, reward 677.0, memory_length 2000, epsilon 0.004584381838208275 total_time 722.0\n",
      "episode 1078, reward 728.0, memory_length 2000, epsilon 0.004561517138401523 total_time 721.0\n",
      "episode 1079, reward 362.0, memory_length 2000, epsilon 0.004538766476760805 total_time 722.0\n",
      "episode 1080, reward 753.0, memory_length 2000, epsilon 0.004516129284518404 total_time 726.0\n",
      "Saving Model 1080\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1081, reward 901.0, memory_length 2000, epsilon 0.004493604995743333 total_time 727.0\n",
      "episode 1082, reward 804.0, memory_length 2000, epsilon 0.004471193047327197 total_time 723.0\n",
      "episode 1083, reward 1087.0, memory_length 2000, epsilon 0.004448892878970119 total_time 721.0\n",
      "episode 1084, reward 958.0, memory_length 2000, epsilon 0.0044267039331667285 total_time 724.0\n",
      "episode 1085, reward 888.0, memory_length 2000, epsilon 0.004404625655192226 total_time 722.0\n",
      "episode 1086, reward 515.0, memory_length 2000, epsilon 0.004382657493088509 total_time 727.0\n",
      "episode 1087, reward 651.0, memory_length 2000, epsilon 0.00436079889765038 total_time 724.0\n",
      "episode 1088, reward 580.0, memory_length 2000, epsilon 0.0043390493224118205 total_time 728.0\n",
      "episode 1089, reward 937.0, memory_length 2000, epsilon 0.004317408223632315 total_time 729.0\n",
      "episode 1090, reward 506.0, memory_length 2000, epsilon 0.004295875060283265 total_time 721.0\n",
      "Saving Model 1090\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1091, reward 779.0, memory_length 2000, epsilon 0.004274449294034465 total_time 725.0\n",
      "episode 1092, reward 827.0, memory_length 2000, epsilon 0.004253130389240644 total_time 722.0\n",
      "episode 1093, reward 1111.0, memory_length 2000, epsilon 0.004231917812928072 total_time 726.0\n",
      "episode 1094, reward 592.0, memory_length 2000, epsilon 0.004210811034781235 total_time 722.0\n",
      "episode 1095, reward 1014.0, memory_length 2000, epsilon 0.004189809527129578 total_time 728.0\n",
      "episode 1096, reward 900.0, memory_length 2000, epsilon 0.004168912764934321 total_time 726.0\n",
      "episode 1097, reward 937.0, memory_length 2000, epsilon 0.004148120225775319 total_time 731.0\n",
      "episode 1098, reward 450.0, memory_length 2000, epsilon 0.004127431389838011 total_time 726.0\n",
      "episode 1099, reward 908.0, memory_length 2000, epsilon 0.004106845739900418 total_time 725.0\n",
      "episode 1100, reward 756.0, memory_length 2000, epsilon 0.00408636276132022 total_time 722.0\n",
      "Saving Model 1100\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1101, reward 960.0, memory_length 2000, epsilon 0.004065981942021888 total_time 727.0\n",
      "episode 1102, reward 972.0, memory_length 2000, epsilon 0.004045702772483877 total_time 732.0\n",
      "episode 1103, reward 863.0, memory_length 2000, epsilon 0.004025524745725892 total_time 723.0\n",
      "episode 1104, reward 725.0, memory_length 2000, epsilon 0.004005447357296208 total_time 726.0\n",
      "episode 1105, reward 973.0, memory_length 2000, epsilon 0.003985470105259078 total_time 721.0\n",
      "episode 1106, reward 744.0, memory_length 2000, epsilon 0.003965592490182156 total_time 724.0\n",
      "episode 1107, reward 1154.0, memory_length 2000, epsilon 0.00394581401512403 total_time 726.0\n",
      "episode 1108, reward 900.0, memory_length 2000, epsilon 0.0039261341856217935 total_time 735.0\n",
      "episode 1109, reward 649.0, memory_length 2000, epsilon 0.003906552509678684 total_time 723.0\n",
      "episode 1110, reward 1122.0, memory_length 2000, epsilon 0.0038870684977517825 total_time 722.0\n",
      "Saving Model 1110\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1111, reward 707.0, memory_length 2000, epsilon 0.0038676816627397767 total_time 721.0\n",
      "episode 1112, reward 620.0, memory_length 2000, epsilon 0.0038483915199707783 total_time 726.0\n",
      "episode 1113, reward 1013.0, memory_length 2000, epsilon 0.0038291975871902195 total_time 724.0\n",
      "episode 1114, reward 706.0, memory_length 2000, epsilon 0.0038100993845487778 total_time 725.0\n",
      "episode 1115, reward 849.0, memory_length 2000, epsilon 0.003791096434590393 total_time 727.0\n",
      "episode 1116, reward 957.0, memory_length 2000, epsilon 0.003772188262240326 total_time 724.0\n",
      "episode 1117, reward 824.0, memory_length 2000, epsilon 0.0037533743947932834 total_time 723.0\n",
      "episode 1118, reward 1015.0, memory_length 2000, epsilon 0.0037346543619015985 total_time 730.0\n",
      "episode 1119, reward 909.0, memory_length 2000, epsilon 0.003716027695563475 total_time 726.0\n",
      "episode 1120, reward 1070.0, memory_length 2000, epsilon 0.0036974939301112806 total_time 722.0\n",
      "Saving Model 1120\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1121, reward 940.0, memory_length 2000, epsilon 0.00367905260219992 total_time 722.0\n",
      "episode 1122, reward 1032.0, memory_length 2000, epsilon 0.003660703250795232 total_time 733.0\n",
      "episode 1123, reward 346.0, memory_length 2000, epsilon 0.003642445417162476 total_time 725.0\n",
      "episode 1124, reward 997.0, memory_length 2000, epsilon 0.003624278644854859 total_time 725.0\n",
      "episode 1125, reward 916.0, memory_length 2000, epsilon 0.003606202479702129 total_time 723.0\n",
      "episode 1126, reward 573.0, memory_length 2000, epsilon 0.0035882164697992147 total_time 727.0\n",
      "episode 1127, reward 529.0, memory_length 2000, epsilon 0.0035703201654949312 total_time 721.0\n",
      "episode 1128, reward 892.0, memory_length 2000, epsilon 0.00355251311938074 total_time 722.0\n",
      "episode 1129, reward 592.0, memory_length 2000, epsilon 0.0035347948862795566 total_time 726.0\n",
      "episode 1130, reward 882.0, memory_length 2000, epsilon 0.0035171650232346374 total_time 723.0\n",
      "Saving Model 1130\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1131, reward 1049.0, memory_length 2000, epsilon 0.003499623089498485 total_time 725.0\n",
      "episode 1132, reward 1008.0, memory_length 2000, epsilon 0.003482168646521842 total_time 721.0\n",
      "episode 1133, reward 903.0, memory_length 2000, epsilon 0.0034648012579427258 total_time 723.0\n",
      "episode 1134, reward 807.0, memory_length 2000, epsilon 0.0034475204895755163 total_time 729.0\n",
      "episode 1135, reward 816.0, memory_length 2000, epsilon 0.003430325909400105 total_time 725.0\n",
      "episode 1136, reward 270.0, memory_length 2000, epsilon 0.003413217087551091 total_time 726.0\n",
      "episode 1137, reward 665.0, memory_length 2000, epsilon 0.003396193596307035 total_time 725.0\n",
      "episode 1138, reward 426.0, memory_length 2000, epsilon 0.003379255010079775 total_time 726.0\n",
      "episode 1139, reward 584.0, memory_length 2000, epsilon 0.00336240090540377 total_time 723.0\n",
      "episode 1140, reward 706.0, memory_length 2000, epsilon 0.003345630860925525 total_time 729.0\n",
      "Saving Model 1140\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1141, reward 558.0, memory_length 2000, epsilon 0.003328944457393055 total_time 730.0\n",
      "episode 1142, reward 574.0, memory_length 2000, epsilon 0.0033123412776454027 total_time 724.0\n",
      "episode 1143, reward 930.0, memory_length 2000, epsilon 0.0032958209066022096 total_time 721.0\n",
      "episode 1144, reward 806.0, memory_length 2000, epsilon 0.0032793829312533387 total_time 722.0\n",
      "episode 1145, reward 1033.0, memory_length 2000, epsilon 0.003263026940648548 total_time 721.0\n",
      "episode 1146, reward 753.0, memory_length 2000, epsilon 0.003246752525887225 total_time 727.0\n",
      "episode 1147, reward 712.0, memory_length 2000, epsilon 0.0032305592801081516 total_time 726.0\n",
      "episode 1148, reward 1015.0, memory_length 2000, epsilon 0.003214446798479339 total_time 721.0\n",
      "episode 1149, reward 811.0, memory_length 2000, epsilon 0.0031984146781879083 total_time 725.0\n",
      "episode 1150, reward 967.0, memory_length 2000, epsilon 0.003182462518430016 total_time 722.0\n",
      "Saving Model 1150\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1151, reward 913.0, memory_length 2000, epsilon 0.003166589920400838 total_time 722.0\n",
      "episode 1152, reward 695.0, memory_length 2000, epsilon 0.003150796487284597 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1153, reward 525.0, memory_length 2000, epsilon 0.003135081824244642 total_time 731.0\n",
      "episode 1154, reward 903.0, memory_length 2000, epsilon 0.0031194455384135756 total_time 729.0\n",
      "episode 1155, reward 661.0, memory_length 2000, epsilon 0.003103887238883444 total_time 723.0\n",
      "episode 1156, reward 796.0, memory_length 2000, epsilon 0.003088406536695945 total_time 726.0\n",
      "episode 1157, reward 1032.0, memory_length 2000, epsilon 0.0030730030448327186 total_time 723.0\n",
      "episode 1158, reward 658.0, memory_length 2000, epsilon 0.003057676378205665 total_time 725.0\n",
      "episode 1159, reward 720.0, memory_length 2000, epsilon 0.003042426153647321 total_time 721.0\n",
      "episode 1160, reward 619.0, memory_length 2000, epsilon 0.0030272519899012776 total_time 723.0\n",
      "Saving Model 1160\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1161, reward 803.0, memory_length 2000, epsilon 0.0030121535076126516 total_time 736.0\n",
      "episode 1162, reward 1152.0, memory_length 2000, epsilon 0.002997130329318596 total_time 721.0\n",
      "episode 1163, reward 1154.0, memory_length 2000, epsilon 0.002982182079438877 total_time 723.0\n",
      "episode 1164, reward 1076.0, memory_length 2000, epsilon 0.002967308384266466 total_time 725.0\n",
      "episode 1165, reward 642.0, memory_length 2000, epsilon 0.002952508871958209 total_time 732.0\n",
      "episode 1166, reward 1109.0, memory_length 2000, epsilon 0.002937783172525528 total_time 721.0\n",
      "episode 1167, reward 871.0, memory_length 2000, epsilon 0.0029231309178251695 total_time 729.0\n",
      "episode 1168, reward 1020.0, memory_length 2000, epsilon 0.002908551741550003 total_time 723.0\n",
      "episode 1169, reward 875.0, memory_length 2000, epsilon 0.0028940452792198625 total_time 726.0\n",
      "episode 1170, reward 830.0, memory_length 2000, epsilon 0.0028796111681724315 total_time 721.0\n",
      "Saving Model 1170\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1171, reward 1084.0, memory_length 2000, epsilon 0.002865249047554188 total_time 727.0\n",
      "episode 1172, reward 1206.0, memory_length 2000, epsilon 0.0028509585583113644 total_time 724.0\n",
      "episode 1173, reward 877.0, memory_length 2000, epsilon 0.0028367393431809862 total_time 722.0\n",
      "episode 1174, reward 745.0, memory_length 2000, epsilon 0.002822591046681935 total_time 728.0\n",
      "episode 1175, reward 1026.0, memory_length 2000, epsilon 0.00280851331510606 total_time 723.0\n",
      "episode 1176, reward 747.0, memory_length 2000, epsilon 0.00279450579650934 total_time 722.0\n",
      "episode 1177, reward 1200.0, memory_length 2000, epsilon 0.0027805681407030805 total_time 731.0\n",
      "episode 1178, reward 1028.0, memory_length 2000, epsilon 0.0027666999992451593 total_time 728.0\n",
      "episode 1179, reward 722.0, memory_length 2000, epsilon 0.002752901025431316 total_time 721.0\n",
      "episode 1180, reward 1118.0, memory_length 2000, epsilon 0.0027391708742864917 total_time 727.0\n",
      "Saving Model 1180\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1181, reward 885.0, memory_length 2000, epsilon 0.0027255092025561894 total_time 730.0\n",
      "episode 1182, reward 1153.0, memory_length 2000, epsilon 0.002711915668697905 total_time 729.0\n",
      "episode 1183, reward 773.0, memory_length 2000, epsilon 0.0026983899328725833 total_time 723.0\n",
      "episode 1184, reward 826.0, memory_length 2000, epsilon 0.002684931656936125 total_time 727.0\n",
      "episode 1185, reward 335.0, memory_length 2000, epsilon 0.0026715405044309306 total_time 724.0\n",
      "episode 1186, reward 785.0, memory_length 2000, epsilon 0.0026582161405774895 total_time 724.0\n",
      "episode 1187, reward 858.0, memory_length 2000, epsilon 0.0026449582322660096 total_time 728.0\n",
      "episode 1188, reward 912.0, memory_length 2000, epsilon 0.002631766448048097 total_time 725.0\n",
      "episode 1189, reward 997.0, memory_length 2000, epsilon 0.0026186404581284564 total_time 722.0\n",
      "episode 1190, reward 977.0, memory_length 2000, epsilon 0.0026055799343566574 total_time 721.0\n",
      "Saving Model 1190\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1191, reward 1316.0, memory_length 2000, epsilon 0.0025925845502189244 total_time 724.0\n",
      "episode 1192, reward 491.0, memory_length 2000, epsilon 0.0025796539808299775 total_time 722.0\n",
      "episode 1193, reward 432.0, memory_length 2000, epsilon 0.002566787902924908 total_time 733.0\n",
      "episode 1194, reward 643.0, memory_length 2000, epsilon 0.002553985994851099 total_time 724.0\n",
      "episode 1195, reward 1410.0, memory_length 2000, epsilon 0.002541247936560179 total_time 722.0\n",
      "episode 1196, reward 508.0, memory_length 2000, epsilon 0.002528573409600033 total_time 731.0\n",
      "episode 1197, reward 697.0, memory_length 2000, epsilon 0.0025159620971068226 total_time 724.0\n",
      "episode 1198, reward 952.0, memory_length 2000, epsilon 0.0025034136837970796 total_time 731.0\n",
      "episode 1199, reward 870.0, memory_length 2000, epsilon 0.002490927855959818 total_time 723.0\n",
      "episode 1200, reward 728.0, memory_length 2000, epsilon 0.002478504301448692 total_time 727.0\n",
      "Saving Model 1200\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1201, reward 1021.0, memory_length 2000, epsilon 0.0024661427096741902 total_time 726.0\n",
      "episode 1202, reward 480.0, memory_length 2000, epsilon 0.0024538427715958756 total_time 728.0\n",
      "episode 1203, reward 836.0, memory_length 2000, epsilon 0.0024416041797146533 total_time 725.0\n",
      "episode 1204, reward 864.0, memory_length 2000, epsilon 0.0024294266280650927 total_time 732.0\n",
      "episode 1205, reward 764.0, memory_length 2000, epsilon 0.002417309812207767 total_time 721.0\n",
      "episode 1206, reward 1052.0, memory_length 2000, epsilon 0.002405253429221648 total_time 723.0\n",
      "episode 1207, reward 848.0, memory_length 2000, epsilon 0.002393257177696533 total_time 723.0\n",
      "episode 1208, reward 1118.0, memory_length 2000, epsilon 0.002381320757725509 total_time 729.0\n",
      "episode 1209, reward 567.0, memory_length 2000, epsilon 0.002369443870897456 total_time 721.0\n",
      "episode 1210, reward 543.0, memory_length 2000, epsilon 0.0023576262202895837 total_time 725.0\n",
      "Saving Model 1210\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1211, reward 910.0, memory_length 2000, epsilon 0.002345867510460012 total_time 725.0\n",
      "episode 1212, reward 703.0, memory_length 2000, epsilon 0.00233416744744038 total_time 721.0\n",
      "episode 1213, reward 1060.0, memory_length 2000, epsilon 0.002322525738728508 total_time 722.0\n",
      "episode 1214, reward 958.0, memory_length 2000, epsilon 0.002310942093281069 total_time 726.0\n",
      "episode 1215, reward 470.0, memory_length 2000, epsilon 0.0022994162215063236 total_time 727.0\n",
      "episode 1216, reward 790.0, memory_length 2000, epsilon 0.002287947835256877 total_time 724.0\n",
      "episode 1217, reward 838.0, memory_length 2000, epsilon 0.0022765366478224762 total_time 726.0\n",
      "episode 1218, reward 637.0, memory_length 2000, epsilon 0.0022651823739228407 total_time 723.0\n",
      "episode 1219, reward 1065.0, memory_length 2000, epsilon 0.0022538847297005316 total_time 724.0\n",
      "episode 1220, reward 937.0, memory_length 2000, epsilon 0.0022426434327138525 total_time 725.0\n",
      "Saving Model 1220\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1221, reward 558.0, memory_length 2000, epsilon 0.0022314582019297984 total_time 729.0\n",
      "episode 1222, reward 958.0, memory_length 2000, epsilon 0.0022203287577170143 total_time 727.0\n",
      "episode 1223, reward 1078.0, memory_length 2000, epsilon 0.002209254821838815 total_time 727.0\n",
      "episode 1224, reward 555.0, memory_length 2000, epsilon 0.002198236117446227 total_time 727.0\n",
      "episode 1225, reward 715.0, memory_length 2000, epsilon 0.0021872723690710668 total_time 722.0\n",
      "episode 1226, reward 1185.0, memory_length 2000, epsilon 0.002176363302619054 total_time 727.0\n",
      "episode 1227, reward 934.0, memory_length 2000, epsilon 0.002165508645362959 total_time 721.0\n",
      "episode 1228, reward 736.0, memory_length 2000, epsilon 0.0021547081259357835 total_time 721.0\n",
      "episode 1229, reward 788.0, memory_length 2000, epsilon 0.0021439614743239827 total_time 726.0\n",
      "episode 1230, reward 1058.0, memory_length 2000, epsilon 0.002133268421860704 total_time 722.0\n",
      "Saving Model 1230\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1231, reward 1322.0, memory_length 2000, epsilon 0.0021226287012190803 total_time 726.0\n",
      "episode 1232, reward 944.0, memory_length 2000, epsilon 0.002112042046405541 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1233, reward 833.0, memory_length 2000, epsilon 0.002101508192753164 total_time 723.0\n",
      "episode 1234, reward 788.0, memory_length 2000, epsilon 0.002091026876915059 total_time 722.0\n",
      "episode 1235, reward 994.0, memory_length 2000, epsilon 0.0020805978368577845 total_time 723.0\n",
      "episode 1236, reward 949.0, memory_length 2000, epsilon 0.0020702208118547967 total_time 724.0\n",
      "episode 1237, reward 499.0, memory_length 2000, epsilon 0.0020598955424799273 total_time 728.0\n",
      "episode 1238, reward 333.0, memory_length 2000, epsilon 0.0020496217706009075 total_time 723.0\n",
      "episode 1239, reward 296.0, memory_length 2000, epsilon 0.0020393992393729046 total_time 723.0\n",
      "episode 1240, reward 276.0, memory_length 2000, epsilon 0.0020292276932321043 total_time 722.0\n",
      "Saving Model 1240\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1241, reward 517.0, memory_length 2000, epsilon 0.0020191068778893243 total_time 721.0\n",
      "episode 1242, reward 688.0, memory_length 2000, epsilon 0.002009036540323653 total_time 722.0\n",
      "episode 1243, reward 604.0, memory_length 2000, epsilon 0.0019990164287761276 total_time 724.0\n",
      "episode 1244, reward 580.0, memory_length 2000, epsilon 0.001989046292743437 total_time 723.0\n",
      "episode 1245, reward 980.0, memory_length 2000, epsilon 0.0019791258829716597 total_time 726.0\n",
      "episode 1246, reward 985.0, memory_length 2000, epsilon 0.0019692549514500374 total_time 725.0\n",
      "episode 1247, reward 757.0, memory_length 2000, epsilon 0.0019594332514047677 total_time 725.0\n",
      "episode 1248, reward 743.0, memory_length 2000, epsilon 0.001949660537292836 total_time 732.0\n",
      "episode 1249, reward 894.0, memory_length 2000, epsilon 0.0019399365647958821 total_time 721.0\n",
      "episode 1250, reward 985.0, memory_length 2000, epsilon 0.0019302610908140865 total_time 723.0\n",
      "Saving Model 1250\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1251, reward 641.0, memory_length 2000, epsilon 0.0019206338734600959 total_time 734.0\n",
      "episode 1252, reward 903.0, memory_length 2000, epsilon 0.0019110546720529744 total_time 721.0\n",
      "episode 1253, reward 788.0, memory_length 2000, epsilon 0.001901523247112187 total_time 724.0\n",
      "episode 1254, reward 838.0, memory_length 2000, epsilon 0.001892039360351617 total_time 724.0\n",
      "episode 1255, reward 828.0, memory_length 2000, epsilon 0.0018826027746735995 total_time 725.0\n",
      "episode 1256, reward 1141.0, memory_length 2000, epsilon 0.001873213254163001 total_time 725.0\n",
      "episode 1257, reward 675.0, memory_length 2000, epsilon 0.00186387056408132 total_time 723.0\n",
      "episode 1258, reward 442.0, memory_length 2000, epsilon 0.0018545744708608177 total_time 723.0\n",
      "episode 1259, reward 699.0, memory_length 2000, epsilon 0.0018453247420986796 total_time 723.0\n",
      "episode 1260, reward 1270.0, memory_length 2000, epsilon 0.0018361211465512044 total_time 739.0\n",
      "Saving Model 1260\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1261, reward 875.0, memory_length 2000, epsilon 0.0018269634541280245 total_time 723.0\n",
      "episode 1262, reward 708.0, memory_length 2000, epsilon 0.0018178514358863503 total_time 723.0\n",
      "episode 1263, reward 775.0, memory_length 2000, epsilon 0.0018087848640252551 total_time 721.0\n",
      "episode 1264, reward 1118.0, memory_length 2000, epsilon 0.0017997635118799681 total_time 721.0\n",
      "episode 1265, reward 1048.0, memory_length 2000, epsilon 0.0017907871539162156 total_time 723.0\n",
      "episode 1266, reward 803.0, memory_length 2000, epsilon 0.0017818555657245815 total_time 732.0\n",
      "episode 1267, reward 627.0, memory_length 2000, epsilon 0.0017729685240148955 total_time 721.0\n",
      "episode 1268, reward 330.0, memory_length 2000, epsilon 0.001764125806610652 total_time 723.0\n",
      "episode 1269, reward 354.0, memory_length 2000, epsilon 0.0017553271924434556 total_time 726.0\n",
      "episode 1270, reward 553.0, memory_length 2000, epsilon 0.0017465724615474921 total_time 725.0\n",
      "Saving Model 1270\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1271, reward 603.0, memory_length 2000, epsilon 0.001737861395054036 total_time 722.0\n",
      "episode 1272, reward 859.0, memory_length 2000, epsilon 0.00172919377518597 total_time 724.0\n",
      "episode 1273, reward 828.0, memory_length 2000, epsilon 0.001720569385252346 total_time 722.0\n",
      "episode 1274, reward 1010.0, memory_length 2000, epsilon 0.0017119880096429663 total_time 724.0\n",
      "episode 1275, reward 909.0, memory_length 2000, epsilon 0.0017034494338229937 total_time 721.0\n",
      "episode 1276, reward 809.0, memory_length 2000, epsilon 0.0016949534443275883 total_time 732.0\n",
      "episode 1277, reward 1122.0, memory_length 2000, epsilon 0.0016864998287565698 total_time 729.0\n",
      "episode 1278, reward 718.0, memory_length 2000, epsilon 0.0016780883757691076 total_time 731.0\n",
      "episode 1279, reward 693.0, memory_length 2000, epsilon 0.0016697188750784413 total_time 725.0\n",
      "episode 1280, reward 838.0, memory_length 2000, epsilon 0.0016613911174466166 total_time 728.0\n",
      "Saving Model 1280\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1281, reward 252.0, memory_length 2000, epsilon 0.001653104894679259 total_time 728.0\n",
      "episode 1282, reward 342.0, memory_length 2000, epsilon 0.0016448599996203676 total_time 724.0\n",
      "episode 1283, reward 697.0, memory_length 2000, epsilon 0.0016366562261471366 total_time 731.0\n",
      "episode 1284, reward 879.0, memory_length 2000, epsilon 0.0016284933691648018 total_time 725.0\n",
      "episode 1285, reward 577.0, memory_length 2000, epsilon 0.0016203712246015138 total_time 728.0\n",
      "episode 1286, reward 986.0, memory_length 2000, epsilon 0.001612289589403235 total_time 729.0\n",
      "episode 1287, reward 939.0, memory_length 2000, epsilon 0.0016042482615286633 total_time 723.0\n",
      "episode 1288, reward 529.0, memory_length 2000, epsilon 0.0015962470399441863 total_time 725.0\n",
      "episode 1289, reward 541.0, memory_length 2000, epsilon 0.0015882857246188454 total_time 731.0\n",
      "episode 1290, reward 780.0, memory_length 2000, epsilon 0.0015803641165193436 total_time 723.0\n",
      "Saving Model 1290\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1291, reward 861.0, memory_length 2000, epsilon 0.001572482017605065 total_time 730.0\n",
      "episode 1292, reward 497.0, memory_length 2000, epsilon 0.0015646392308231272 total_time 724.0\n",
      "episode 1293, reward 947.0, memory_length 2000, epsilon 0.0015568355601034516 total_time 731.0\n",
      "episode 1294, reward 986.0, memory_length 2000, epsilon 0.0015490708103538635 total_time 723.0\n",
      "episode 1295, reward 1088.0, memory_length 2000, epsilon 0.0015413447874552141 total_time 726.0\n",
      "episode 1296, reward 918.0, memory_length 2000, epsilon 0.0015336572982565307 total_time 729.0\n",
      "episode 1297, reward 732.0, memory_length 2000, epsilon 0.0015260081505701817 total_time 726.0\n",
      "episode 1298, reward 1265.0, memory_length 2000, epsilon 0.0015183971531670768 total_time 722.0\n",
      "episode 1299, reward 1063.0, memory_length 2000, epsilon 0.0015108241157718843 total_time 726.0\n",
      "episode 1300, reward 646.0, memory_length 2000, epsilon 0.0015032888490582746 total_time 732.0\n",
      "Saving Model 1300\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1301, reward 839.0, memory_length 2000, epsilon 0.0014957911646441883 total_time 728.0\n",
      "episode 1302, reward 846.0, memory_length 2000, epsilon 0.0014883308750871234 total_time 722.0\n",
      "episode 1303, reward 642.0, memory_length 2000, epsilon 0.0014809077938794518 total_time 722.0\n",
      "episode 1304, reward 674.0, memory_length 2000, epsilon 0.0014735217354437595 total_time 724.0\n",
      "episode 1305, reward 854.0, memory_length 2000, epsilon 0.0014661725151281987 total_time 721.0\n",
      "episode 1306, reward 490.0, memory_length 2000, epsilon 0.0014588599492018797 total_time 729.0\n",
      "episode 1307, reward 338.0, memory_length 2000, epsilon 0.0014515838548502732 total_time 723.0\n",
      "episode 1308, reward 929.0, memory_length 2000, epsilon 0.0014443440501706413 total_time 724.0\n",
      "episode 1309, reward 1144.0, memory_length 2000, epsilon 0.0014371403541674898 total_time 725.0\n",
      "episode 1310, reward 883.0, memory_length 2000, epsilon 0.0014299725867480437 total_time 723.0\n",
      "Saving Model 1310\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1311, reward 334.0, memory_length 2000, epsilon 0.001422840568717744 total_time 721.0\n",
      "episode 1312, reward 677.0, memory_length 2000, epsilon 0.0014157441217757675 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1313, reward 1045.0, memory_length 2000, epsilon 0.001408683068510573 total_time 722.0\n",
      "episode 1314, reward 866.0, memory_length 2000, epsilon 0.0014016572323954607 total_time 734.0\n",
      "episode 1315, reward 1101.0, memory_length 2000, epsilon 0.0013946664377841613 total_time 725.0\n",
      "episode 1316, reward 422.0, memory_length 2000, epsilon 0.0013877105099064453 total_time 721.0\n",
      "episode 1317, reward 1126.0, memory_length 2000, epsilon 0.0013807892748637534 total_time 721.0\n",
      "episode 1318, reward 575.0, memory_length 2000, epsilon 0.0013739025596248497 total_time 726.0\n",
      "episode 1319, reward 694.0, memory_length 2000, epsilon 0.0013670501920214938 total_time 727.0\n",
      "episode 1320, reward 990.0, memory_length 2000, epsilon 0.001360232000744138 total_time 726.0\n",
      "Saving Model 1320\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1321, reward 993.0, memory_length 2000, epsilon 0.0013534478153376475 total_time 722.0\n",
      "episode 1322, reward 946.0, memory_length 2000, epsilon 0.0013466974661970324 total_time 728.0\n",
      "episode 1323, reward 494.0, memory_length 2000, epsilon 0.0013399807845632127 total_time 724.0\n",
      "episode 1324, reward 863.0, memory_length 2000, epsilon 0.001333297602518798 total_time 725.0\n",
      "episode 1325, reward 662.0, memory_length 2000, epsilon 0.0013266477529838888 total_time 721.0\n",
      "episode 1326, reward 574.0, memory_length 2000, epsilon 0.0013200310697119007 total_time 721.0\n",
      "episode 1327, reward 722.0, memory_length 2000, epsilon 0.0013134473872854066 total_time 723.0\n",
      "episode 1328, reward 851.0, memory_length 2000, epsilon 0.0013068965411120027 total_time 726.0\n",
      "episode 1329, reward 621.0, memory_length 2000, epsilon 0.0013003783674201952 total_time 729.0\n",
      "episode 1330, reward 1367.0, memory_length 2000, epsilon 0.0012938927032553015 total_time 726.0\n",
      "Saving Model 1330\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1331, reward 1249.0, memory_length 2000, epsilon 0.001287439386475379 total_time 723.0\n",
      "episode 1332, reward 945.0, memory_length 2000, epsilon 0.0012810182557471729 total_time 733.0\n",
      "episode 1333, reward 450.0, memory_length 2000, epsilon 0.00127462915054208 total_time 729.0\n",
      "episode 1334, reward 1093.0, memory_length 2000, epsilon 0.0012682719111321381 total_time 726.0\n",
      "episode 1335, reward 496.0, memory_length 2000, epsilon 0.00126194637858603 total_time 725.0\n",
      "episode 1336, reward 702.0, memory_length 2000, epsilon 0.0012556523947651133 total_time 723.0\n",
      "episode 1337, reward 594.0, memory_length 2000, epsilon 0.001249389802319463 total_time 727.0\n",
      "episode 1338, reward 887.0, memory_length 2000, epsilon 0.0012431584446839442 total_time 725.0\n",
      "episode 1339, reward 581.0, memory_length 2000, epsilon 0.0012369581660742906 total_time 726.0\n",
      "episode 1340, reward 540.0, memory_length 2000, epsilon 0.0012307888114832138 total_time 728.0\n",
      "Saving Model 1340\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1341, reward 567.0, memory_length 2000, epsilon 0.0012246502266765275 total_time 724.0\n",
      "episode 1342, reward 745.0, memory_length 2000, epsilon 0.0012185422581892922 total_time 728.0\n",
      "episode 1343, reward 374.0, memory_length 2000, epsilon 0.0012124647533219772 total_time 727.0\n",
      "episode 1344, reward 519.0, memory_length 2000, epsilon 0.0012064175601366445 total_time 723.0\n",
      "episode 1345, reward 531.0, memory_length 2000, epsilon 0.0012004005274531488 total_time 728.0\n",
      "episode 1346, reward 923.0, memory_length 2000, epsilon 0.0011944135048453611 total_time 726.0\n",
      "episode 1347, reward 1743.0, memory_length 2000, epsilon 0.001188456342637404 total_time 723.0\n",
      "episode 1348, reward 851.0, memory_length 2000, epsilon 0.001182528891899911 total_time 725.0\n",
      "episode 1349, reward 820.0, memory_length 2000, epsilon 0.0011766310044463062 total_time 726.0\n",
      "episode 1350, reward 724.0, memory_length 2000, epsilon 0.0011707625328290954 total_time 726.0\n",
      "Saving Model 1350\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1351, reward 438.0, memory_length 2000, epsilon 0.0011649233303361825 total_time 731.0\n",
      "episode 1352, reward 1083.0, memory_length 2000, epsilon 0.0011591132509872009 total_time 723.0\n",
      "episode 1353, reward 847.0, memory_length 2000, epsilon 0.0011533321495298637 total_time 722.0\n",
      "episode 1354, reward 652.0, memory_length 2000, epsilon 0.001147579881436335 total_time 722.0\n",
      "episode 1355, reward 1183.0, memory_length 2000, epsilon 0.0011418563028996126 total_time 724.0\n",
      "episode 1356, reward 839.0, memory_length 2000, epsilon 0.001136161270829934 total_time 722.0\n",
      "episode 1357, reward 913.0, memory_length 2000, epsilon 0.0011304946428512012 total_time 722.0\n",
      "episode 1358, reward 727.0, memory_length 2000, epsilon 0.0011248562772974199 total_time 732.0\n",
      "episode 1359, reward 1103.0, memory_length 2000, epsilon 0.0011192460332091572 total_time 727.0\n",
      "episode 1360, reward 974.0, memory_length 2000, epsilon 0.0011136637703300187 total_time 730.0\n",
      "Saving Model 1360\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1361, reward 919.0, memory_length 2000, epsilon 0.0011081093491031421 total_time 721.0\n",
      "episode 1362, reward 834.0, memory_length 2000, epsilon 0.0011025826306677062 total_time 721.0\n",
      "episode 1363, reward 714.0, memory_length 2000, epsilon 0.001097083476855464 total_time 725.0\n",
      "episode 1364, reward 709.0, memory_length 2000, epsilon 0.0010916117501872829 total_time 726.0\n",
      "episode 1365, reward 890.0, memory_length 2000, epsilon 0.0010861673138697115 total_time 726.0\n",
      "episode 1366, reward 677.0, memory_length 2000, epsilon 0.0010807500317915582 total_time 730.0\n",
      "episode 1367, reward 908.0, memory_length 2000, epsilon 0.0010753597685204887 total_time 729.0\n",
      "episode 1368, reward 556.0, memory_length 2000, epsilon 0.0010699963892996404 total_time 731.0\n",
      "episode 1369, reward 938.0, memory_length 2000, epsilon 0.0010646597600442538 total_time 724.0\n",
      "episode 1370, reward 647.0, memory_length 2000, epsilon 0.0010593497473383184 total_time 725.0\n",
      "Saving Model 1370\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1371, reward 802.0, memory_length 2000, epsilon 0.001054066218431242 total_time 724.0\n",
      "episode 1372, reward 814.0, memory_length 2000, epsilon 0.0010488090412345255 total_time 728.0\n",
      "episode 1373, reward 1212.0, memory_length 2000, epsilon 0.0010435780843184655 total_time 726.0\n",
      "episode 1374, reward 873.0, memory_length 2000, epsilon 0.0010383732169088667 total_time 722.0\n",
      "episode 1375, reward 950.0, memory_length 2000, epsilon 0.0010331943088837724 total_time 721.0\n",
      "episode 1376, reward 1063.0, memory_length 2000, epsilon 0.0010280412307702123 total_time 727.0\n",
      "episode 1377, reward 897.0, memory_length 2000, epsilon 0.0010229138537409656 total_time 730.0\n",
      "episode 1378, reward 1056.0, memory_length 2000, epsilon 0.0010178120496113381 total_time 723.0\n",
      "episode 1379, reward 924.0, memory_length 2000, epsilon 0.0010127356908359632 total_time 725.0\n",
      "episode 1380, reward 333.0, memory_length 2000, epsilon 0.0010076846505056056 total_time 723.0\n",
      "Saving Model 1380\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1381, reward 1265.0, memory_length 2000, epsilon 0.0010026588023439944 total_time 721.0\n",
      "episode 1382, reward 1177.0, memory_length 2000, epsilon 0.0009976580207046637 total_time 727.0\n",
      "episode 1383, reward 719.0, memory_length 2000, epsilon 0.0009926821805678117 total_time 724.0\n",
      "episode 1384, reward 619.0, memory_length 2000, epsilon 0.0009877311575371764 total_time 726.0\n",
      "episode 1385, reward 402.0, memory_length 2000, epsilon 0.000982804827836924 total_time 728.0\n",
      "episode 1386, reward 638.0, memory_length 2000, epsilon 0.000977903068308555 total_time 729.0\n",
      "episode 1387, reward 681.0, memory_length 2000, epsilon 0.0009730257564078256 total_time 726.0\n",
      "episode 1388, reward 952.0, memory_length 2000, epsilon 0.0009681727702016856 total_time 722.0\n",
      "episode 1389, reward 662.0, memory_length 2000, epsilon 0.0009633439883652263 total_time 731.0\n",
      "episode 1390, reward 428.0, memory_length 2000, epsilon 0.0009585392901786504 total_time 723.0\n",
      "Saving Model 1390\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1391, reward 620.0, memory_length 2000, epsilon 0.000953758555524253 total_time 721.0\n",
      "episode 1392, reward 659.0, memory_length 2000, epsilon 0.0009490016648834187 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1393, reward 629.0, memory_length 2000, epsilon 0.0009442684993336335 total_time 731.0\n",
      "episode 1394, reward 1015.0, memory_length 2000, epsilon 0.0009395589405455125 total_time 724.0\n",
      "episode 1395, reward 550.0, memory_length 2000, epsilon 0.0009348728707798397 total_time 727.0\n",
      "episode 1396, reward 650.0, memory_length 2000, epsilon 0.0009302101728846285 total_time 722.0\n",
      "episode 1397, reward 960.0, memory_length 2000, epsilon 0.000925570730292188 total_time 723.0\n",
      "episode 1398, reward 1097.0, memory_length 2000, epsilon 0.0009209544270162115 total_time 722.0\n",
      "episode 1399, reward 652.0, memory_length 2000, epsilon 0.0009163611476488769 total_time 722.0\n",
      "episode 1400, reward 936.0, memory_length 2000, epsilon 0.0009117907773579608 total_time 726.0\n",
      "Saving Model 1400\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1401, reward 838.0, memory_length 2000, epsilon 0.0009072432018839676 total_time 725.0\n",
      "episode 1402, reward 963.0, memory_length 2000, epsilon 0.000902718307537274 total_time 726.0\n",
      "episode 1403, reward 699.0, memory_length 2000, epsilon 0.0008982159811952845 total_time 732.0\n",
      "episode 1404, reward 915.0, memory_length 2000, epsilon 0.0008937361102996078 total_time 721.0\n",
      "episode 1405, reward 1162.0, memory_length 2000, epsilon 0.0008892785828532375 total_time 721.0\n",
      "episode 1406, reward 1032.0, memory_length 2000, epsilon 0.000884843287417755 total_time 723.0\n",
      "episode 1407, reward 1025.0, memory_length 2000, epsilon 0.0008804301131105437 total_time 721.0\n",
      "episode 1408, reward 945.0, memory_length 2000, epsilon 0.0008760389496020158 total_time 732.0\n",
      "episode 1409, reward 853.0, memory_length 2000, epsilon 0.0008716696871128552 total_time 726.0\n",
      "episode 1410, reward 1086.0, memory_length 2000, epsilon 0.0008673222164112718 total_time 721.0\n",
      "Saving Model 1410\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1411, reward 1018.0, memory_length 2000, epsilon 0.0008629964288102718 total_time 725.0\n",
      "episode 1412, reward 769.0, memory_length 2000, epsilon 0.000858692216164939 total_time 726.0\n",
      "episode 1413, reward 377.0, memory_length 2000, epsilon 0.0008544094708697348 total_time 725.0\n",
      "episode 1414, reward 799.0, memory_length 2000, epsilon 0.0008501480858558027 total_time 728.0\n",
      "episode 1415, reward 847.0, memory_length 2000, epsilon 0.0008459079545882957 total_time 730.0\n",
      "episode 1416, reward 1082.0, memory_length 2000, epsilon 0.0008416889710637112 total_time 727.0\n",
      "episode 1417, reward 741.0, memory_length 2000, epsilon 0.0008374910298072411 total_time 725.0\n",
      "episode 1418, reward 1027.0, memory_length 2000, epsilon 0.0008333140258701358 total_time 729.0\n",
      "episode 1419, reward 1104.0, memory_length 2000, epsilon 0.0008291578548270789 total_time 726.0\n",
      "episode 1420, reward 641.0, memory_length 2000, epsilon 0.0008250224127735773 total_time 723.0\n",
      "Saving Model 1420\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1421, reward 814.0, memory_length 2000, epsilon 0.0008209075963233656 total_time 724.0\n",
      "episode 1422, reward 1014.0, memory_length 2000, epsilon 0.0008168133026058178 total_time 728.0\n",
      "episode 1423, reward 845.0, memory_length 2000, epsilon 0.0008127394292633775 total_time 731.0\n",
      "episode 1424, reward 841.0, memory_length 2000, epsilon 0.000808685874448999 total_time 730.0\n",
      "episode 1425, reward 641.0, memory_length 2000, epsilon 0.0008046525368236008 total_time 724.0\n",
      "episode 1426, reward 661.0, memory_length 2000, epsilon 0.0008006393155535322 total_time 725.0\n",
      "episode 1427, reward 829.0, memory_length 2000, epsilon 0.0007966461103080525 total_time 725.0\n",
      "episode 1428, reward 1060.0, memory_length 2000, epsilon 0.0007926728212568217 total_time 722.0\n",
      "episode 1429, reward 791.0, memory_length 2000, epsilon 0.0007887193490674082 total_time 727.0\n",
      "episode 1430, reward 990.0, memory_length 2000, epsilon 0.0007847855949028006 total_time 728.0\n",
      "Saving Model 1430\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1431, reward 793.0, memory_length 2000, epsilon 0.0007808714604189398 total_time 723.0\n",
      "episode 1432, reward 351.0, memory_length 2000, epsilon 0.0007769768477622598 total_time 725.0\n",
      "episode 1433, reward 1238.0, memory_length 2000, epsilon 0.0007731016595672415 total_time 724.0\n",
      "episode 1434, reward 883.0, memory_length 2000, epsilon 0.0007692457989539781 total_time 723.0\n",
      "episode 1435, reward 608.0, memory_length 2000, epsilon 0.0007654091695257536 total_time 731.0\n",
      "episode 1436, reward 855.0, memory_length 2000, epsilon 0.0007615916753666322 total_time 728.0\n",
      "episode 1437, reward 697.0, memory_length 2000, epsilon 0.0007577932210390605 total_time 731.0\n",
      "episode 1438, reward 768.0, memory_length 2000, epsilon 0.0007540137115814839 total_time 724.0\n",
      "episode 1439, reward 1257.0, memory_length 2000, epsilon 0.0007502530525059685 total_time 726.0\n",
      "episode 1440, reward 518.0, memory_length 2000, epsilon 0.0007465111497958416 total_time 729.0\n",
      "Saving Model 1440\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1441, reward 780.0, memory_length 2000, epsilon 0.0007427879099033402 total_time 725.0\n",
      "episode 1442, reward 355.0, memory_length 2000, epsilon 0.0007390832397472733 total_time 728.0\n",
      "episode 1443, reward 666.0, memory_length 2000, epsilon 0.0007353970467106942 total_time 723.0\n",
      "episode 1444, reward 1098.0, memory_length 2000, epsilon 0.0007317292386385848 total_time 722.0\n",
      "episode 1445, reward 761.0, memory_length 2000, epsilon 0.0007280797238355515 total_time 724.0\n",
      "episode 1446, reward 771.0, memory_length 2000, epsilon 0.0007244484110635357 total_time 724.0\n",
      "episode 1447, reward 288.0, memory_length 2000, epsilon 0.0007208352095395281 total_time 728.0\n",
      "episode 1448, reward 564.0, memory_length 2000, epsilon 0.0007172400289333025 total_time 721.0\n",
      "episode 1449, reward 746.0, memory_length 2000, epsilon 0.0007136627793651566 total_time 721.0\n",
      "episode 1450, reward 599.0, memory_length 2000, epsilon 0.0007101033714036648 total_time 721.0\n",
      "Saving Model 1450\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1451, reward 532.0, memory_length 2000, epsilon 0.0007065617160634427 total_time 729.0\n",
      "episode 1452, reward 193.0, memory_length 2000, epsilon 0.0007030377248029222 total_time 723.0\n",
      "episode 1453, reward 605.0, memory_length 2000, epsilon 0.0006995313095221378 total_time 722.0\n",
      "episode 1454, reward 539.0, memory_length 2000, epsilon 0.0006960423825605261 total_time 731.0\n",
      "episode 1455, reward 1124.0, memory_length 2000, epsilon 0.0006925708566947306 total_time 725.0\n",
      "episode 1456, reward 590.0, memory_length 2000, epsilon 0.0006891166451364238 total_time 727.0\n",
      "episode 1457, reward 430.0, memory_length 2000, epsilon 0.000685679661530137 total_time 732.0\n",
      "episode 1458, reward 589.0, memory_length 2000, epsilon 0.000682259819951101 total_time 728.0\n",
      "episode 1459, reward 415.0, memory_length 2000, epsilon 0.000678857034903098 total_time 721.0\n",
      "episode 1460, reward 326.0, memory_length 2000, epsilon 0.000675471221316325 total_time 721.0\n",
      "Saving Model 1460\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1461, reward 982.0, memory_length 2000, epsilon 0.0006721022945452656 total_time 724.0\n",
      "episode 1462, reward 978.0, memory_length 2000, epsilon 0.0006687501703665745 total_time 728.0\n",
      "episode 1463, reward 904.0, memory_length 2000, epsilon 0.0006654147649769741 total_time 721.0\n",
      "episode 1464, reward 1259.0, memory_length 2000, epsilon 0.0006620959949911551 total_time 722.0\n",
      "episode 1465, reward 817.0, memory_length 2000, epsilon 0.0006587937774396952 total_time 721.0\n",
      "episode 1466, reward 999.0, memory_length 2000, epsilon 0.0006555080297669832 total_time 730.0\n",
      "episode 1467, reward 1432.0, memory_length 2000, epsilon 0.0006522386698291567 total_time 725.0\n",
      "episode 1468, reward 923.0, memory_length 2000, epsilon 0.0006489856158920467 total_time 726.0\n",
      "episode 1469, reward 727.0, memory_length 2000, epsilon 0.0006457487866291352 total_time 731.0\n",
      "episode 1470, reward 1055.0, memory_length 2000, epsilon 0.0006425281011195218 total_time 723.0\n",
      "Saving Model 1470\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1471, reward 1128.0, memory_length 2000, epsilon 0.000639323478845902 total_time 734.0\n",
      "episode 1472, reward 1349.0, memory_length 2000, epsilon 0.0006361348396925513 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1473, reward 1130.0, memory_length 2000, epsilon 0.0006329621039433251 total_time 721.0\n",
      "episode 1474, reward 951.0, memory_length 2000, epsilon 0.0006298051922796643 total_time 726.0\n",
      "episode 1475, reward 1281.0, memory_length 2000, epsilon 0.0006266640257786127 total_time 724.0\n",
      "episode 1476, reward 968.0, memory_length 2000, epsilon 0.0006235385259108446 total_time 727.0\n",
      "episode 1477, reward 675.0, memory_length 2000, epsilon 0.0006204286145387001 total_time 723.0\n",
      "episode 1478, reward 942.0, memory_length 2000, epsilon 0.0006173342139142324 total_time 727.0\n",
      "episode 1479, reward 863.0, memory_length 2000, epsilon 0.0006142552466772663 total_time 724.0\n",
      "episode 1480, reward 959.0, memory_length 2000, epsilon 0.0006111916358534594 total_time 722.0\n",
      "Saving Model 1480\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1481, reward 571.0, memory_length 2000, epsilon 0.0006081433048523817 total_time 724.0\n",
      "episode 1482, reward 870.0, memory_length 2000, epsilon 0.0006051101774655997 total_time 721.0\n",
      "episode 1483, reward 1002.0, memory_length 2000, epsilon 0.0006020921778647704 total_time 722.0\n",
      "episode 1484, reward 666.0, memory_length 2000, epsilon 0.0005990892305997467 total_time 725.0\n",
      "episode 1485, reward 741.0, memory_length 2000, epsilon 0.0005961012605966905 total_time 726.0\n",
      "episode 1486, reward 588.0, memory_length 2000, epsilon 0.0005931281931561963 total_time 725.0\n",
      "episode 1487, reward 535.0, memory_length 2000, epsilon 0.0005901699539514226 total_time 724.0\n",
      "episode 1488, reward 909.0, memory_length 2000, epsilon 0.0005872264690262362 total_time 724.0\n",
      "episode 1489, reward 1193.0, memory_length 2000, epsilon 0.0005842976647933601 total_time 725.0\n",
      "episode 1490, reward 541.0, memory_length 2000, epsilon 0.0005813834680325362 total_time 724.0\n",
      "Saving Model 1490\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1491, reward 930.0, memory_length 2000, epsilon 0.0005784838058886935 total_time 725.0\n",
      "episode 1492, reward 997.0, memory_length 2000, epsilon 0.0005755986058701274 total_time 721.0\n",
      "episode 1493, reward 813.0, memory_length 2000, epsilon 0.000572727795846687 total_time 721.0\n",
      "episode 1494, reward 856.0, memory_length 2000, epsilon 0.0005698713040479727 total_time 724.0\n",
      "episode 1495, reward 456.0, memory_length 2000, epsilon 0.0005670290590615397 total_time 725.0\n",
      "episode 1496, reward 969.0, memory_length 2000, epsilon 0.0005642009898311165 total_time 726.0\n",
      "episode 1497, reward 503.0, memory_length 2000, epsilon 0.0005613870256548247 total_time 727.0\n",
      "episode 1498, reward 937.0, memory_length 2000, epsilon 0.0005585870961834132 total_time 721.0\n",
      "episode 1499, reward 945.0, memory_length 2000, epsilon 0.0005558011314184992 total_time 723.0\n",
      "episode 1500, reward 719.0, memory_length 2000, epsilon 0.0005530290617108189 total_time 736.0\n",
      "Saving Model 1500\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1501, reward 1108.0, memory_length 2000, epsilon 0.0005502708177584848 total_time 722.0\n",
      "episode 1502, reward 1121.0, memory_length 2000, epsilon 0.0005475263306052547 total_time 725.0\n",
      "episode 1503, reward 1243.0, memory_length 2000, epsilon 0.0005447955316388063 total_time 726.0\n",
      "episode 1504, reward 948.0, memory_length 2000, epsilon 0.000542078352589024 total_time 724.0\n",
      "episode 1505, reward 884.0, memory_length 2000, epsilon 0.0005393747255262899 total_time 723.0\n",
      "episode 1506, reward 966.0, memory_length 2000, epsilon 0.0005366845828597863 total_time 725.0\n",
      "episode 1507, reward 1039.0, memory_length 2000, epsilon 0.0005340078573358066 total_time 730.0\n",
      "episode 1508, reward 548.0, memory_length 2000, epsilon 0.0005313444820360732 total_time 721.0\n",
      "episode 1509, reward 1343.0, memory_length 2000, epsilon 0.0005286943903760648 total_time 731.0\n",
      "episode 1510, reward 898.0, memory_length 2000, epsilon 0.0005260575161033521 total_time 724.0\n",
      "Saving Model 1510\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1511, reward 999.0, memory_length 2000, epsilon 0.0005234337932959409 total_time 722.0\n",
      "episode 1512, reward 803.0, memory_length 2000, epsilon 0.0005208231563606237 total_time 722.0\n",
      "episode 1513, reward 831.0, memory_length 2000, epsilon 0.0005182255400313422 total_time 721.0\n",
      "episode 1514, reward 1039.0, memory_length 2000, epsilon 0.0005156408793675526 total_time 731.0\n",
      "episode 1515, reward 384.0, memory_length 2000, epsilon 0.0005130691097526034 total_time 726.0\n",
      "episode 1516, reward 712.0, memory_length 2000, epsilon 0.0005105101668921204 total_time 723.0\n",
      "episode 1517, reward 1438.0, memory_length 2000, epsilon 0.0005079639868123988 total_time 728.0\n",
      "episode 1518, reward 887.0, memory_length 2000, epsilon 0.0005054305058588039 total_time 722.0\n",
      "episode 1519, reward 507.0, memory_length 2000, epsilon 0.0005029096606941801 total_time 728.0\n",
      "episode 1520, reward 621.0, memory_length 2000, epsilon 0.0005004013882972663 total_time 726.0\n",
      "Saving Model 1520\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1521, reward 938.0, memory_length 2000, epsilon 0.0004979056259611232 total_time 724.0\n",
      "episode 1522, reward 1081.0, memory_length 2000, epsilon 0.0004954223112915616 total_time 727.0\n",
      "episode 1523, reward 677.0, memory_length 2000, epsilon 0.0004929513822055856 total_time 721.0\n",
      "episode 1524, reward 1189.0, memory_length 2000, epsilon 0.0004904927769298393 total_time 725.0\n",
      "episode 1525, reward 1038.0, memory_length 2000, epsilon 0.00048804643399906266 total_time 722.0\n",
      "episode 1526, reward 637.0, memory_length 2000, epsilon 0.0004856122922545552 total_time 721.0\n",
      "episode 1527, reward 764.0, memory_length 2000, epsilon 0.0004831902908426464 total_time 728.0\n",
      "episode 1528, reward 652.0, memory_length 2000, epsilon 0.00048078036921317445 total_time 726.0\n",
      "episode 1529, reward 1180.0, memory_length 2000, epsilon 0.00047838246711797393 total_time 726.0\n",
      "episode 1530, reward 667.0, memory_length 2000, epsilon 0.00047599652460936714 total_time 721.0\n",
      "Saving Model 1530\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1531, reward 1145.0, memory_length 2000, epsilon 0.00047362248203866705 total_time 727.0\n",
      "episode 1532, reward 799.0, memory_length 2000, epsilon 0.0004712602800546858 total_time 723.0\n",
      "episode 1533, reward 763.0, memory_length 2000, epsilon 0.0004689098596022507 total_time 724.0\n",
      "episode 1534, reward 827.0, memory_length 2000, epsilon 0.0004665711619207281 total_time 722.0\n",
      "episode 1535, reward 799.0, memory_length 2000, epsilon 0.00046424412854255415 total_time 722.0\n",
      "episode 1536, reward 951.0, memory_length 2000, epsilon 0.00046192870129177315 total_time 722.0\n",
      "episode 1537, reward 335.0, memory_length 2000, epsilon 0.00045962482228258285 total_time 730.0\n",
      "episode 1538, reward 1149.0, memory_length 2000, epsilon 0.0004573324339178888 total_time 722.0\n",
      "episode 1539, reward 709.0, memory_length 2000, epsilon 0.0004550514788878622 total_time 726.0\n",
      "episode 1540, reward 933.0, memory_length 2000, epsilon 0.0004527819001685083 total_time 726.0\n",
      "Saving Model 1540\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1541, reward 611.0, memory_length 2000, epsilon 0.0004505236410202411 total_time 735.0\n",
      "episode 1542, reward 714.0, memory_length 2000, epsilon 0.00044827664498646414 total_time 725.0\n",
      "episode 1543, reward 362.0, memory_length 2000, epsilon 0.00044604085589215964 total_time 727.0\n",
      "episode 1544, reward 164.0, memory_length 2000, epsilon 0.0004438162178424837 total_time 727.0\n",
      "episode 1545, reward 581.0, memory_length 2000, epsilon 0.000441602675221369 total_time 726.0\n",
      "episode 1546, reward 859.0, memory_length 2000, epsilon 0.0004394001726901353 total_time 731.0\n",
      "episode 1547, reward 476.0, memory_length 2000, epsilon 0.00043720865518610434 total_time 723.0\n",
      "episode 1548, reward 585.0, memory_length 2000, epsilon 0.00043502806792122426 total_time 721.0\n",
      "episode 1549, reward 1060.0, memory_length 2000, epsilon 0.0004328583563807 total_time 722.0\n",
      "episode 1550, reward 635.0, memory_length 2000, epsilon 0.00043069946632162996 total_time 723.0\n",
      "Saving Model 1550\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1551, reward 510.0, memory_length 2000, epsilon 0.00042855134377165025 total_time 727.0\n",
      "episode 1552, reward 930.0, memory_length 2000, epsilon 0.00042641393502758525 total_time 727.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1553, reward 626.0, memory_length 2000, epsilon 0.00042428718665410463 total_time 724.0\n",
      "episode 1554, reward 636.0, memory_length 2000, epsilon 0.00042217104548238906 total_time 729.0\n",
      "episode 1555, reward 734.0, memory_length 2000, epsilon 0.00042006545860879857 total_time 725.0\n",
      "episode 1556, reward 840.0, memory_length 2000, epsilon 0.00041797037339355185 total_time 725.0\n",
      "episode 1557, reward 713.0, memory_length 2000, epsilon 0.0004158857374594092 total_time 721.0\n",
      "episode 1558, reward 1026.0, memory_length 2000, epsilon 0.0004138114986903638 total_time 724.0\n",
      "episode 1559, reward 1090.0, memory_length 2000, epsilon 0.0004117476052303383 total_time 722.0\n",
      "episode 1560, reward 968.0, memory_length 2000, epsilon 0.0004096940054818888 total_time 721.0\n",
      "Saving Model 1560\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1561, reward 889.0, memory_length 2000, epsilon 0.0004076506481049142 total_time 723.0\n",
      "episode 1562, reward 564.0, memory_length 2000, epsilon 0.0004056174820153745 total_time 725.0\n",
      "episode 1563, reward 1193.0, memory_length 2000, epsilon 0.000403594456384011 total_time 724.0\n",
      "episode 1564, reward 1180.0, memory_length 2000, epsilon 0.0004015815206350777 total_time 721.0\n",
      "episode 1565, reward 1041.0, memory_length 2000, epsilon 0.0003995786244450761 total_time 723.0\n",
      "episode 1566, reward 736.0, memory_length 2000, epsilon 0.0003975857177414969 total_time 725.0\n",
      "episode 1567, reward 764.0, memory_length 2000, epsilon 0.0003956027507015689 total_time 724.0\n",
      "episode 1568, reward 854.0, memory_length 2000, epsilon 0.00039362967375101277 total_time 724.0\n",
      "episode 1569, reward 1168.0, memory_length 2000, epsilon 0.00039166643756280195 total_time 722.0\n",
      "episode 1570, reward 1194.0, memory_length 2000, epsilon 0.0003897129930559292 total_time 725.0\n",
      "Saving Model 1570\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1571, reward 890.0, memory_length 2000, epsilon 0.0003877692913941807 total_time 721.0\n",
      "episode 1572, reward 969.0, memory_length 2000, epsilon 0.00038583528398491345 total_time 724.0\n",
      "episode 1573, reward 687.0, memory_length 2000, epsilon 0.0003839109224778414 total_time 726.0\n",
      "episode 1574, reward 1146.0, memory_length 2000, epsilon 0.0003819961587638267 total_time 724.0\n",
      "episode 1575, reward 1248.0, memory_length 2000, epsilon 0.00038009094497367676 total_time 725.0\n",
      "episode 1576, reward 947.0, memory_length 2000, epsilon 0.00037819523347694747 total_time 727.0\n",
      "episode 1577, reward 697.0, memory_length 2000, epsilon 0.0003763089768807529 total_time 725.0\n",
      "episode 1578, reward 926.0, memory_length 2000, epsilon 0.0003744321280285794 total_time 721.0\n",
      "episode 1579, reward 866.0, memory_length 2000, epsilon 0.00037256463999910865 total_time 725.0\n",
      "episode 1580, reward 1076.0, memory_length 2000, epsilon 0.0003707064661050423 total_time 730.0\n",
      "Saving Model 1580\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1581, reward 971.0, memory_length 2000, epsilon 0.00036885755989193625 total_time 723.0\n",
      "episode 1582, reward 599.0, memory_length 2000, epsilon 0.00036701787513703887 total_time 722.0\n",
      "episode 1583, reward 749.0, memory_length 2000, epsilon 0.00036518736584813537 total_time 728.0\n",
      "episode 1584, reward 950.0, memory_length 2000, epsilon 0.00036336598626239834 total_time 723.0\n",
      "episode 1585, reward 509.0, memory_length 2000, epsilon 0.0003615536908452431 total_time 723.0\n",
      "episode 1586, reward 592.0, memory_length 2000, epsilon 0.00035975043428918967 total_time 725.0\n",
      "episode 1587, reward 619.0, memory_length 2000, epsilon 0.0003579561715127308 total_time 722.0\n",
      "episode 1588, reward 878.0, memory_length 2000, epsilon 0.0003561708576592033 total_time 721.0\n",
      "episode 1589, reward 966.0, memory_length 2000, epsilon 0.0003543944480956679 total_time 725.0\n",
      "episode 1590, reward 913.0, memory_length 2000, epsilon 0.0003526268984117929 total_time 724.0\n",
      "Saving Model 1590\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1591, reward 764.0, memory_length 2000, epsilon 0.00035086816441874425 total_time 728.0\n",
      "episode 1592, reward 931.0, memory_length 2000, epsilon 0.00034911820214808043 total_time 722.0\n",
      "episode 1593, reward 1100.0, memory_length 2000, epsilon 0.00034737696785065356 total_time 726.0\n",
      "episode 1594, reward 609.0, memory_length 2000, epsilon 0.0003456444179955155 total_time 724.0\n",
      "episode 1595, reward 1309.0, memory_length 2000, epsilon 0.0003439205092688295 total_time 728.0\n",
      "episode 1596, reward 974.0, memory_length 2000, epsilon 0.00034220519857278787 total_time 724.0\n",
      "episode 1597, reward 765.0, memory_length 2000, epsilon 0.0003404984430245339 total_time 731.0\n",
      "episode 1598, reward 939.0, memory_length 2000, epsilon 0.0003388001999550898 total_time 722.0\n",
      "episode 1599, reward 707.0, memory_length 2000, epsilon 0.0003371104269082904 total_time 724.0\n",
      "episode 1600, reward 1171.0, memory_length 2000, epsilon 0.0003354290816397216 total_time 729.0\n",
      "Saving Model 1600\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1601, reward 1342.0, memory_length 2000, epsilon 0.00033375612211566377 total_time 722.0\n",
      "episode 1602, reward 861.0, memory_length 2000, epsilon 0.00033209150651204256 total_time 724.0\n",
      "episode 1603, reward 1049.0, memory_length 2000, epsilon 0.00033043519321338 total_time 725.0\n",
      "episode 1604, reward 745.0, memory_length 2000, epsilon 0.00032878714081175856 total_time 725.0\n",
      "episode 1605, reward 1080.0, memory_length 2000, epsilon 0.0003271473081057812 total_time 731.0\n",
      "episode 1606, reward 1173.0, memory_length 2000, epsilon 0.0003255156540995459 total_time 727.0\n",
      "episode 1607, reward 1285.0, memory_length 2000, epsilon 0.0003238921380016166 total_time 725.0\n",
      "episode 1608, reward 907.0, memory_length 2000, epsilon 0.00032227671922400666 total_time 722.0\n",
      "episode 1609, reward 1107.0, memory_length 2000, epsilon 0.0003206693573811631 total_time 726.0\n",
      "episode 1610, reward 923.0, memory_length 2000, epsilon 0.00031907001228895514 total_time 727.0\n",
      "Saving Model 1610\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1611, reward 1050.0, memory_length 2000, epsilon 0.0003174786439636732 total_time 726.0\n",
      "episode 1612, reward 430.0, memory_length 2000, epsilon 0.0003158952126210251 total_time 729.0\n",
      "episode 1613, reward 1038.0, memory_length 2000, epsilon 0.00031431967867514605 total_time 722.0\n",
      "episode 1614, reward 1164.0, memory_length 2000, epsilon 0.0003127520027376041 total_time 726.0\n",
      "episode 1615, reward 1158.0, memory_length 2000, epsilon 0.00031119214561642035 total_time 724.0\n",
      "episode 1616, reward 847.0, memory_length 2000, epsilon 0.00030964006831508435 total_time 727.0\n",
      "episode 1617, reward 632.0, memory_length 2000, epsilon 0.00030809573203158334 total_time 721.0\n",
      "episode 1618, reward 662.0, memory_length 2000, epsilon 0.00030655909815743035 total_time 726.0\n",
      "episode 1619, reward 967.0, memory_length 2000, epsilon 0.0003050301282766974 total_time 729.0\n",
      "episode 1620, reward 840.0, memory_length 2000, epsilon 0.0003035087841650589 total_time 721.0\n",
      "Saving Model 1620\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1621, reward 576.0, memory_length 2000, epsilon 0.0003019950277888317 total_time 726.0\n",
      "episode 1622, reward 857.0, memory_length 2000, epsilon 0.00030048882130402876 total_time 726.0\n",
      "episode 1623, reward 602.0, memory_length 2000, epsilon 0.0002989901270554083 total_time 728.0\n",
      "episode 1624, reward 1057.0, memory_length 2000, epsilon 0.00029749890757553663 total_time 722.0\n",
      "episode 1625, reward 760.0, memory_length 2000, epsilon 0.0002960151255838497 total_time 732.0\n",
      "episode 1626, reward 806.0, memory_length 2000, epsilon 0.00029453874398571923 total_time 722.0\n",
      "episode 1627, reward 635.0, memory_length 2000, epsilon 0.00029306972587152957 total_time 732.0\n",
      "episode 1628, reward 603.0, memory_length 2000, epsilon 0.0002916080345157502 total_time 722.0\n",
      "episode 1629, reward 1200.0, memory_length 2000, epsilon 0.0002901536333760222 total_time 726.0\n",
      "episode 1630, reward 766.0, memory_length 2000, epsilon 0.0002887064860922402 total_time 727.0\n",
      "Saving Model 1630\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1631, reward 843.0, memory_length 2000, epsilon 0.0002872665564856478 total_time 725.0\n",
      "episode 1632, reward 933.0, memory_length 2000, epsilon 0.000285833808557929 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1633, reward 1172.0, memory_length 2000, epsilon 0.00028440820649031117 total_time 728.0\n",
      "episode 1634, reward 1280.0, memory_length 2000, epsilon 0.00028298971464266914 total_time 723.0\n",
      "episode 1635, reward 921.0, memory_length 2000, epsilon 0.0002815782975526317 total_time 727.0\n",
      "episode 1636, reward 565.0, memory_length 2000, epsilon 0.00028017391993469915 total_time 727.0\n",
      "episode 1637, reward 1048.0, memory_length 2000, epsilon 0.00027877654667935684 total_time 722.0\n",
      "episode 1638, reward 829.0, memory_length 2000, epsilon 0.00027738614285220166 total_time 721.0\n",
      "episode 1639, reward 770.0, memory_length 2000, epsilon 0.0002760026736930645 total_time 732.0\n",
      "episode 1640, reward 620.0, memory_length 2000, epsilon 0.0002746261046151453 total_time 729.0\n",
      "Saving Model 1640\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1641, reward 1199.0, memory_length 2000, epsilon 0.00027325640120414444 total_time 736.0\n",
      "episode 1642, reward 734.0, memory_length 2000, epsilon 0.0002718935292174058 total_time 721.0\n",
      "episode 1643, reward 859.0, memory_length 2000, epsilon 0.00027053745458305924 total_time 728.0\n",
      "episode 1644, reward 849.0, memory_length 2000, epsilon 0.0002691881433991673 total_time 726.0\n",
      "episode 1645, reward 505.0, memory_length 2000, epsilon 0.000267845561932881 total_time 727.0\n",
      "episode 1646, reward 1050.0, memory_length 2000, epsilon 0.00026650967661959277 total_time 723.0\n",
      "episode 1647, reward 801.0, memory_length 2000, epsilon 0.00026518045406210135 total_time 737.0\n",
      "episode 1648, reward 1032.0, memory_length 2000, epsilon 0.0002638578610297725 total_time 721.0\n",
      "episode 1649, reward 1110.0, memory_length 2000, epsilon 0.00026254186445771193 total_time 724.0\n",
      "episode 1650, reward 1045.0, memory_length 2000, epsilon 0.0002612324314459374 total_time 721.0\n",
      "Saving Model 1650\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1651, reward 954.0, memory_length 2000, epsilon 0.00025992952925855435 total_time 726.0\n",
      "episode 1652, reward 1013.0, memory_length 2000, epsilon 0.0002586331253229413 total_time 721.0\n",
      "episode 1653, reward 905.0, memory_length 2000, epsilon 0.0002573431872289313 total_time 726.0\n",
      "episode 1654, reward 1300.0, memory_length 2000, epsilon 0.00025605968272800585 total_time 729.0\n",
      "episode 1655, reward 842.0, memory_length 2000, epsilon 0.00025478257973248457 total_time 727.0\n",
      "episode 1656, reward 811.0, memory_length 2000, epsilon 0.0002535118463147269 total_time 722.0\n",
      "episode 1657, reward 475.0, memory_length 2000, epsilon 0.0002522474507063305 total_time 724.0\n",
      "episode 1658, reward 1072.0, memory_length 2000, epsilon 0.00025098936129733967 total_time 721.0\n",
      "episode 1659, reward 1327.0, memory_length 2000, epsilon 0.00024973754663545406 total_time 721.0\n",
      "episode 1660, reward 1015.0, memory_length 2000, epsilon 0.00024849197542524106 total_time 726.0\n",
      "Saving Model 1660\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1661, reward 980.0, memory_length 2000, epsilon 0.00024725261652735645 total_time 724.0\n",
      "episode 1662, reward 926.0, memory_length 2000, epsilon 0.00024601943895776233 total_time 731.0\n",
      "episode 1663, reward 913.0, memory_length 2000, epsilon 0.0002447924118869561 total_time 729.0\n",
      "episode 1664, reward 1140.0, memory_length 2000, epsilon 0.00024357150463919622 total_time 726.0\n",
      "episode 1665, reward 935.0, memory_length 2000, epsilon 0.00024235668669173879 total_time 722.0\n",
      "episode 1666, reward 679.0, memory_length 2000, epsilon 0.000241147927674071 total_time 729.0\n",
      "episode 1667, reward 1559.0, memory_length 2000, epsilon 0.00023994519736715483 total_time 721.0\n",
      "episode 1668, reward 1010.0, memory_length 2000, epsilon 0.00023874846570267044 total_time 731.0\n",
      "episode 1669, reward 1047.0, memory_length 2000, epsilon 0.000237557702762263 total_time 725.0\n",
      "episode 1670, reward 708.0, memory_length 2000, epsilon 0.00023637287877679785 total_time 726.0\n",
      "Saving Model 1670\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1671, reward 1018.0, memory_length 2000, epsilon 0.00023519396412561284 total_time 721.0\n",
      "episode 1672, reward 373.0, memory_length 2000, epsilon 0.00023402092933578103 total_time 722.0\n",
      "episode 1673, reward 1289.0, memory_length 2000, epsilon 0.0002328537450813708 total_time 730.0\n",
      "episode 1674, reward 771.0, memory_length 2000, epsilon 0.00023169238218271544 total_time 723.0\n",
      "episode 1675, reward 753.0, memory_length 2000, epsilon 0.0002305368116056824 total_time 721.0\n",
      "episode 1676, reward 1052.0, memory_length 2000, epsilon 0.00022938700446094618 total_time 722.0\n",
      "episode 1677, reward 1170.0, memory_length 2000, epsilon 0.00022824293200326916 total_time 728.0\n",
      "episode 1678, reward 1021.0, memory_length 2000, epsilon 0.0002271045656307795 total_time 722.0\n",
      "episode 1679, reward 838.0, memory_length 2000, epsilon 0.00022597187688425937 total_time 722.0\n",
      "episode 1680, reward 1564.0, memory_length 2000, epsilon 0.00022484483744643032 total_time 722.0\n",
      "Saving Model 1680\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1681, reward 1052.0, memory_length 2000, epsilon 0.00022372341914124848 total_time 726.0\n",
      "episode 1682, reward 838.0, memory_length 2000, epsilon 0.00022260759393319708 total_time 723.0\n",
      "episode 1683, reward 1346.0, memory_length 2000, epsilon 0.00022149733392658817 total_time 722.0\n",
      "episode 1684, reward 1180.0, memory_length 2000, epsilon 0.00022039261136486412 total_time 724.0\n",
      "episode 1685, reward 1388.0, memory_length 2000, epsilon 0.00021929339862990262 total_time 723.0\n",
      "episode 1686, reward 427.0, memory_length 2000, epsilon 0.00021819966824132878 total_time 731.0\n",
      "episode 1687, reward 1057.0, memory_length 2000, epsilon 0.00021711139285582518 total_time 729.0\n",
      "episode 1688, reward 684.0, memory_length 2000, epsilon 0.00021602854526645124 total_time 725.0\n",
      "episode 1689, reward 619.0, memory_length 2000, epsilon 0.00021495109840196007 total_time 731.0\n",
      "episode 1690, reward 1264.0, memory_length 2000, epsilon 0.00021387902532612473 total_time 727.0\n",
      "Saving Model 1690\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1691, reward 1302.0, memory_length 2000, epsilon 0.0002128122992370617 total_time 728.0\n",
      "episode 1692, reward 804.0, memory_length 2000, epsilon 0.00021175089346656356 total_time 729.0\n",
      "episode 1693, reward 830.0, memory_length 2000, epsilon 0.00021069478147943115 total_time 725.0\n",
      "episode 1694, reward 1186.0, memory_length 2000, epsilon 0.00020964393687280907 total_time 722.0\n",
      "episode 1695, reward 845.0, memory_length 2000, epsilon 0.00020859833337552816 total_time 730.0\n",
      "episode 1696, reward 718.0, memory_length 2000, epsilon 0.00020755794484744576 total_time 722.0\n",
      "episode 1697, reward 929.0, memory_length 2000, epsilon 0.00020652274527879525 total_time 724.0\n",
      "episode 1698, reward 1176.0, memory_length 2000, epsilon 0.00020549270878953273 total_time 724.0\n",
      "episode 1699, reward 835.0, memory_length 2000, epsilon 0.00020446780962869268 total_time 727.0\n",
      "episode 1700, reward 917.0, memory_length 2000, epsilon 0.0002034480221737431 total_time 722.0\n",
      "Saving Model 1700\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1701, reward 1028.0, memory_length 2000, epsilon 0.00020243332092994377 total_time 732.0\n",
      "episode 1702, reward 821.0, memory_length 2000, epsilon 0.00020142368052971147 total_time 727.0\n",
      "episode 1703, reward 842.0, memory_length 2000, epsilon 0.00020041907573198288 total_time 726.0\n",
      "episode 1704, reward 939.0, memory_length 2000, epsilon 0.0001994194814215864 total_time 725.0\n",
      "episode 1705, reward 966.0, memory_length 2000, epsilon 0.00019842487260861159 total_time 724.0\n",
      "episode 1706, reward 617.0, memory_length 2000, epsilon 0.00019743522442778697 total_time 722.0\n",
      "episode 1707, reward 973.0, memory_length 2000, epsilon 0.0001964505121378558 total_time 722.0\n",
      "episode 1708, reward 790.0, memory_length 2000, epsilon 0.00019547071112095988 total_time 727.0\n",
      "episode 1709, reward 512.0, memory_length 2000, epsilon 0.0001944957968820231 total_time 730.0\n",
      "episode 1710, reward 1194.0, memory_length 2000, epsilon 0.000193525745048138 total_time 726.0\n",
      "Saving Model 1710\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1711, reward 1002.0, memory_length 2000, epsilon 0.00019256053136795898 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1712, reward 972.0, memory_length 2000, epsilon 0.00019160013171109298 total_time 723.0\n",
      "episode 1713, reward 727.0, memory_length 2000, epsilon 0.00019064452206749927 total_time 723.0\n",
      "episode 1714, reward 1133.0, memory_length 2000, epsilon 0.00018969367854688635 total_time 731.0\n",
      "episode 1715, reward 1064.0, memory_length 2000, epsilon 0.00018874757737811696 total_time 729.0\n",
      "episode 1716, reward 782.0, memory_length 2000, epsilon 0.00018780619490861298 total_time 723.0\n",
      "episode 1717, reward 827.0, memory_length 2000, epsilon 0.00018686950760376297 total_time 721.0\n",
      "episode 1718, reward 655.0, memory_length 2000, epsilon 0.0001859374920463362 total_time 730.0\n",
      "episode 1719, reward 1158.0, memory_length 2000, epsilon 0.00018501012493589447 total_time 724.0\n",
      "episode 1720, reward 902.0, memory_length 2000, epsilon 0.00018408738308821243 total_time 725.0\n",
      "Saving Model 1720\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1721, reward 1044.0, memory_length 2000, epsilon 0.00018316924343469518 total_time 724.0\n",
      "episode 1722, reward 874.0, memory_length 2000, epsilon 0.00018225568302180416 total_time 722.0\n",
      "episode 1723, reward 930.0, memory_length 2000, epsilon 0.00018134667901048088 total_time 724.0\n",
      "episode 1724, reward 857.0, memory_length 2000, epsilon 0.00018044220867557802 total_time 723.0\n",
      "episode 1725, reward 1130.0, memory_length 2000, epsilon 0.00017954224940529038 total_time 727.0\n",
      "episode 1726, reward 1189.0, memory_length 2000, epsilon 0.00017864677870058874 total_time 728.0\n",
      "episode 1727, reward 857.0, memory_length 2000, epsilon 0.00017775577417465945 total_time 723.0\n",
      "episode 1728, reward 1051.0, memory_length 2000, epsilon 0.00017686921355234233 total_time 721.0\n",
      "episode 1729, reward 970.0, memory_length 2000, epsilon 0.00017598707466957628 total_time 725.0\n",
      "episode 1730, reward 900.0, memory_length 2000, epsilon 0.00017510933547284265 total_time 722.0\n",
      "Saving Model 1730\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1731, reward 668.0, memory_length 2000, epsilon 0.00017423597401861646 total_time 728.0\n",
      "episode 1732, reward 897.0, memory_length 2000, epsilon 0.00017336696847281523 total_time 721.0\n",
      "episode 1733, reward 635.0, memory_length 2000, epsilon 0.00017250229711025534 total_time 721.0\n",
      "episode 1734, reward 1238.0, memory_length 2000, epsilon 0.00017164193831410802 total_time 727.0\n",
      "episode 1735, reward 744.0, memory_length 2000, epsilon 0.0001707858705753579 total_time 723.0\n",
      "episode 1736, reward 596.0, memory_length 2000, epsilon 0.0001699340724922676 total_time 722.0\n",
      "episode 1737, reward 989.0, memory_length 2000, epsilon 0.00016908652276984007 total_time 729.0\n",
      "episode 1738, reward 1046.0, memory_length 2000, epsilon 0.00016824320021928865 total_time 731.0\n",
      "episode 1739, reward 785.0, memory_length 2000, epsilon 0.00016740408375750512 total_time 722.0\n",
      "episode 1740, reward 791.0, memory_length 2000, epsilon 0.00016656915240653448 total_time 723.0\n",
      "Saving Model 1740\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1741, reward 884.0, memory_length 2000, epsilon 0.00016573838529304976 total_time 721.0\n",
      "episode 1742, reward 594.0, memory_length 2000, epsilon 0.00016491176164782934 total_time 722.0\n",
      "episode 1743, reward 946.0, memory_length 2000, epsilon 0.0001640892608052395 total_time 726.0\n",
      "episode 1744, reward 1037.0, memory_length 2000, epsilon 0.00016327086220271588 total_time 722.0\n",
      "episode 1745, reward 462.0, memory_length 2000, epsilon 0.0001624565453802513 total_time 729.0\n",
      "episode 1746, reward 654.0, memory_length 2000, epsilon 0.00016164628997988222 total_time 725.0\n",
      "episode 1747, reward 819.0, memory_length 2000, epsilon 0.00016084007574518203 total_time 722.0\n",
      "episode 1748, reward 271.0, memory_length 2000, epsilon 0.00016003788252075222 total_time 723.0\n",
      "episode 1749, reward 720.0, memory_length 2000, epsilon 0.00015923969025172078 total_time 722.0\n",
      "episode 1750, reward 658.0, memory_length 2000, epsilon 0.0001584454789832397 total_time 733.0\n",
      "Saving Model 1750\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1751, reward 1068.0, memory_length 2000, epsilon 0.00015765522885998522 total_time 726.0\n",
      "episode 1752, reward 768.0, memory_length 2000, epsilon 0.00015686892012566376 total_time 721.0\n",
      "episode 1753, reward 640.0, memory_length 2000, epsilon 0.00015608653312251545 total_time 725.0\n",
      "episode 1754, reward 869.0, memory_length 2000, epsilon 0.00015530804829082498 total_time 724.0\n",
      "episode 1755, reward 765.0, memory_length 2000, epsilon 0.00015453344616843045 total_time 723.0\n",
      "episode 1756, reward 663.0, memory_length 2000, epsilon 0.00015376270739023907 total_time 721.0\n",
      "episode 1757, reward 987.0, memory_length 2000, epsilon 0.00015299581268774062 total_time 721.0\n",
      "episode 1758, reward 580.0, memory_length 2000, epsilon 0.0001522327428885279 total_time 735.0\n",
      "episode 1759, reward 959.0, memory_length 2000, epsilon 0.0001514734789158165 total_time 726.0\n",
      "episode 1760, reward 919.0, memory_length 2000, epsilon 0.00015071800178796695 total_time 729.0\n",
      "Saving Model 1760\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1761, reward 896.0, memory_length 2000, epsilon 0.00014996629261801228 total_time 725.0\n",
      "episode 1762, reward 917.0, memory_length 2000, epsilon 0.0001492183326131835 total_time 723.0\n",
      "episode 1763, reward 863.0, memory_length 2000, epsilon 0.00014847410307444219 total_time 725.0\n",
      "episode 1764, reward 998.0, memory_length 2000, epsilon 0.00014773358539601044 total_time 725.0\n",
      "episode 1765, reward 1034.0, memory_length 2000, epsilon 0.00014699676106490808 total_time 725.0\n",
      "episode 1766, reward 1043.0, memory_length 2000, epsilon 0.0001462636116604887 total_time 725.0\n",
      "episode 1767, reward 845.0, memory_length 2000, epsilon 0.00014553411885397845 total_time 721.0\n",
      "episode 1768, reward 710.0, memory_length 2000, epsilon 0.00014480826440801974 total_time 723.0\n",
      "episode 1769, reward 933.0, memory_length 2000, epsilon 0.00014408603017621307 total_time 724.0\n",
      "episode 1770, reward 870.0, memory_length 2000, epsilon 0.00014336739810266554 total_time 727.0\n",
      "Saving Model 1770\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1771, reward 993.0, memory_length 2000, epsilon 0.0001426523502215374 total_time 730.0\n",
      "episode 1772, reward 1018.0, memory_length 2000, epsilon 0.00014194086865659486 total_time 731.0\n",
      "episode 1773, reward 770.0, memory_length 2000, epsilon 0.0001412329356207612 total_time 722.0\n",
      "episode 1774, reward 962.0, memory_length 2000, epsilon 0.000140528533415674 total_time 723.0\n",
      "episode 1775, reward 735.0, memory_length 2000, epsilon 0.00013982764443124163 total_time 725.0\n",
      "episode 1776, reward 897.0, memory_length 2000, epsilon 0.00013913025114520249 total_time 721.0\n",
      "episode 1777, reward 815.0, memory_length 2000, epsilon 0.00013843633612268858 total_time 723.0\n",
      "episode 1778, reward 814.0, memory_length 2000, epsilon 0.00013774588201578773 total_time 726.0\n",
      "episode 1779, reward 1393.0, memory_length 2000, epsilon 0.0001370588715631118 total_time 725.0\n",
      "episode 1780, reward 740.0, memory_length 2000, epsilon 0.0001363752875893632 total_time 724.0\n",
      "Saving Model 1780\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1781, reward 859.0, memory_length 2000, epsilon 0.00013569511300490745 total_time 733.0\n",
      "episode 1782, reward 1124.0, memory_length 2000, epsilon 0.00013501833080534404 total_time 721.0\n",
      "episode 1783, reward 1033.0, memory_length 2000, epsilon 0.00013434492407108297 total_time 724.0\n",
      "episode 1784, reward 937.0, memory_length 2000, epsilon 0.0001336748759669211 total_time 724.0\n",
      "episode 1785, reward 1231.0, memory_length 2000, epsilon 0.00013300816974162033 total_time 723.0\n",
      "episode 1786, reward 942.0, memory_length 2000, epsilon 0.0001323447887274909 total_time 725.0\n",
      "episode 1787, reward 916.0, memory_length 2000, epsilon 0.0001316847163399724 total_time 726.0\n",
      "episode 1788, reward 1180.0, memory_length 2000, epsilon 0.00013102793607722117 total_time 726.0\n",
      "episode 1789, reward 707.0, memory_length 2000, epsilon 0.00013037443151969603 total_time 726.0\n",
      "episode 1790, reward 773.0, memory_length 2000, epsilon 0.00012972418632974922 total_time 725.0\n",
      "Saving Model 1790\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1791, reward 389.0, memory_length 2000, epsilon 0.00012907718425121738 total_time 729.0\n",
      "episode 1792, reward 938.0, memory_length 2000, epsilon 0.00012843340910901436 total_time 724.0\n",
      "episode 1793, reward 1781.0, memory_length 2000, epsilon 0.0001277928448087285 total_time 732.0\n",
      "episode 1794, reward 683.0, memory_length 2000, epsilon 0.00012715547533621857 total_time 723.0\n",
      "episode 1795, reward 1017.0, memory_length 2000, epsilon 0.00012652128475721495 total_time 722.0\n",
      "episode 1796, reward 786.0, memory_length 2000, epsilon 0.00012589025721691967 total_time 727.0\n",
      "episode 1797, reward 741.0, memory_length 2000, epsilon 0.00012526237693961183 total_time 726.0\n",
      "episode 1798, reward 703.0, memory_length 2000, epsilon 0.00012463762822825135 total_time 724.0\n",
      "episode 1799, reward 1060.0, memory_length 2000, epsilon 0.0001240159954640881 total_time 723.0\n",
      "episode 1800, reward 827.0, memory_length 2000, epsilon 0.00012339746310627089 total_time 721.0\n",
      "Saving Model 1800\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1801, reward 814.0, memory_length 2000, epsilon 0.00012278201569145803 total_time 721.0\n",
      "episode 1802, reward 1001.0, memory_length 2000, epsilon 0.0001221696378334326 total_time 722.0\n",
      "episode 1803, reward 773.0, memory_length 2000, epsilon 0.00012156031422271581 total_time 721.0\n",
      "episode 1804, reward 1001.0, memory_length 2000, epsilon 0.00012095402962618606 total_time 722.0\n",
      "episode 1805, reward 798.0, memory_length 2000, epsilon 0.00012035076888669644 total_time 721.0\n",
      "episode 1806, reward 1177.0, memory_length 2000, epsilon 0.00011975051692269749 total_time 722.0\n",
      "episode 1807, reward 794.0, memory_length 2000, epsilon 0.00011915325872785838 total_time 728.0\n",
      "episode 1808, reward 716.0, memory_length 2000, epsilon 0.00011855897937069339 total_time 731.0\n",
      "episode 1809, reward 836.0, memory_length 2000, epsilon 0.00011796766399418783 total_time 726.0\n",
      "episode 1810, reward 923.0, memory_length 2000, epsilon 0.00011737929781542605 total_time 735.0\n",
      "Saving Model 1810\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1811, reward 879.0, memory_length 2000, epsilon 0.0001167938661252234 total_time 722.0\n",
      "episode 1812, reward 775.0, memory_length 2000, epsilon 0.00011621135428775669 total_time 722.0\n",
      "episode 1813, reward 850.0, memory_length 2000, epsilon 0.00011563174774020004 total_time 724.0\n",
      "episode 1814, reward 1299.0, memory_length 2000, epsilon 0.00011505503199235919 total_time 731.0\n",
      "episode 1815, reward 876.0, memory_length 2000, epsilon 0.0001144811926263106 total_time 722.0\n",
      "episode 1816, reward 724.0, memory_length 2000, epsilon 0.00011391021529604046 total_time 728.0\n",
      "episode 1817, reward 744.0, memory_length 2000, epsilon 0.00011334208572708533 total_time 722.0\n",
      "episode 1818, reward 883.0, memory_length 2000, epsilon 0.00011277678971617682 total_time 725.0\n",
      "episode 1819, reward 1016.0, memory_length 2000, epsilon 0.00011221431313088481 total_time 724.0\n",
      "episode 1820, reward 586.0, memory_length 2000, epsilon 0.00011165464190926577 total_time 722.0\n",
      "Saving Model 1820\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1821, reward 786.0, memory_length 2000, epsilon 0.00011109776205950961 total_time 732.0\n",
      "episode 1822, reward 964.0, memory_length 2000, epsilon 0.00011054365965959149 total_time 721.0\n",
      "episode 1823, reward 904.0, memory_length 2000, epsilon 0.00010999232085692214 total_time 721.0\n",
      "episode 1824, reward 1080.0, memory_length 2000, epsilon 0.000109443731868003 total_time 725.0\n",
      "episode 1825, reward 1232.0, memory_length 2000, epsilon 0.00010889787897808095 total_time 723.0\n",
      "episode 1826, reward 815.0, memory_length 2000, epsilon 0.00010835474854080491 total_time 728.0\n",
      "episode 1827, reward 866.0, memory_length 2000, epsilon 0.00010781432697788609 total_time 728.0\n",
      "episode 1828, reward 767.0, memory_length 2000, epsilon 0.00010727660077875683 total_time 724.0\n",
      "episode 1829, reward 903.0, memory_length 2000, epsilon 0.00010674155650023458 total_time 722.0\n",
      "episode 1830, reward 789.0, memory_length 2000, epsilon 0.00010620918076618411 total_time 730.0\n",
      "Saving Model 1830\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1831, reward 566.0, memory_length 2000, epsilon 0.0001056794602671847 total_time 727.0\n",
      "episode 1832, reward 1024.0, memory_length 2000, epsilon 0.00010515238176019594 total_time 729.0\n",
      "episode 1833, reward 1044.0, memory_length 2000, epsilon 0.00010462793206822786 total_time 724.0\n",
      "episode 1834, reward 712.0, memory_length 2000, epsilon 0.00010410609808001105 total_time 723.0\n",
      "episode 1835, reward 801.0, memory_length 2000, epsilon 0.00010358686674966826 total_time 723.0\n",
      "episode 1836, reward 677.0, memory_length 2000, epsilon 0.00010307022509638954 total_time 729.0\n",
      "episode 1837, reward 433.0, memory_length 2000, epsilon 0.0001025561602041063 total_time 721.0\n",
      "episode 1838, reward 421.0, memory_length 2000, epsilon 0.00010204465922116983 total_time 725.0\n",
      "episode 1839, reward 821.0, memory_length 2000, epsilon 0.00010153570936002852 total_time 726.0\n",
      "episode 1840, reward 888.0, memory_length 2000, epsilon 0.00010102929789690953 total_time 721.0\n",
      "Saving Model 1840\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1841, reward 719.0, memory_length 2000, epsilon 0.0001005254121715001 total_time 721.0\n",
      "episode 1842, reward 757.0, memory_length 2000, epsilon 0.00010002403958663047 total_time 728.0\n",
      "episode 1843, reward 405.0, memory_length 2000, epsilon 9.952516760796029e-05 total_time 721.0\n",
      "episode 1844, reward 413.0, memory_length 2000, epsilon 9.902878376366374e-05 total_time 726.0\n",
      "episode 1845, reward 1269.0, memory_length 2000, epsilon 9.85348756441192e-05 total_time 730.0\n",
      "episode 1846, reward 610.0, memory_length 2000, epsilon 9.804343090159762e-05 total_time 723.0\n",
      "episode 1847, reward 998.0, memory_length 2000, epsilon 9.755443724995518e-05 total_time 724.0\n",
      "episode 1848, reward 842.0, memory_length 2000, epsilon 9.706788246432478e-05 total_time 721.0\n",
      "episode 1849, reward 1051.0, memory_length 2000, epsilon 9.658375438081161e-05 total_time 727.0\n",
      "episode 1850, reward 771.0, memory_length 2000, epsilon 9.610204089618856e-05 total_time 733.0\n",
      "Saving Model 1850\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1851, reward 790.0, memory_length 2000, epsilon 9.562272996759305e-05 total_time 722.0\n",
      "episode 1852, reward 854.0, memory_length 2000, epsilon 9.514580961222725e-05 total_time 728.0\n",
      "episode 1853, reward 966.0, memory_length 2000, epsilon 9.467126790705711e-05 total_time 726.0\n",
      "episode 1854, reward 1220.0, memory_length 2000, epsilon 9.41990929885156e-05 total_time 724.0\n",
      "episode 1855, reward 1018.0, memory_length 2000, epsilon 9.372927305220485e-05 total_time 722.0\n",
      "episode 1856, reward 656.0, memory_length 2000, epsilon 9.326179635260231e-05 total_time 731.0\n",
      "episode 1857, reward 608.0, memory_length 2000, epsilon 9.279665120276581e-05 total_time 728.0\n",
      "episode 1858, reward 1303.0, memory_length 2000, epsilon 9.233382597404254e-05 total_time 722.0\n",
      "episode 1859, reward 805.0, memory_length 2000, epsilon 9.187330909577786e-05 total_time 721.0\n",
      "episode 1860, reward 514.0, memory_length 2000, epsilon 9.141508905502546e-05 total_time 727.0\n",
      "Saving Model 1860\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1861, reward 876.0, memory_length 2000, epsilon 9.095915439626081e-05 total_time 727.0\n",
      "episode 1862, reward 789.0, memory_length 2000, epsilon 9.050549372109336e-05 total_time 737.0\n",
      "episode 1863, reward 1573.0, memory_length 2000, epsilon 9.005409568798294e-05 total_time 722.0\n",
      "episode 1864, reward 917.0, memory_length 2000, epsilon 8.960494901195488e-05 total_time 727.0\n",
      "episode 1865, reward 402.0, memory_length 2000, epsilon 8.915804246431904e-05 total_time 738.0\n",
      "episode 1866, reward 1125.0, memory_length 2000, epsilon 8.871336487238863e-05 total_time 722.0\n",
      "episode 1867, reward 1150.0, memory_length 2000, epsilon 8.827090511920035e-05 total_time 724.0\n",
      "episode 1868, reward 767.0, memory_length 2000, epsilon 8.783065214323766e-05 total_time 731.0\n",
      "episode 1869, reward 866.0, memory_length 2000, epsilon 8.739259493815292e-05 total_time 724.0\n",
      "episode 1870, reward 1176.0, memory_length 2000, epsilon 8.695672255249348e-05 total_time 722.0\n",
      "Saving Model 1870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1871, reward 898.0, memory_length 2000, epsilon 8.652302408942669e-05 total_time 721.0\n",
      "episode 1872, reward 859.0, memory_length 2000, epsilon 8.609148870646871e-05 total_time 725.0\n",
      "episode 1873, reward 785.0, memory_length 2000, epsilon 8.56621056152122e-05 total_time 723.0\n",
      "episode 1874, reward 1287.0, memory_length 2000, epsilon 8.52348640810576e-05 total_time 726.0\n",
      "episode 1875, reward 673.0, memory_length 2000, epsilon 8.480975342294451e-05 total_time 725.0\n",
      "episode 1876, reward 903.0, memory_length 2000, epsilon 8.438676301308403e-05 total_time 731.0\n",
      "episode 1877, reward 480.0, memory_length 2000, epsilon 8.396588227669418e-05 total_time 722.0\n",
      "episode 1878, reward 802.0, memory_length 2000, epsilon 8.35471006917343e-05 total_time 726.0\n",
      "episode 1879, reward 676.0, memory_length 2000, epsilon 8.313040778864329e-05 total_time 722.0\n",
      "episode 1880, reward 1135.0, memory_length 2000, epsilon 8.271579315007657e-05 total_time 721.0\n",
      "Saving Model 1880\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1881, reward 840.0, memory_length 2000, epsilon 8.230324641064687e-05 total_time 737.0\n",
      "episode 1882, reward 588.0, memory_length 2000, epsilon 8.18927572566639e-05 total_time 729.0\n",
      "episode 1883, reward 794.0, memory_length 2000, epsilon 8.14843154258776e-05 total_time 724.0\n",
      "episode 1884, reward 861.0, memory_length 2000, epsilon 8.107791070722108e-05 total_time 733.0\n",
      "episode 1885, reward 905.0, memory_length 2000, epsilon 8.067353294055492e-05 total_time 733.0\n",
      "episode 1886, reward 1037.0, memory_length 2000, epsilon 8.027117201641414e-05 total_time 724.0\n",
      "episode 1887, reward 852.0, memory_length 2000, epsilon 7.987081787575445e-05 total_time 721.0\n",
      "episode 1888, reward 662.0, memory_length 2000, epsilon 7.947246050970172e-05 total_time 724.0\n",
      "episode 1889, reward 665.0, memory_length 2000, epsilon 7.907608995930078e-05 total_time 730.0\n",
      "episode 1890, reward 657.0, memory_length 2000, epsilon 7.868169631526738e-05 total_time 724.0\n",
      "Saving Model 1890\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1891, reward 607.0, memory_length 2000, epsilon 7.828926971774001e-05 total_time 721.0\n",
      "episode 1892, reward 112.0, memory_length 2000, epsilon 7.789880035603303e-05 total_time 725.0\n",
      "episode 1893, reward 525.0, memory_length 2000, epsilon 7.751027846839229e-05 total_time 725.0\n",
      "episode 1894, reward 1129.0, memory_length 2000, epsilon 7.712369434175014e-05 total_time 729.0\n",
      "episode 1895, reward 949.0, memory_length 2000, epsilon 7.673903831148353e-05 total_time 729.0\n",
      "episode 1896, reward 822.0, memory_length 2000, epsilon 7.635630076117139e-05 total_time 725.0\n",
      "episode 1897, reward 940.0, memory_length 2000, epsilon 7.597547212235532e-05 total_time 723.0\n",
      "episode 1898, reward 918.0, memory_length 2000, epsilon 7.559654287429924e-05 total_time 724.0\n",
      "episode 1899, reward 609.0, memory_length 2000, epsilon 7.521950354375232e-05 total_time 730.0\n",
      "episode 1900, reward 941.0, memory_length 2000, epsilon 7.484434470471183e-05 total_time 725.0\n",
      "Saving Model 1900\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1901, reward 572.0, memory_length 2000, epsilon 7.447105697818695e-05 total_time 726.0\n",
      "episode 1902, reward 748.0, memory_length 2000, epsilon 7.409963103196539e-05 total_time 722.0\n",
      "episode 1903, reward 951.0, memory_length 2000, epsilon 7.373005758037883e-05 total_time 722.0\n",
      "episode 1904, reward 591.0, memory_length 2000, epsilon 7.336232738407203e-05 total_time 724.0\n",
      "episode 1905, reward 1537.0, memory_length 2000, epsilon 7.299643124977067e-05 total_time 726.0\n",
      "episode 1906, reward 822.0, memory_length 2000, epsilon 7.263236003005257e-05 total_time 721.0\n",
      "episode 1907, reward 1095.0, memory_length 2000, epsilon 7.227010462311804e-05 total_time 733.0\n",
      "episode 1908, reward 682.0, memory_length 2000, epsilon 7.190965597256315e-05 total_time 721.0\n",
      "episode 1909, reward 838.0, memory_length 2000, epsilon 7.155100506715302e-05 total_time 726.0\n",
      "episode 1910, reward 766.0, memory_length 2000, epsilon 7.119414294059604e-05 total_time 724.0\n",
      "Saving Model 1910\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1911, reward 1052.0, memory_length 2000, epsilon 7.083906067132073e-05 total_time 728.0\n",
      "episode 1912, reward 879.0, memory_length 2000, epsilon 7.048574938225162e-05 total_time 727.0\n",
      "episode 1913, reward 981.0, memory_length 2000, epsilon 7.013420024058834e-05 total_time 726.0\n",
      "episode 1914, reward 1036.0, memory_length 2000, epsilon 6.978440445758377e-05 total_time 727.0\n",
      "episode 1915, reward 911.0, memory_length 2000, epsilon 6.943635328832523e-05 total_time 723.0\n",
      "episode 1916, reward 766.0, memory_length 2000, epsilon 6.909003803151554e-05 total_time 724.0\n",
      "episode 1917, reward 936.0, memory_length 2000, epsilon 6.87454500292549e-05 total_time 726.0\n",
      "episode 1918, reward 807.0, memory_length 2000, epsilon 6.840258066682564e-05 total_time 724.0\n",
      "episode 1919, reward 615.0, memory_length 2000, epsilon 6.806142137247558e-05 total_time 721.0\n",
      "episode 1920, reward 920.0, memory_length 2000, epsilon 6.772196361720481e-05 total_time 724.0\n",
      "Saving Model 1920\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1921, reward 1208.0, memory_length 2000, epsilon 6.738419891455154e-05 total_time 727.0\n",
      "episode 1922, reward 920.0, memory_length 2000, epsilon 6.704811882038083e-05 total_time 730.0\n",
      "episode 1923, reward 948.0, memory_length 2000, epsilon 6.671371493267263e-05 total_time 728.0\n",
      "episode 1924, reward 654.0, memory_length 2000, epsilon 6.638097889131242e-05 total_time 725.0\n",
      "episode 1925, reward 1066.0, memory_length 2000, epsilon 6.604990237788195e-05 total_time 721.0\n",
      "episode 1926, reward 699.0, memory_length 2000, epsilon 6.572047711545091e-05 total_time 731.0\n",
      "episode 1927, reward 928.0, memory_length 2000, epsilon 6.539269486837081e-05 total_time 728.0\n",
      "episode 1928, reward 767.0, memory_length 2000, epsilon 6.506654744206819e-05 total_time 725.0\n",
      "episode 1929, reward 827.0, memory_length 2000, epsilon 6.474202668284061e-05 total_time 723.0\n",
      "episode 1930, reward 570.0, memory_length 2000, epsilon 6.441912447765199e-05 total_time 723.0\n",
      "Saving Model 1930\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1931, reward 913.0, memory_length 2000, epsilon 6.409783275393057e-05 total_time 726.0\n",
      "episode 1932, reward 715.0, memory_length 2000, epsilon 6.377814347936633e-05 total_time 724.0\n",
      "episode 1933, reward 873.0, memory_length 2000, epsilon 6.346004866171084e-05 total_time 724.0\n",
      "episode 1934, reward 1019.0, memory_length 2000, epsilon 6.314354034857722e-05 total_time 725.0\n",
      "episode 1935, reward 724.0, memory_length 2000, epsilon 6.282861062724095e-05 total_time 721.0\n",
      "episode 1936, reward 519.0, memory_length 2000, epsilon 6.251525162444278e-05 total_time 723.0\n",
      "episode 1937, reward 992.0, memory_length 2000, epsilon 6.220345550619113e-05 total_time 723.0\n",
      "episode 1938, reward 777.0, memory_length 2000, epsilon 6.189321447756698e-05 total_time 731.0\n",
      "episode 1939, reward 733.0, memory_length 2000, epsilon 6.15845207825283e-05 total_time 726.0\n",
      "episode 1940, reward 986.0, memory_length 2000, epsilon 6.12773667037167e-05 total_time 724.0\n",
      "Saving Model 1940\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1941, reward 844.0, memory_length 2000, epsilon 6.0971744562264344e-05 total_time 725.0\n",
      "episode 1942, reward 1330.0, memory_length 2000, epsilon 6.066764671760154e-05 total_time 726.0\n",
      "episode 1943, reward 493.0, memory_length 2000, epsilon 6.036506556726657e-05 total_time 725.0\n",
      "episode 1944, reward 955.0, memory_length 2000, epsilon 6.0063993546714685e-05 total_time 721.0\n",
      "episode 1945, reward 808.0, memory_length 2000, epsilon 5.9764423129129905e-05 total_time 724.0\n",
      "episode 1946, reward 718.0, memory_length 2000, epsilon 5.946634682523599e-05 total_time 723.0\n",
      "episode 1947, reward 886.0, memory_length 2000, epsilon 5.916975718311002e-05 total_time 724.0\n",
      "episode 1948, reward 1317.0, memory_length 2000, epsilon 5.887464678799527e-05 total_time 722.0\n",
      "episode 1949, reward 691.0, memory_length 2000, epsilon 5.858100826211662e-05 total_time 723.0\n",
      "episode 1950, reward 781.0, memory_length 2000, epsilon 5.8288834264495724e-05 total_time 721.0\n",
      "Saving Model 1950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1951, reward 1147.0, memory_length 2000, epsilon 5.799811749076721e-05 total_time 724.0\n",
      "episode 1952, reward 1090.0, memory_length 2000, epsilon 5.770885067299681e-05 total_time 724.0\n",
      "episode 1953, reward 940.0, memory_length 2000, epsilon 5.7421026579498806e-05 total_time 724.0\n",
      "episode 1954, reward 1223.0, memory_length 2000, epsilon 5.713463801465607e-05 total_time 723.0\n",
      "episode 1955, reward 1028.0, memory_length 2000, epsilon 5.6849677818739366e-05 total_time 721.0\n",
      "episode 1956, reward 752.0, memory_length 2000, epsilon 5.656613886772915e-05 total_time 725.0\n",
      "episode 1957, reward 759.0, memory_length 2000, epsilon 5.6284014073136684e-05 total_time 728.0\n",
      "episode 1958, reward 1282.0, memory_length 2000, epsilon 5.600329638182751e-05 total_time 722.0\n",
      "episode 1959, reward 1298.0, memory_length 2000, epsilon 5.572397877584482e-05 total_time 729.0\n",
      "episode 1960, reward 1276.0, memory_length 2000, epsilon 5.544605427223373e-05 total_time 725.0\n",
      "Saving Model 1960\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1961, reward 610.0, memory_length 2000, epsilon 5.516951592286735e-05 total_time 725.0\n",
      "episode 1962, reward 932.0, memory_length 2000, epsilon 5.4894356814272356e-05 total_time 724.0\n",
      "episode 1963, reward 874.0, memory_length 2000, epsilon 5.462057006745691e-05 total_time 727.0\n",
      "episode 1964, reward 867.0, memory_length 2000, epsilon 5.434814883773787e-05 total_time 722.0\n",
      "episode 1965, reward 1023.0, memory_length 2000, epsilon 5.407708631457042e-05 total_time 722.0\n",
      "episode 1966, reward 1202.0, memory_length 2000, epsilon 5.380737572137743e-05 total_time 728.0\n",
      "episode 1967, reward 1267.0, memory_length 2000, epsilon 5.353901031537986e-05 total_time 729.0\n",
      "episode 1968, reward 975.0, memory_length 2000, epsilon 5.3271983387428765e-05 total_time 728.0\n",
      "episode 1969, reward 1367.0, memory_length 2000, epsilon 5.300628826183684e-05 total_time 721.0\n",
      "episode 1970, reward 1149.0, memory_length 2000, epsilon 5.27419182962123e-05 total_time 725.0\n",
      "Saving Model 1970\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1971, reward 1316.0, memory_length 2000, epsilon 5.247886688129205e-05 total_time 728.0\n",
      "episode 1972, reward 1279.0, memory_length 2000, epsilon 5.22171274407772e-05 total_time 734.0\n",
      "episode 1973, reward 859.0, memory_length 2000, epsilon 5.195669343116792e-05 total_time 722.0\n",
      "episode 1974, reward 1169.0, memory_length 2000, epsilon 5.169755834160051e-05 total_time 722.0\n",
      "episode 1975, reward 785.0, memory_length 2000, epsilon 5.143971569368431e-05 total_time 721.0\n",
      "episode 1976, reward 1183.0, memory_length 2000, epsilon 5.1183159041339513e-05 total_time 722.0\n",
      "episode 1977, reward 641.0, memory_length 2000, epsilon 5.0927881970636635e-05 total_time 729.0\n",
      "episode 1978, reward 512.0, memory_length 2000, epsilon 5.067387809963542e-05 total_time 722.0\n",
      "episode 1979, reward 849.0, memory_length 2000, epsilon 5.042114107822606e-05 total_time 724.0\n",
      "episode 1980, reward 1367.0, memory_length 2000, epsilon 5.0169664587969665e-05 total_time 730.0\n",
      "Saving Model 1980\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1981, reward 698.0, memory_length 2000, epsilon 4.991944234194107e-05 total_time 726.0\n",
      "episode 1982, reward 1015.0, memory_length 2000, epsilon 4.9670468084570904e-05 total_time 725.0\n",
      "episode 1983, reward 1129.0, memory_length 2000, epsilon 4.9422735591489856e-05 total_time 724.0\n",
      "episode 1984, reward 784.0, memory_length 2000, epsilon 4.917623866937279e-05 total_time 724.0\n",
      "episode 1985, reward 835.0, memory_length 2000, epsilon 4.8930971155783633e-05 total_time 728.0\n",
      "episode 1986, reward 902.0, memory_length 2000, epsilon 4.868692691902195e-05 total_time 723.0\n",
      "episode 1987, reward 982.0, memory_length 2000, epsilon 4.844409985796893e-05 total_time 724.0\n",
      "episode 1988, reward 924.0, memory_length 2000, epsilon 4.820248390193559e-05 total_time 724.0\n",
      "episode 1989, reward 1068.0, memory_length 2000, epsilon 4.7962073010510255e-05 total_time 726.0\n",
      "episode 1990, reward 1357.0, memory_length 2000, epsilon 4.77228611734082e-05 total_time 721.0\n",
      "Saving Model 1990\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 1991, reward 1256.0, memory_length 2000, epsilon 4.748484241032114e-05 total_time 725.0\n",
      "episode 1992, reward 1185.0, memory_length 2000, epsilon 4.7248010770767435e-05 total_time 724.0\n",
      "episode 1993, reward 1041.0, memory_length 2000, epsilon 4.70123603339439e-05 total_time 723.0\n",
      "episode 1994, reward 849.0, memory_length 2000, epsilon 4.6777885208577205e-05 total_time 729.0\n",
      "episode 1995, reward 1134.0, memory_length 2000, epsilon 4.6544579532777155e-05 total_time 722.0\n",
      "episode 1996, reward 635.0, memory_length 2000, epsilon 4.631243747388954e-05 total_time 725.0\n",
      "episode 1997, reward 1148.0, memory_length 2000, epsilon 4.608145322835096e-05 total_time 726.0\n",
      "episode 1998, reward 711.0, memory_length 2000, epsilon 4.585162102154309e-05 total_time 723.0\n",
      "episode 1999, reward 785.0, memory_length 2000, epsilon 4.562293510764886e-05 total_time 725.0\n",
      "episode 2000, reward 1153.0, memory_length 2000, epsilon 4.539538976950861e-05 total_time 723.0\n",
      "Saving Model 2000\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2001, reward 1101.0, memory_length 2000, epsilon 4.516897931847685e-05 total_time 721.0\n",
      "episode 2002, reward 752.0, memory_length 2000, epsilon 4.4943698094280685e-05 total_time 731.0\n",
      "episode 2003, reward 963.0, memory_length 2000, epsilon 4.471954046487762e-05 total_time 722.0\n",
      "episode 2004, reward 848.0, memory_length 2000, epsilon 4.4496500826315406e-05 total_time 721.0\n",
      "episode 2005, reward 779.0, memory_length 2000, epsilon 4.42745736025913e-05 total_time 722.0\n",
      "episode 2006, reward 467.0, memory_length 2000, epsilon 4.405375324551329e-05 total_time 732.0\n",
      "episode 2007, reward 493.0, memory_length 2000, epsilon 4.3834034234560825e-05 total_time 731.0\n",
      "episode 2008, reward 499.0, memory_length 2000, epsilon 4.361541107674724e-05 total_time 726.0\n",
      "episode 2009, reward 478.0, memory_length 2000, epsilon 4.339787830648229e-05 total_time 727.0\n",
      "episode 2010, reward 626.0, memory_length 2000, epsilon 4.318143048543524e-05 total_time 721.0\n",
      "Saving Model 2010\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2011, reward 270.0, memory_length 2000, epsilon 4.296606220239943e-05 total_time 728.0\n",
      "episode 2012, reward 1071.0, memory_length 2000, epsilon 4.2751768073156425e-05 total_time 725.0\n",
      "episode 2013, reward 750.0, memory_length 2000, epsilon 4.253854274034198e-05 total_time 725.0\n",
      "episode 2014, reward 199.0, memory_length 2000, epsilon 4.232638087331152e-05 total_time 722.0\n",
      "episode 2015, reward 594.0, memory_length 2000, epsilon 4.211527716800739e-05 total_time 724.0\n",
      "episode 2016, reward 752.0, memory_length 2000, epsilon 4.190522634682605e-05 total_time 721.0\n",
      "episode 2017, reward 434.0, memory_length 2000, epsilon 4.169622315848586e-05 total_time 732.0\n",
      "episode 2018, reward 714.0, memory_length 2000, epsilon 4.1488262377896394e-05 total_time 725.0\n",
      "episode 2019, reward 509.0, memory_length 2000, epsilon 4.1281338806027145e-05 total_time 729.0\n",
      "episode 2020, reward 685.0, memory_length 2000, epsilon 4.1075447269778196e-05 total_time 730.0\n",
      "Saving Model 2020\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2021, reward 616.0, memory_length 2000, epsilon 4.087058262185026e-05 total_time 722.0\n",
      "episode 2022, reward 667.0, memory_length 2000, epsilon 4.066673974061663e-05 total_time 721.0\n",
      "episode 2023, reward 635.0, memory_length 2000, epsilon 4.04639135299945e-05 total_time 723.0\n",
      "episode 2024, reward 755.0, memory_length 2000, epsilon 4.026209891931811e-05 total_time 724.0\n",
      "episode 2025, reward 865.0, memory_length 2000, epsilon 4.006129086321177e-05 total_time 727.0\n",
      "episode 2026, reward 892.0, memory_length 2000, epsilon 3.986148434146347e-05 total_time 723.0\n",
      "episode 2027, reward 655.0, memory_length 2000, epsilon 3.966267435889989e-05 total_time 726.0\n",
      "episode 2028, reward 748.0, memory_length 2000, epsilon 3.946485594526098e-05 total_time 724.0\n",
      "episode 2029, reward 792.0, memory_length 2000, epsilon 3.926802415507623e-05 total_time 722.0\n",
      "episode 2030, reward 413.0, memory_length 2000, epsilon 3.907217406754051e-05 total_time 721.0\n",
      "Saving Model 2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2031, reward 436.0, memory_length 2000, epsilon 3.887730078639155e-05 total_time 725.0\n",
      "episode 2032, reward 616.0, memory_length 2000, epsilon 3.868339943978704e-05 total_time 726.0\n",
      "episode 2033, reward 844.0, memory_length 2000, epsilon 3.849046518018329e-05 total_time 724.0\n",
      "episode 2034, reward 1177.0, memory_length 2000, epsilon 3.829849318421383e-05 total_time 728.0\n",
      "episode 2035, reward 839.0, memory_length 2000, epsilon 3.810747865256862e-05 total_time 721.0\n",
      "episode 2036, reward 940.0, memory_length 2000, epsilon 3.791741680987456e-05 total_time 721.0\n",
      "episode 2037, reward 1282.0, memory_length 2000, epsilon 3.772830290457554e-05 total_time 726.0\n",
      "episode 2038, reward 776.0, memory_length 2000, epsilon 3.754013220881422e-05 total_time 724.0\n",
      "episode 2039, reward 1180.0, memory_length 2000, epsilon 3.735290001831327e-05 total_time 728.0\n",
      "episode 2040, reward 818.0, memory_length 2000, epsilon 3.716660165225826e-05 total_time 728.0\n",
      "Saving Model 2040\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2041, reward 1025.0, memory_length 2000, epsilon 3.698123245318036e-05 total_time 728.0\n",
      "episode 2042, reward 940.0, memory_length 2000, epsilon 3.679678778683984e-05 total_time 721.0\n",
      "episode 2043, reward 1062.0, memory_length 2000, epsilon 3.6613263042110564e-05 total_time 725.0\n",
      "episode 2044, reward 1476.0, memory_length 2000, epsilon 3.643065363086422e-05 total_time 726.0\n",
      "episode 2045, reward 1329.0, memory_length 2000, epsilon 3.624895498785613e-05 total_time 723.0\n",
      "episode 2046, reward 1259.0, memory_length 2000, epsilon 3.606816257061065e-05 total_time 722.0\n",
      "episode 2047, reward 1012.0, memory_length 2000, epsilon 3.588827185930805e-05 total_time 724.0\n",
      "episode 2048, reward 688.0, memory_length 2000, epsilon 3.5709278356671046e-05 total_time 721.0\n",
      "episode 2049, reward 904.0, memory_length 2000, epsilon 3.553117758785282e-05 total_time 722.0\n",
      "episode 2050, reward 954.0, memory_length 2000, epsilon 3.535396510032494e-05 total_time 726.0\n",
      "Saving Model 2050\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2051, reward 1110.0, memory_length 2000, epsilon 3.5177636463765865e-05 total_time 722.0\n",
      "episode 2052, reward 1338.0, memory_length 2000, epsilon 3.5002187269950606e-05 total_time 726.0\n",
      "episode 2053, reward 1518.0, memory_length 2000, epsilon 3.482761313264007e-05 total_time 725.0\n",
      "episode 2054, reward 1083.0, memory_length 2000, epsilon 3.465390968747185e-05 total_time 721.0\n",
      "episode 2055, reward 1120.0, memory_length 2000, epsilon 3.4481072591850646e-05 total_time 738.0\n",
      "episode 2056, reward 1280.0, memory_length 2000, epsilon 3.43090975248402e-05 total_time 722.0\n",
      "episode 2057, reward 678.0, memory_length 2000, epsilon 3.413798018705474e-05 total_time 724.0\n",
      "episode 2058, reward 1185.0, memory_length 2000, epsilon 3.396771630055198e-05 total_time 726.0\n",
      "episode 2059, reward 1016.0, memory_length 2000, epsilon 3.379830160872594e-05 total_time 725.0\n",
      "episode 2060, reward 1254.0, memory_length 2000, epsilon 3.36297318762004e-05 total_time 727.0\n",
      "Saving Model 2060\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2061, reward 1146.0, memory_length 2000, epsilon 3.346200288872337e-05 total_time 724.0\n",
      "episode 2062, reward 1296.0, memory_length 2000, epsilon 3.329511045306131e-05 total_time 726.0\n",
      "episode 2063, reward 789.0, memory_length 2000, epsilon 3.3129050396894754e-05 total_time 723.0\n",
      "episode 2064, reward 1178.0, memory_length 2000, epsilon 3.296381856871355e-05 total_time 725.0\n",
      "episode 2065, reward 827.0, memory_length 2000, epsilon 3.2799410837713413e-05 total_time 729.0\n",
      "episode 2066, reward 1044.0, memory_length 2000, epsilon 3.263582309369259e-05 total_time 729.0\n",
      "episode 2067, reward 1077.0, memory_length 2000, epsilon 3.247305124694883e-05 total_time 728.0\n",
      "episode 2068, reward 1138.0, memory_length 2000, epsilon 3.2311091228177617e-05 total_time 721.0\n",
      "episode 2069, reward 1010.0, memory_length 2000, epsilon 3.2149938988369914e-05 total_time 723.0\n",
      "episode 2070, reward 1143.0, memory_length 2000, epsilon 3.198959049871146e-05 total_time 726.0\n",
      "Saving Model 2070\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2071, reward 950.0, memory_length 2000, epsilon 3.1830041750481536e-05 total_time 721.0\n",
      "episode 2072, reward 1110.0, memory_length 2000, epsilon 3.1671288754953246e-05 total_time 722.0\n",
      "episode 2073, reward 1080.0, memory_length 2000, epsilon 3.1513327543293325e-05 total_time 724.0\n",
      "episode 2074, reward 971.0, memory_length 2000, epsilon 3.1356154166463317e-05 total_time 729.0\n",
      "episode 2075, reward 602.0, memory_length 2000, epsilon 3.1199764695120645e-05 total_time 727.0\n",
      "episode 2076, reward 487.0, memory_length 2000, epsilon 3.104415521952029e-05 total_time 723.0\n",
      "episode 2077, reward 1143.0, memory_length 2000, epsilon 3.0889321849417365e-05 total_time 727.0\n",
      "episode 2078, reward 864.0, memory_length 2000, epsilon 3.073526071396944e-05 total_time 721.0\n",
      "episode 2079, reward 550.0, memory_length 2000, epsilon 3.0581967961640214e-05 total_time 721.0\n",
      "episode 2080, reward 1183.0, memory_length 2000, epsilon 3.0429439760102783e-05 total_time 723.0\n",
      "Saving Model 2080\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2081, reward 789.0, memory_length 2000, epsilon 3.0277672296144284e-05 total_time 734.0\n",
      "episode 2082, reward 831.0, memory_length 2000, epsilon 3.0126661775570096e-05 total_time 726.0\n",
      "episode 2083, reward 985.0, memory_length 2000, epsilon 2.997640442310939e-05 total_time 726.0\n",
      "episode 2084, reward 905.0, memory_length 2000, epsilon 2.9826896482320594e-05 total_time 727.0\n",
      "episode 2085, reward 1359.0, memory_length 2000, epsilon 2.9678134215497287e-05 total_time 721.0\n",
      "episode 2086, reward 991.0, memory_length 2000, epsilon 2.9530113903575154e-05 total_time 726.0\n",
      "episode 2087, reward 1194.0, memory_length 2000, epsilon 2.9382831846038592e-05 total_time 722.0\n",
      "episode 2088, reward 664.0, memory_length 2000, epsilon 2.9236284360828585e-05 total_time 723.0\n",
      "episode 2089, reward 858.0, memory_length 2000, epsilon 2.9090467784250274e-05 total_time 724.0\n",
      "episode 2090, reward 778.0, memory_length 2000, epsilon 2.8945378470881694e-05 total_time 725.0\n",
      "Saving Model 2090\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2091, reward 702.0, memory_length 2000, epsilon 2.880101279348252e-05 total_time 724.0\n",
      "episode 2092, reward 1162.0, memory_length 2000, epsilon 2.865736714290318e-05 total_time 729.0\n",
      "episode 2093, reward 1055.0, memory_length 2000, epsilon 2.8514437927995037e-05 total_time 733.0\n",
      "episode 2094, reward 1101.0, memory_length 2000, epsilon 2.837222157552017e-05 total_time 727.0\n",
      "episode 2095, reward 1274.0, memory_length 2000, epsilon 2.8230714530062463e-05 total_time 727.0\n",
      "episode 2096, reward 762.0, memory_length 2000, epsilon 2.8089913253938308e-05 total_time 728.0\n",
      "episode 2097, reward 839.0, memory_length 2000, epsilon 2.7949814227108567e-05 total_time 721.0\n",
      "episode 2098, reward 521.0, memory_length 2000, epsilon 2.7810413947090177e-05 total_time 726.0\n",
      "episode 2099, reward 697.0, memory_length 2000, epsilon 2.7671708928868927e-05 total_time 730.0\n",
      "episode 2100, reward 819.0, memory_length 2000, epsilon 2.7533695704812185e-05 total_time 721.0\n",
      "Saving Model 2100\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2101, reward 758.0, memory_length 2000, epsilon 2.739637082458206e-05 total_time 721.0\n",
      "episode 2102, reward 844.0, memory_length 2000, epsilon 2.7259730855049492e-05 total_time 726.0\n",
      "episode 2103, reward 846.0, memory_length 2000, epsilon 2.712377238020803e-05 total_time 724.0\n",
      "episode 2104, reward 1312.0, memory_length 2000, epsilon 2.6988492001088823e-05 total_time 724.0\n",
      "episode 2105, reward 1306.0, memory_length 2000, epsilon 2.6853886335675243e-05 total_time 729.0\n",
      "episode 2106, reward 1189.0, memory_length 2000, epsilon 2.6719952018818745e-05 total_time 724.0\n",
      "episode 2107, reward 772.0, memory_length 2000, epsilon 2.6586685702154334e-05 total_time 721.0\n",
      "episode 2108, reward 1170.0, memory_length 2000, epsilon 2.6454084054017203e-05 total_time 723.0\n",
      "episode 2109, reward 978.0, memory_length 2000, epsilon 2.632214375935929e-05 total_time 724.0\n",
      "episode 2110, reward 489.0, memory_length 2000, epsilon 2.6190861519666257e-05 total_time 726.0\n",
      "Saving Model 2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2111, reward 459.0, memory_length 2000, epsilon 2.6060234052875372e-05 total_time 722.0\n",
      "episode 2112, reward 874.0, memory_length 2000, epsilon 2.5930258093293066e-05 total_time 725.0\n",
      "episode 2113, reward 1176.0, memory_length 2000, epsilon 2.5800930391513673e-05 total_time 723.0\n",
      "episode 2114, reward 791.0, memory_length 2000, epsilon 2.5672247714337826e-05 total_time 724.0\n",
      "episode 2115, reward 982.0, memory_length 2000, epsilon 2.5544206844691933e-05 total_time 730.0\n",
      "episode 2116, reward 973.0, memory_length 2000, epsilon 2.541680458154763e-05 total_time 721.0\n",
      "episode 2117, reward 614.0, memory_length 2000, epsilon 2.529003773984161e-05 total_time 727.0\n",
      "episode 2118, reward 666.0, memory_length 2000, epsilon 2.5163903150396327e-05 total_time 724.0\n",
      "episode 2119, reward 719.0, memory_length 2000, epsilon 2.503839765984038e-05 total_time 727.0\n",
      "episode 2120, reward 802.0, memory_length 2000, epsilon 2.4913518130530054e-05 total_time 726.0\n",
      "Saving Model 2120\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2121, reward 894.0, memory_length 2000, epsilon 2.478926144047053e-05 total_time 722.0\n",
      "episode 2122, reward 771.0, memory_length 2000, epsilon 2.466562448323817e-05 total_time 722.0\n",
      "episode 2123, reward 709.0, memory_length 2000, epsilon 2.4542604167902515e-05 total_time 721.0\n",
      "episode 2124, reward 857.0, memory_length 2000, epsilon 2.442019741894932e-05 total_time 721.0\n",
      "episode 2125, reward 601.0, memory_length 2000, epsilon 2.4298401176203528e-05 total_time 737.0\n",
      "episode 2126, reward 1234.0, memory_length 2000, epsilon 2.4177212394752643e-05 total_time 727.0\n",
      "episode 2127, reward 821.0, memory_length 2000, epsilon 2.40566280448709e-05 total_time 722.0\n",
      "episode 2128, reward 554.0, memory_length 2000, epsilon 2.3936645111943187e-05 total_time 728.0\n",
      "episode 2129, reward 1011.0, memory_length 2000, epsilon 2.3817260596390013e-05 total_time 727.0\n",
      "episode 2130, reward 938.0, memory_length 2000, epsilon 2.3698471513592194e-05 total_time 731.0\n",
      "Saving Model 2130\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2131, reward 1045.0, memory_length 2000, epsilon 2.358027489381655e-05 total_time 725.0\n",
      "episode 2132, reward 852.0, memory_length 2000, epsilon 2.3462667782141348e-05 total_time 721.0\n",
      "episode 2133, reward 977.0, memory_length 2000, epsilon 2.334564723838272e-05 total_time 725.0\n",
      "episode 2134, reward 867.0, memory_length 2000, epsilon 2.3229210337021008e-05 total_time 722.0\n",
      "episode 2135, reward 983.0, memory_length 2000, epsilon 2.3113354167127538e-05 total_time 725.0\n",
      "episode 2136, reward 970.0, memory_length 2000, epsilon 2.299807583229211e-05 total_time 723.0\n",
      "episode 2137, reward 643.0, memory_length 2000, epsilon 2.2883372450550267e-05 total_time 727.0\n",
      "episode 2138, reward 898.0, memory_length 2000, epsilon 2.276924115431157e-05 total_time 722.0\n",
      "episode 2139, reward 1359.0, memory_length 2000, epsilon 2.265567909028759e-05 total_time 730.0\n",
      "episode 2140, reward 1119.0, memory_length 2000, epsilon 2.254268341942085e-05 total_time 729.0\n",
      "Saving Model 2140\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2141, reward 804.0, memory_length 2000, epsilon 2.2430251316813735e-05 total_time 722.0\n",
      "episode 2142, reward 535.0, memory_length 2000, epsilon 2.2318379971657744e-05 total_time 729.0\n",
      "episode 2143, reward 617.0, memory_length 2000, epsilon 2.22070665871635e-05 total_time 725.0\n",
      "episode 2144, reward 331.0, memory_length 2000, epsilon 2.2096308380490516e-05 total_time 725.0\n",
      "episode 2145, reward 754.0, memory_length 2000, epsilon 2.198610258267793e-05 total_time 726.0\n",
      "episode 2146, reward 955.0, memory_length 2000, epsilon 2.187644643857499e-05 total_time 727.0\n",
      "episode 2147, reward 598.0, memory_length 2000, epsilon 2.1767337206772447e-05 total_time 728.0\n",
      "episode 2148, reward 1253.0, memory_length 2000, epsilon 2.165877215953375e-05 total_time 725.0\n",
      "episode 2149, reward 1078.0, memory_length 2000, epsilon 2.155074858272711e-05 total_time 727.0\n",
      "episode 2150, reward 881.0, memory_length 2000, epsilon 2.1443263775757504e-05 total_time 728.0\n",
      "Saving Model 2150\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2151, reward 1236.0, memory_length 2000, epsilon 2.1336315051499094e-05 total_time 724.0\n",
      "episode 2152, reward 1041.0, memory_length 2000, epsilon 2.122989973622828e-05 total_time 728.0\n",
      "episode 2153, reward 999.0, memory_length 2000, epsilon 2.1124015169556556e-05 total_time 728.0\n",
      "episode 2154, reward 895.0, memory_length 2000, epsilon 2.1018658704364323e-05 total_time 726.0\n",
      "episode 2155, reward 1147.0, memory_length 2000, epsilon 2.0913827706734377e-05 total_time 730.0\n",
      "episode 2156, reward 808.0, memory_length 2000, epsilon 2.0809519555886405e-05 total_time 726.0\n",
      "episode 2157, reward 1090.0, memory_length 2000, epsilon 2.070573164411112e-05 total_time 723.0\n",
      "episode 2158, reward 1180.0, memory_length 2000, epsilon 2.0602461376705362e-05 total_time 721.0\n",
      "episode 2159, reward 820.0, memory_length 2000, epsilon 2.0499706171907108e-05 total_time 730.0\n",
      "episode 2160, reward 426.0, memory_length 2000, epsilon 2.0397463460830804e-05 total_time 721.0\n",
      "Saving Model 2160\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2161, reward 1170.0, memory_length 2000, epsilon 2.029573068740343e-05 total_time 728.0\n",
      "episode 2162, reward 856.0, memory_length 2000, epsilon 2.0194505308300272e-05 total_time 723.0\n",
      "episode 2163, reward 1007.0, memory_length 2000, epsilon 2.009378479288166e-05 total_time 724.0\n",
      "episode 2164, reward 847.0, memory_length 2000, epsilon 1.999356662312938e-05 total_time 721.0\n",
      "episode 2165, reward 984.0, memory_length 2000, epsilon 1.9893848293584015e-05 total_time 725.0\n",
      "episode 2166, reward 1273.0, memory_length 2000, epsilon 1.9794627311282164e-05 total_time 721.0\n",
      "episode 2167, reward 1229.0, memory_length 2000, epsilon 1.969590119569403e-05 total_time 722.0\n",
      "episode 2168, reward 1354.0, memory_length 2000, epsilon 1.959766747866165e-05 total_time 723.0\n",
      "episode 2169, reward 1306.0, memory_length 2000, epsilon 1.949992370433692e-05 total_time 729.0\n",
      "episode 2170, reward 1093.0, memory_length 2000, epsilon 1.940266742912045e-05 total_time 723.0\n",
      "Saving Model 2170\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2171, reward 944.0, memory_length 2000, epsilon 1.930589622160023e-05 total_time 726.0\n",
      "episode 2172, reward 967.0, memory_length 2000, epsilon 1.9209607662491105e-05 total_time 721.0\n",
      "episode 2173, reward 854.0, memory_length 2000, epsilon 1.9113799344574006e-05 total_time 721.0\n",
      "episode 2174, reward 1572.0, memory_length 2000, epsilon 1.9018468872636033e-05 total_time 721.0\n",
      "episode 2175, reward 1442.0, memory_length 2000, epsilon 1.8923613863410453e-05 total_time 722.0\n",
      "episode 2176, reward 1173.0, memory_length 2000, epsilon 1.8829231945517035e-05 total_time 725.0\n",
      "episode 2177, reward 1102.0, memory_length 2000, epsilon 1.8735320759402976e-05 total_time 721.0\n",
      "episode 2178, reward 1146.0, memory_length 2000, epsilon 1.864187795728367e-05 total_time 726.0\n",
      "episode 2179, reward 1042.0, memory_length 2000, epsilon 1.8548901203084258e-05 total_time 729.0\n",
      "episode 2180, reward 700.0, memory_length 2000, epsilon 1.8456388172380982e-05 total_time 722.0\n",
      "Saving Model 2180\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2181, reward 789.0, memory_length 2000, epsilon 1.8364336552343315e-05 total_time 723.0\n",
      "episode 2182, reward 980.0, memory_length 2000, epsilon 1.8272744041675904e-05 total_time 723.0\n",
      "episode 2183, reward 962.0, memory_length 2000, epsilon 1.8181608350561242e-05 total_time 732.0\n",
      "episode 2184, reward 736.0, memory_length 2000, epsilon 1.8090927200602332e-05 total_time 722.0\n",
      "episode 2185, reward 578.0, memory_length 2000, epsilon 1.800069832476565e-05 total_time 726.0\n",
      "episode 2186, reward 1267.0, memory_length 2000, epsilon 1.791091946732465e-05 total_time 723.0\n",
      "episode 2187, reward 1253.0, memory_length 2000, epsilon 1.782158838380316e-05 total_time 721.0\n",
      "episode 2188, reward 761.0, memory_length 2000, epsilon 1.7732702840919507e-05 total_time 731.0\n",
      "episode 2189, reward 920.0, memory_length 2000, epsilon 1.764426061653043e-05 total_time 730.0\n",
      "episode 2190, reward 1017.0, memory_length 2000, epsilon 1.755625949957573e-05 total_time 730.0\n",
      "Saving Model 2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2191, reward 792.0, memory_length 2000, epsilon 1.7468697290022946e-05 total_time 721.0\n",
      "episode 2192, reward 663.0, memory_length 2000, epsilon 1.738157179881221e-05 total_time 722.0\n",
      "episode 2193, reward 1344.0, memory_length 2000, epsilon 1.7294880847801767e-05 total_time 726.0\n",
      "episode 2194, reward 436.0, memory_length 2000, epsilon 1.7208622269713258e-05 total_time 726.0\n",
      "episode 2195, reward 1090.0, memory_length 2000, epsilon 1.7122793908077814e-05 total_time 731.0\n",
      "episode 2196, reward 847.0, memory_length 2000, epsilon 1.7037393617181848e-05 total_time 726.0\n",
      "episode 2197, reward 1293.0, memory_length 2000, epsilon 1.6952419262013707e-05 total_time 722.0\n",
      "episode 2198, reward 1133.0, memory_length 2000, epsilon 1.6867868718210028e-05 total_time 721.0\n",
      "episode 2199, reward 1139.0, memory_length 2000, epsilon 1.678373987200284e-05 total_time 726.0\n",
      "episode 2200, reward 745.0, memory_length 2000, epsilon 1.6700030620166636e-05 total_time 722.0\n",
      "Saving Model 2200\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2201, reward 746.0, memory_length 2000, epsilon 1.6616738869965697e-05 total_time 726.0\n",
      "episode 2202, reward 554.0, memory_length 2000, epsilon 1.6533862539101997e-05 total_time 723.0\n",
      "episode 2203, reward 943.0, memory_length 2000, epsilon 1.6451399555662884e-05 total_time 731.0\n",
      "episode 2204, reward 783.0, memory_length 2000, epsilon 1.6369347858069534e-05 total_time 721.0\n",
      "episode 2205, reward 941.0, memory_length 2000, epsilon 1.6287705395025176e-05 total_time 724.0\n",
      "episode 2206, reward 922.0, memory_length 2000, epsilon 1.6206470125464044e-05 total_time 722.0\n",
      "episode 2207, reward 923.0, memory_length 2000, epsilon 1.6125640018500107e-05 total_time 724.0\n",
      "episode 2208, reward 1036.0, memory_length 2000, epsilon 1.6045213053376512e-05 total_time 727.0\n",
      "episode 2209, reward 769.0, memory_length 2000, epsilon 1.5965187219414966e-05 total_time 726.0\n",
      "episode 2210, reward 1306.0, memory_length 2000, epsilon 1.58855605159654e-05 total_time 722.0\n",
      "Saving Model 2210\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2211, reward 1123.0, memory_length 2000, epsilon 1.5806330952356134e-05 total_time 721.0\n",
      "episode 2212, reward 810.0, memory_length 2000, epsilon 1.5727496547843896e-05 total_time 721.0\n",
      "episode 2213, reward 493.0, memory_length 2000, epsilon 1.564905533156452e-05 total_time 729.0\n",
      "episode 2214, reward 1007.0, memory_length 2000, epsilon 1.557100534248347e-05 total_time 727.0\n",
      "episode 2215, reward 1101.0, memory_length 2000, epsilon 1.549334462934696e-05 total_time 727.0\n",
      "episode 2216, reward 723.0, memory_length 2000, epsilon 1.5416071250633167e-05 total_time 726.0\n",
      "episode 2217, reward 1372.0, memory_length 2000, epsilon 1.533918327450353e-05 total_time 721.0\n",
      "episode 2218, reward 1713.0, memory_length 2000, epsilon 1.52626787787547e-05 total_time 725.0\n",
      "episode 2219, reward 732.0, memory_length 2000, epsilon 1.5186555850770241e-05 total_time 723.0\n",
      "episode 2220, reward 588.0, memory_length 2000, epsilon 1.5110812587473049e-05 total_time 726.0\n",
      "Saving Model 2220\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2221, reward 721.0, memory_length 2000, epsilon 1.5035447095277536e-05 total_time 721.0\n",
      "episode 2222, reward 1323.0, memory_length 2000, epsilon 1.496045749004253e-05 total_time 731.0\n",
      "episode 2223, reward 1090.0, memory_length 2000, epsilon 1.488584189702394e-05 total_time 722.0\n",
      "episode 2224, reward 788.0, memory_length 2000, epsilon 1.481159845082808e-05 total_time 731.0\n",
      "episode 2225, reward 775.0, memory_length 2000, epsilon 1.4737725295364955e-05 total_time 722.0\n",
      "episode 2226, reward 1078.0, memory_length 2000, epsilon 1.466422058380178e-05 total_time 730.0\n",
      "episode 2227, reward 745.0, memory_length 2000, epsilon 1.4591082478516985e-05 total_time 727.0\n",
      "episode 2228, reward 814.0, memory_length 2000, epsilon 1.4518309151054083e-05 total_time 722.0\n",
      "episode 2229, reward 898.0, memory_length 2000, epsilon 1.4445898782076143e-05 total_time 725.0\n",
      "episode 2230, reward 868.0, memory_length 2000, epsilon 1.4373849561320122e-05 total_time 723.0\n",
      "Saving Model 2230\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2231, reward 833.0, memory_length 2000, epsilon 1.4302159687551798e-05 total_time 723.0\n",
      "episode 2232, reward 999.0, memory_length 2000, epsilon 1.4230827368520544e-05 total_time 729.0\n",
      "episode 2233, reward 979.0, memory_length 2000, epsilon 1.415985082091469e-05 total_time 726.0\n",
      "episode 2234, reward 1141.0, memory_length 2000, epsilon 1.4089228270316878e-05 total_time 724.0\n",
      "episode 2235, reward 961.0, memory_length 2000, epsilon 1.4018957951159612e-05 total_time 725.0\n",
      "episode 2236, reward 910.0, memory_length 2000, epsilon 1.3949038106681305e-05 total_time 737.0\n",
      "episode 2237, reward 1352.0, memory_length 2000, epsilon 1.3879466988882153e-05 total_time 722.0\n",
      "episode 2238, reward 778.0, memory_length 2000, epsilon 1.3810242858480638e-05 total_time 726.0\n",
      "episode 2239, reward 1012.0, memory_length 2000, epsilon 1.3741363984869847e-05 total_time 722.0\n",
      "episode 2240, reward 1131.0, memory_length 2000, epsilon 1.3672828646074371e-05 total_time 721.0\n",
      "Saving Model 2240\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2241, reward 959.0, memory_length 2000, epsilon 1.36046351287072e-05 total_time 728.0\n",
      "episode 2242, reward 1210.0, memory_length 2000, epsilon 1.3536781727926796e-05 total_time 722.0\n",
      "episode 2243, reward 742.0, memory_length 2000, epsilon 1.3469266747394656e-05 total_time 722.0\n",
      "episode 2244, reward 994.0, memory_length 2000, epsilon 1.3402088499232704e-05 total_time 723.0\n",
      "episode 2245, reward 1070.0, memory_length 2000, epsilon 1.333524530398128e-05 total_time 723.0\n",
      "episode 2246, reward 996.0, memory_length 2000, epsilon 1.3268735490556978e-05 total_time 726.0\n",
      "episode 2247, reward 1113.0, memory_length 2000, epsilon 1.3202557396211042e-05 total_time 725.0\n",
      "episode 2248, reward 1339.0, memory_length 2000, epsilon 1.3136709366487624e-05 total_time 722.0\n",
      "episode 2249, reward 760.0, memory_length 2000, epsilon 1.3071189755182573e-05 total_time 724.0\n",
      "episode 2250, reward 1250.0, memory_length 2000, epsilon 1.3005996924302215e-05 total_time 725.0\n",
      "Saving Model 2250\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2251, reward 835.0, memory_length 2000, epsilon 1.2941129244022338e-05 total_time 722.0\n",
      "episode 2252, reward 850.0, memory_length 2000, epsilon 1.28765850926476e-05 total_time 721.0\n",
      "episode 2253, reward 1216.0, memory_length 2000, epsilon 1.2812362856570815e-05 total_time 724.0\n",
      "episode 2254, reward 531.0, memory_length 2000, epsilon 1.2748460930232776e-05 total_time 723.0\n",
      "episode 2255, reward 469.0, memory_length 2000, epsilon 1.2684877716081953e-05 total_time 727.0\n",
      "episode 2256, reward 1016.0, memory_length 2000, epsilon 1.2621611624534725e-05 total_time 724.0\n",
      "episode 2257, reward 1252.0, memory_length 2000, epsilon 1.2558661073935467e-05 total_time 728.0\n",
      "episode 2258, reward 851.0, memory_length 2000, epsilon 1.2496024490517153e-05 total_time 722.0\n",
      "episode 2259, reward 1267.0, memory_length 2000, epsilon 1.243370030836196e-05 total_time 726.0\n",
      "episode 2260, reward 629.0, memory_length 2000, epsilon 1.2371686969362042e-05 total_time 722.0\n",
      "Saving Model 2260\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2261, reward 571.0, memory_length 2000, epsilon 1.230998292318074e-05 total_time 723.0\n",
      "episode 2262, reward 723.0, memory_length 2000, epsilon 1.2248586627213642e-05 total_time 726.0\n",
      "episode 2263, reward 785.0, memory_length 2000, epsilon 1.2187496546550193e-05 total_time 728.0\n",
      "episode 2264, reward 1001.0, memory_length 2000, epsilon 1.2126711153935152e-05 total_time 722.0\n",
      "episode 2265, reward 1371.0, memory_length 2000, epsilon 1.2066228929730559e-05 total_time 722.0\n",
      "episode 2266, reward 783.0, memory_length 2000, epsilon 1.2006048361877682e-05 total_time 721.0\n",
      "episode 2267, reward 855.0, memory_length 2000, epsilon 1.1946167945859147e-05 total_time 727.0\n",
      "episode 2268, reward 1105.0, memory_length 2000, epsilon 1.1886586184661472e-05 total_time 721.0\n",
      "episode 2269, reward 1063.0, memory_length 2000, epsilon 1.182730158873749e-05 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2270, reward 519.0, memory_length 2000, epsilon 1.1768312675969251e-05 total_time 721.0\n",
      "Saving Model 2270\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2271, reward 994.0, memory_length 2000, epsilon 1.1709617971630825e-05 total_time 724.0\n",
      "episode 2272, reward 1311.0, memory_length 2000, epsilon 1.1651216008351586e-05 total_time 722.0\n",
      "episode 2273, reward 1041.0, memory_length 2000, epsilon 1.1593105326079371e-05 total_time 728.0\n",
      "episode 2274, reward 990.0, memory_length 2000, epsilon 1.1535284472044117e-05 total_time 725.0\n",
      "episode 2275, reward 1144.0, memory_length 2000, epsilon 1.147775200072148e-05 total_time 722.0\n",
      "episode 2276, reward 1083.0, memory_length 2000, epsilon 1.1420506473796639e-05 total_time 721.0\n",
      "episode 2277, reward 921.0, memory_length 2000, epsilon 1.1363546460128483e-05 total_time 722.0\n",
      "episode 2278, reward 1166.0, memory_length 2000, epsilon 1.1306870535713663e-05 total_time 722.0\n",
      "episode 2279, reward 558.0, memory_length 2000, epsilon 1.1250477283651155e-05 total_time 729.0\n",
      "episode 2280, reward 802.0, memory_length 2000, epsilon 1.119436529410668e-05 total_time 722.0\n",
      "Saving Model 2280\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2281, reward 1417.0, memory_length 2000, epsilon 1.1138533164277619e-05 total_time 723.0\n",
      "episode 2282, reward 589.0, memory_length 2000, epsilon 1.1082979498357777e-05 total_time 721.0\n",
      "episode 2283, reward 1392.0, memory_length 2000, epsilon 1.1027702907502636e-05 total_time 722.0\n",
      "episode 2284, reward 1372.0, memory_length 2000, epsilon 1.0972702009794558e-05 total_time 722.0\n",
      "episode 2285, reward 1130.0, memory_length 2000, epsilon 1.0917975430208203e-05 total_time 721.0\n",
      "episode 2286, reward 1381.0, memory_length 2000, epsilon 1.0863521800576268e-05 total_time 721.0\n",
      "episode 2287, reward 780.0, memory_length 2000, epsilon 1.0809339759555135e-05 total_time 726.0\n",
      "episode 2288, reward 908.0, memory_length 2000, epsilon 1.0755427952590999e-05 total_time 721.0\n",
      "episode 2289, reward 845.0, memory_length 2000, epsilon 1.0701785031885836e-05 total_time 722.0\n",
      "episode 2290, reward 945.0, memory_length 2000, epsilon 1.0648409656363856e-05 total_time 729.0\n",
      "Saving Model 2290\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2291, reward 1107.0, memory_length 2000, epsilon 1.0595300491637911e-05 total_time 724.0\n",
      "episode 2292, reward 1045.0, memory_length 2000, epsilon 1.0542456209976073e-05 total_time 728.0\n",
      "episode 2293, reward 1407.0, memory_length 2000, epsilon 1.0489875490268593e-05 total_time 721.0\n",
      "episode 2294, reward 1004.0, memory_length 2000, epsilon 1.0437557017994699e-05 total_time 729.0\n",
      "episode 2295, reward 1042.0, memory_length 2000, epsilon 1.0385499485189896e-05 total_time 721.0\n",
      "episode 2296, reward 923.0, memory_length 2000, epsilon 1.0333701590413115e-05 total_time 725.0\n",
      "episode 2297, reward 1562.0, memory_length 2000, epsilon 1.028216203871433e-05 total_time 721.0\n",
      "episode 2298, reward 993.0, memory_length 2000, epsilon 1.0230879541602021e-05 total_time 723.0\n",
      "episode 2299, reward 726.0, memory_length 2000, epsilon 1.0179852817011112e-05 total_time 731.0\n",
      "episode 2300, reward 1021.0, memory_length 2000, epsilon 1.0129080589270848e-05 total_time 722.0\n",
      "Saving Model 2300\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2301, reward 703.0, memory_length 2000, epsilon 1.0078561589072853e-05 total_time 722.0\n",
      "episode 2302, reward 1381.0, memory_length 2000, epsilon 1.0028294553439529e-05 total_time 728.0\n",
      "episode 2303, reward 977.0, memory_length 2000, epsilon 9.978278225692332e-06 total_time 728.0\n",
      "episode 2304, reward 567.0, memory_length 2000, epsilon 9.928511355420496e-06 total_time 726.0\n",
      "episode 2305, reward 775.0, memory_length 2000, epsilon 9.878992698449639e-06 total_time 729.0\n",
      "episode 2306, reward 1100.0, memory_length 2000, epsilon 9.829721016810793e-06 total_time 726.0\n",
      "episode 2307, reward 1194.0, memory_length 2000, epsilon 9.780695078709313e-06 total_time 733.0\n",
      "episode 2308, reward 1518.0, memory_length 2000, epsilon 9.731913658494213e-06 total_time 724.0\n",
      "episode 2309, reward 1169.0, memory_length 2000, epsilon 9.683375536627462e-06 total_time 727.0\n",
      "episode 2310, reward 622.0, memory_length 2000, epsilon 9.635079499653454e-06 total_time 722.0\n",
      "Saving Model 2310\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2311, reward 1026.0, memory_length 2000, epsilon 9.587024340168781e-06 total_time 725.0\n",
      "episode 2312, reward 1268.0, memory_length 2000, epsilon 9.539208856791922e-06 total_time 726.0\n",
      "episode 2313, reward 1344.0, memory_length 2000, epsilon 9.491631854133332e-06 total_time 723.0\n",
      "episode 2314, reward 1250.0, memory_length 2000, epsilon 9.444292142765437e-06 total_time 725.0\n",
      "episode 2315, reward 454.0, memory_length 2000, epsilon 9.397188539192998e-06 total_time 726.0\n",
      "episode 2316, reward 1023.0, memory_length 2000, epsilon 9.350319865823497e-06 total_time 727.0\n",
      "episode 2317, reward 816.0, memory_length 2000, epsilon 9.303684950937618e-06 total_time 721.0\n",
      "episode 2318, reward 704.0, memory_length 2000, epsilon 9.257282628660097e-06 total_time 724.0\n",
      "episode 2319, reward 1387.0, memory_length 2000, epsilon 9.211111738930427e-06 total_time 723.0\n",
      "episode 2320, reward 934.0, memory_length 2000, epsilon 9.165171127473992e-06 total_time 727.0\n",
      "Saving Model 2320\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2321, reward 686.0, memory_length 2000, epsilon 9.119459645773083e-06 total_time 721.0\n",
      "episode 2322, reward 973.0, memory_length 2000, epsilon 9.073976151038305e-06 total_time 728.0\n",
      "episode 2323, reward 593.0, memory_length 2000, epsilon 9.028719506179888e-06 total_time 723.0\n",
      "episode 2324, reward 830.0, memory_length 2000, epsilon 8.983688579779374e-06 total_time 723.0\n",
      "episode 2325, reward 1267.0, memory_length 2000, epsilon 8.938882246061273e-06 total_time 724.0\n",
      "episode 2326, reward 897.0, memory_length 2000, epsilon 8.89429938486487e-06 total_time 725.0\n",
      "episode 2327, reward 532.0, memory_length 2000, epsilon 8.849938881616354e-06 total_time 733.0\n",
      "episode 2328, reward 229.0, memory_length 2000, epsilon 8.805799627300795e-06 total_time 729.0\n",
      "episode 2329, reward 810.0, memory_length 2000, epsilon 8.761880518434571e-06 total_time 725.0\n",
      "episode 2330, reward 1079.0, memory_length 2000, epsilon 8.71818045703764e-06 total_time 723.0\n",
      "Saving Model 2330\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2331, reward 953.0, memory_length 2000, epsilon 8.674698350606223e-06 total_time 728.0\n",
      "episode 2332, reward 1040.0, memory_length 2000, epsilon 8.631433112085365e-06 total_time 721.0\n",
      "episode 2333, reward 1104.0, memory_length 2000, epsilon 8.58838365984186e-06 total_time 721.0\n",
      "episode 2334, reward 1128.0, memory_length 2000, epsilon 8.54554891763718e-06 total_time 721.0\n",
      "episode 2335, reward 1279.0, memory_length 2000, epsilon 8.502927814600508e-06 total_time 724.0\n",
      "episode 2336, reward 625.0, memory_length 2000, epsilon 8.460519285202075e-06 total_time 723.0\n",
      "episode 2337, reward 776.0, memory_length 2000, epsilon 8.41832226922641e-06 total_time 727.0\n",
      "episode 2338, reward 675.0, memory_length 2000, epsilon 8.376335711745947e-06 total_time 731.0\n",
      "episode 2339, reward 1185.0, memory_length 2000, epsilon 8.334558563094528e-06 total_time 725.0\n",
      "episode 2340, reward 905.0, memory_length 2000, epsilon 8.29298977884128e-06 total_time 738.0\n",
      "Saving Model 2340\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2341, reward 866.0, memory_length 2000, epsilon 8.251628319764445e-06 total_time 727.0\n",
      "episode 2342, reward 906.0, memory_length 2000, epsilon 8.21047315182536e-06 total_time 726.0\n",
      "episode 2343, reward 1105.0, memory_length 2000, epsilon 8.169523246142718e-06 total_time 728.0\n",
      "episode 2344, reward 712.0, memory_length 2000, epsilon 8.128777578966709e-06 total_time 723.0\n",
      "episode 2345, reward 974.0, memory_length 2000, epsilon 8.088235131653563e-06 total_time 722.0\n",
      "episode 2346, reward 1086.0, memory_length 2000, epsilon 8.047894890639957e-06 total_time 726.0\n",
      "episode 2347, reward 860.0, memory_length 2000, epsilon 8.007755847417792e-06 total_time 727.0\n",
      "episode 2348, reward 1227.0, memory_length 2000, epsilon 7.96781699850887e-06 total_time 724.0\n",
      "episode 2349, reward 1059.0, memory_length 2000, epsilon 7.9280773454399e-06 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2350, reward 912.0, memory_length 2000, epsilon 7.888535894717504e-06 total_time 723.0\n",
      "Saving Model 2350\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2351, reward 800.0, memory_length 2000, epsilon 7.84919165780332e-06 total_time 724.0\n",
      "episode 2352, reward 720.0, memory_length 2000, epsilon 7.810043651089411e-06 total_time 733.0\n",
      "episode 2353, reward 753.0, memory_length 2000, epsilon 7.771090895873536e-06 total_time 728.0\n",
      "episode 2354, reward 1023.0, memory_length 2000, epsilon 7.732332418334819e-06 total_time 721.0\n",
      "episode 2355, reward 1314.0, memory_length 2000, epsilon 7.69376724950927e-06 total_time 724.0\n",
      "episode 2356, reward 556.0, memory_length 2000, epsilon 7.65539442526569e-06 total_time 721.0\n",
      "episode 2357, reward 1341.0, memory_length 2000, epsilon 7.617212986281449e-06 total_time 732.0\n",
      "episode 2358, reward 1020.0, memory_length 2000, epsilon 7.579221978018593e-06 total_time 722.0\n",
      "episode 2359, reward 1070.0, memory_length 2000, epsilon 7.541420450699954e-06 total_time 721.0\n",
      "episode 2360, reward 1249.0, memory_length 2000, epsilon 7.50380745928535e-06 total_time 722.0\n",
      "Saving Model 2360\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2361, reward 1023.0, memory_length 2000, epsilon 7.466382063448066e-06 total_time 722.0\n",
      "episode 2362, reward 1321.0, memory_length 2000, epsilon 7.4291433275512294e-06 total_time 728.0\n",
      "episode 2363, reward 1216.0, memory_length 2000, epsilon 7.3920903206245305e-06 total_time 723.0\n",
      "episode 2364, reward 1022.0, memory_length 2000, epsilon 7.355222116340838e-06 total_time 729.0\n",
      "episode 2365, reward 890.0, memory_length 2000, epsilon 7.318537792993139e-06 total_time 736.0\n",
      "episode 2366, reward 694.0, memory_length 2000, epsilon 7.282036433471452e-06 total_time 721.0\n",
      "episode 2367, reward 927.0, memory_length 2000, epsilon 7.245717125239862e-06 total_time 731.0\n",
      "episode 2368, reward 1461.0, memory_length 2000, epsilon 7.209578960313797e-06 total_time 725.0\n",
      "episode 2369, reward 1556.0, memory_length 2000, epsilon 7.173621035237227e-06 total_time 724.0\n",
      "episode 2370, reward 1034.0, memory_length 2000, epsilon 7.137842451060176e-06 total_time 724.0\n",
      "Saving Model 2370\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2371, reward 554.0, memory_length 2000, epsilon 7.1022423133161525e-06 total_time 721.0\n",
      "episode 2372, reward 859.0, memory_length 2000, epsilon 7.066819731999884e-06 total_time 725.0\n",
      "episode 2373, reward 963.0, memory_length 2000, epsilon 7.031573821544965e-06 total_time 721.0\n",
      "episode 2374, reward 835.0, memory_length 2000, epsilon 6.996503700801813e-06 total_time 722.0\n",
      "episode 2375, reward 1034.0, memory_length 2000, epsilon 6.961608493015597e-06 total_time 721.0\n",
      "episode 2376, reward 1250.0, memory_length 2000, epsilon 6.926887325804276e-06 total_time 725.0\n",
      "episode 2377, reward 954.0, memory_length 2000, epsilon 6.892339331136889e-06 total_time 721.0\n",
      "episode 2378, reward 1550.0, memory_length 2000, epsilon 6.857963645311745e-06 total_time 723.0\n",
      "episode 2379, reward 634.0, memory_length 2000, epsilon 6.82375940893493e-06 total_time 721.0\n",
      "episode 2380, reward 1135.0, memory_length 2000, epsilon 6.7897257668987325e-06 total_time 726.0\n",
      "Saving Model 2380\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2381, reward 1199.0, memory_length 2000, epsilon 6.755861868360351e-06 total_time 723.0\n",
      "episode 2382, reward 901.0, memory_length 2000, epsilon 6.722166866720534e-06 total_time 721.0\n",
      "episode 2383, reward 1215.0, memory_length 2000, epsilon 6.688639919602498e-06 total_time 724.0\n",
      "episode 2384, reward 1174.0, memory_length 2000, epsilon 6.655280188830833e-06 total_time 721.0\n",
      "episode 2385, reward 802.0, memory_length 2000, epsilon 6.6220868404105046e-06 total_time 722.0\n",
      "episode 2386, reward 820.0, memory_length 2000, epsilon 6.589059044506099e-06 total_time 728.0\n",
      "episode 2387, reward 877.0, memory_length 2000, epsilon 6.556195975420974e-06 total_time 731.0\n",
      "episode 2388, reward 1559.0, memory_length 2000, epsilon 6.523496811576717e-06 total_time 730.0\n",
      "episode 2389, reward 1240.0, memory_length 2000, epsilon 6.490960735492502e-06 total_time 724.0\n",
      "episode 2390, reward 1015.0, memory_length 2000, epsilon 6.458586933764746e-06 total_time 724.0\n",
      "Saving Model 2390\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2391, reward 908.0, memory_length 2000, epsilon 6.426374597046731e-06 total_time 722.0\n",
      "episode 2392, reward 1254.0, memory_length 2000, epsilon 6.3943229200283375e-06 total_time 730.0\n",
      "episode 2393, reward 964.0, memory_length 2000, epsilon 6.3624311014159935e-06 total_time 728.0\n",
      "episode 2394, reward 839.0, memory_length 2000, epsilon 6.330698343912552e-06 total_time 740.0\n",
      "episode 2395, reward 840.0, memory_length 2000, epsilon 6.299123854197442e-06 total_time 721.0\n",
      "episode 2396, reward 657.0, memory_length 2000, epsilon 6.267706842906757e-06 total_time 721.0\n",
      "episode 2397, reward 610.0, memory_length 2000, epsilon 6.236446524613597e-06 total_time 721.0\n",
      "episode 2398, reward 910.0, memory_length 2000, epsilon 6.205342117808358e-06 total_time 731.0\n",
      "episode 2399, reward 877.0, memory_length 2000, epsilon 6.17439284487926e-06 total_time 728.0\n",
      "episode 2400, reward 802.0, memory_length 2000, epsilon 6.143597932092877e-06 total_time 727.0\n",
      "Saving Model 2400\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2401, reward 977.0, memory_length 2000, epsilon 6.1129566095747654e-06 total_time 725.0\n",
      "episode 2402, reward 546.0, memory_length 2000, epsilon 6.082468111290287e-06 total_time 726.0\n",
      "episode 2403, reward 509.0, memory_length 2000, epsilon 6.052131675025375e-06 total_time 726.0\n",
      "episode 2404, reward 710.0, memory_length 2000, epsilon 6.021946542367566e-06 total_time 728.0\n",
      "episode 2405, reward 616.0, memory_length 2000, epsilon 5.9919119586869485e-06 total_time 722.0\n",
      "episode 2406, reward 1122.0, memory_length 2000, epsilon 5.962027173117377e-06 total_time 724.0\n",
      "episode 2407, reward 1184.0, memory_length 2000, epsilon 5.9322914385376665e-06 total_time 721.0\n",
      "episode 2408, reward 586.0, memory_length 2000, epsilon 5.902704011552883e-06 total_time 722.0\n",
      "episode 2409, reward 988.0, memory_length 2000, epsilon 5.873264152475831e-06 total_time 723.0\n",
      "episode 2410, reward 535.0, memory_length 2000, epsilon 5.84397112530848e-06 total_time 728.0\n",
      "Saving Model 2410\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2411, reward 1124.0, memory_length 2000, epsilon 5.814824197723646e-06 total_time 724.0\n",
      "episode 2412, reward 1132.0, memory_length 2000, epsilon 5.7858226410466e-06 total_time 730.0\n",
      "episode 2413, reward 699.0, memory_length 2000, epsilon 5.756965730236936e-06 total_time 731.0\n",
      "episode 2414, reward 1020.0, memory_length 2000, epsilon 5.72825274387036e-06 total_time 731.0\n",
      "episode 2415, reward 828.0, memory_length 2000, epsilon 5.699682964120728e-06 total_time 727.0\n",
      "episode 2416, reward 446.0, memory_length 2000, epsilon 5.671255676742067e-06 total_time 721.0\n",
      "episode 2417, reward 1225.0, memory_length 2000, epsilon 5.642970171050693e-06 total_time 723.0\n",
      "episode 2418, reward 929.0, memory_length 2000, epsilon 5.6148257399075106e-06 total_time 726.0\n",
      "episode 2419, reward 1200.0, memory_length 2000, epsilon 5.586821679700254e-06 total_time 722.0\n",
      "episode 2420, reward 760.0, memory_length 2000, epsilon 5.558957290325981e-06 total_time 726.0\n",
      "Saving Model 2420\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2421, reward 798.0, memory_length 2000, epsilon 5.531231875173486e-06 total_time 723.0\n",
      "episode 2422, reward 824.0, memory_length 2000, epsilon 5.503644741105965e-06 total_time 721.0\n",
      "episode 2423, reward 992.0, memory_length 2000, epsilon 5.47619519844361e-06 total_time 731.0\n",
      "episode 2424, reward 1047.0, memory_length 2000, epsilon 5.448882560946435e-06 total_time 724.0\n",
      "episode 2425, reward 898.0, memory_length 2000, epsilon 5.421706145797089e-06 total_time 723.0\n",
      "episode 2426, reward 927.0, memory_length 2000, epsilon 5.394665273583761e-06 total_time 725.0\n",
      "episode 2427, reward 723.0, memory_length 2000, epsilon 5.367759268283253e-06 total_time 728.0\n",
      "episode 2428, reward 965.0, memory_length 2000, epsilon 5.340987457244013e-06 total_time 722.0\n",
      "episode 2429, reward 252.0, memory_length 2000, epsilon 5.31434917116939e-06 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2430, reward 1407.0, memory_length 2000, epsilon 5.287843744100828e-06 total_time 723.0\n",
      "Saving Model 2430\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2431, reward 1227.0, memory_length 2000, epsilon 5.261470513401276e-06 total_time 721.0\n",
      "episode 2432, reward 757.0, memory_length 2000, epsilon 5.235228819738604e-06 total_time 725.0\n",
      "episode 2433, reward 786.0, memory_length 2000, epsilon 5.209118007069085e-06 total_time 729.0\n",
      "episode 2434, reward 496.0, memory_length 2000, epsilon 5.18313742262106e-06 total_time 726.0\n",
      "episode 2435, reward 1098.0, memory_length 2000, epsilon 5.157286416878546e-06 total_time 728.0\n",
      "episode 2436, reward 795.0, memory_length 2000, epsilon 5.131564343565073e-06 total_time 722.0\n",
      "episode 2437, reward 1141.0, memory_length 2000, epsilon 5.105970559627448e-06 total_time 726.0\n",
      "episode 2438, reward 740.0, memory_length 2000, epsilon 5.08050442521976e-06 total_time 724.0\n",
      "episode 2439, reward 1157.0, memory_length 2000, epsilon 5.055165303687302e-06 total_time 725.0\n",
      "episode 2440, reward 825.0, memory_length 2000, epsilon 5.0299525615507276e-06 total_time 724.0\n",
      "Saving Model 2440\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2441, reward 871.0, memory_length 2000, epsilon 5.004865568490178e-06 total_time 728.0\n",
      "episode 2442, reward 1076.0, memory_length 2000, epsilon 4.9799036973295015e-06 total_time 724.0\n",
      "episode 2443, reward 626.0, memory_length 2000, epsilon 4.955066324020637e-06 total_time 725.0\n",
      "episode 2444, reward 1003.0, memory_length 2000, epsilon 4.9303528276279414e-06 total_time 725.0\n",
      "episode 2445, reward 1036.0, memory_length 2000, epsilon 4.905762590312734e-06 total_time 728.0\n",
      "episode 2446, reward 835.0, memory_length 2000, epsilon 4.881294997317785e-06 total_time 729.0\n",
      "episode 2447, reward 727.0, memory_length 2000, epsilon 4.856949436952011e-06 total_time 730.0\n",
      "episode 2448, reward 639.0, memory_length 2000, epsilon 4.8327253005751195e-06 total_time 725.0\n",
      "episode 2449, reward 621.0, memory_length 2000, epsilon 4.8086219825824464e-06 total_time 730.0\n",
      "episode 2450, reward 765.0, memory_length 2000, epsilon 4.7846388803897956e-06 total_time 728.0\n",
      "Saving Model 2450\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2451, reward 828.0, memory_length 2000, epsilon 4.7607753944183476e-06 total_time 724.0\n",
      "episode 2452, reward 1517.0, memory_length 2000, epsilon 4.7370309280797245e-06 total_time 722.0\n",
      "episode 2453, reward 1214.0, memory_length 2000, epsilon 4.713404887761016e-06 total_time 721.0\n",
      "episode 2454, reward 764.0, memory_length 2000, epsilon 4.689896682809999e-06 total_time 723.0\n",
      "episode 2455, reward 671.0, memory_length 2000, epsilon 4.666505725520311e-06 total_time 721.0\n",
      "episode 2456, reward 850.0, memory_length 2000, epsilon 4.643231431116808e-06 total_time 726.0\n",
      "episode 2457, reward 922.0, memory_length 2000, epsilon 4.620073217740925e-06 total_time 722.0\n",
      "episode 2458, reward 756.0, memory_length 2000, epsilon 4.597030506436107e-06 total_time 722.0\n",
      "episode 2459, reward 951.0, memory_length 2000, epsilon 4.574102721133388e-06 total_time 722.0\n",
      "episode 2460, reward 1200.0, memory_length 2000, epsilon 4.551289288636923e-06 total_time 734.0\n",
      "Saving Model 2460\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2461, reward 1223.0, memory_length 2000, epsilon 4.528589638609729e-06 total_time 723.0\n",
      "episode 2462, reward 1250.0, memory_length 2000, epsilon 4.5060032035593564e-06 total_time 721.0\n",
      "episode 2463, reward 1394.0, memory_length 2000, epsilon 4.483529418823768e-06 total_time 724.0\n",
      "episode 2464, reward 938.0, memory_length 2000, epsilon 4.461167722557161e-06 total_time 723.0\n",
      "episode 2465, reward 1690.0, memory_length 2000, epsilon 4.438917555715969e-06 total_time 729.0\n",
      "episode 2466, reward 1368.0, memory_length 2000, epsilon 4.4167783620448714e-06 total_time 721.0\n",
      "episode 2467, reward 788.0, memory_length 2000, epsilon 4.3947495880628595e-06 total_time 722.0\n",
      "episode 2468, reward 886.0, memory_length 2000, epsilon 4.372830683049449e-06 total_time 721.0\n",
      "episode 2469, reward 1000.0, memory_length 2000, epsilon 4.351021099030859e-06 total_time 726.0\n",
      "episode 2470, reward 1196.0, memory_length 2000, epsilon 4.329320290766369e-06 total_time 724.0\n",
      "Saving Model 2470\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2471, reward 742.0, memory_length 2000, epsilon 4.307727715734626e-06 total_time 727.0\n",
      "episode 2472, reward 1046.0, memory_length 2000, epsilon 4.286242834120145e-06 total_time 727.0\n",
      "episode 2473, reward 812.0, memory_length 2000, epsilon 4.26486510879975e-06 total_time 723.0\n",
      "episode 2474, reward 705.0, memory_length 2000, epsilon 4.243594005329206e-06 total_time 728.0\n",
      "episode 2475, reward 1287.0, memory_length 2000, epsilon 4.222428991929821e-06 total_time 723.0\n",
      "episode 2476, reward 961.0, memory_length 2000, epsilon 4.201369539475147e-06 total_time 721.0\n",
      "episode 2477, reward 1195.0, memory_length 2000, epsilon 4.180415121477788e-06 total_time 722.0\n",
      "episode 2478, reward 795.0, memory_length 2000, epsilon 4.159565214076189e-06 total_time 721.0\n",
      "episode 2479, reward 1121.0, memory_length 2000, epsilon 4.138819296021593e-06 total_time 723.0\n",
      "episode 2480, reward 630.0, memory_length 2000, epsilon 4.118176848664954e-06 total_time 725.0\n",
      "Saving Model 2480\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2481, reward 1014.0, memory_length 2000, epsilon 4.09763735594402e-06 total_time 726.0\n",
      "episode 2482, reward 943.0, memory_length 2000, epsilon 4.077200304370412e-06 total_time 726.0\n",
      "episode 2483, reward 1081.0, memory_length 2000, epsilon 4.056865183016759e-06 total_time 724.0\n",
      "episode 2484, reward 927.0, memory_length 2000, epsilon 4.036631483503984e-06 total_time 728.0\n",
      "episode 2485, reward 1037.0, memory_length 2000, epsilon 4.0164986999885315e-06 total_time 730.0\n",
      "episode 2486, reward 1095.0, memory_length 2000, epsilon 3.996466329149777e-06 total_time 722.0\n",
      "episode 2487, reward 910.0, memory_length 2000, epsilon 3.976533870177396e-06 total_time 722.0\n",
      "episode 2488, reward 1318.0, memory_length 2000, epsilon 3.956700824758887e-06 total_time 724.0\n",
      "episode 2489, reward 708.0, memory_length 2000, epsilon 3.936966697067068e-06 total_time 726.0\n",
      "episode 2490, reward 623.0, memory_length 2000, epsilon 3.917330993747726e-06 total_time 727.0\n",
      "Saving Model 2490\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2491, reward 1386.0, memory_length 2000, epsilon 3.897793223907262e-06 total_time 721.0\n",
      "episode 2492, reward 930.0, memory_length 2000, epsilon 3.8783528991004e-06 total_time 725.0\n",
      "episode 2493, reward 1160.0, memory_length 2000, epsilon 3.85900953331802e-06 total_time 733.0\n",
      "episode 2494, reward 764.0, memory_length 2000, epsilon 3.839762642974955e-06 total_time 723.0\n",
      "episode 2495, reward 534.0, memory_length 2000, epsilon 3.820611746897961e-06 total_time 727.0\n",
      "episode 2496, reward 1224.0, memory_length 2000, epsilon 3.8015563663136216e-06 total_time 726.0\n",
      "episode 2497, reward 843.0, memory_length 2000, epsilon 3.7825960248364454e-06 total_time 728.0\n",
      "episode 2498, reward 785.0, memory_length 2000, epsilon 3.7637302484568935e-06 total_time 729.0\n",
      "episode 2499, reward 1121.0, memory_length 2000, epsilon 3.7449585655295807e-06 total_time 729.0\n",
      "episode 2500, reward 721.0, memory_length 2000, epsilon 3.726280506761463e-06 total_time 724.0\n",
      "Saving Model 2500\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2501, reward 1479.0, memory_length 2000, epsilon 3.707695605200085e-06 total_time 722.0\n",
      "episode 2502, reward 808.0, memory_length 2000, epsilon 3.6892033962219533e-06 total_time 729.0\n",
      "episode 2503, reward 897.0, memory_length 2000, epsilon 3.670803417520866e-06 total_time 727.0\n",
      "episode 2504, reward 817.0, memory_length 2000, epsilon 3.6524952090964115e-06 total_time 722.0\n",
      "episode 2505, reward 1274.0, memory_length 2000, epsilon 3.6342783132424124e-06 total_time 721.0\n",
      "episode 2506, reward 839.0, memory_length 2000, epsilon 3.6161522745355295e-06 total_time 725.0\n",
      "episode 2507, reward 869.0, memory_length 2000, epsilon 3.598116639823858e-06 total_time 727.0\n",
      "episode 2508, reward 585.0, memory_length 2000, epsilon 3.5801709582155774e-06 total_time 723.0\n",
      "episode 2509, reward 1219.0, memory_length 2000, epsilon 3.5623147810677265e-06 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2510, reward 1241.0, memory_length 2000, epsilon 3.544547661974933e-06 total_time 721.0\n",
      "Saving Model 2510\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2511, reward 1149.0, memory_length 2000, epsilon 3.526869156758307e-06 total_time 726.0\n",
      "episode 2512, reward 1188.0, memory_length 2000, epsilon 3.5092788234542857e-06 total_time 725.0\n",
      "episode 2513, reward 1121.0, memory_length 2000, epsilon 3.4917762223036314e-06 total_time 723.0\n",
      "episode 2514, reward 803.0, memory_length 2000, epsilon 3.4743609157403923e-06 total_time 733.0\n",
      "episode 2515, reward 825.0, memory_length 2000, epsilon 3.457032468381003e-06 total_time 721.0\n",
      "episode 2516, reward 1020.0, memory_length 2000, epsilon 3.4397904470133834e-06 total_time 725.0\n",
      "episode 2517, reward 1096.0, memory_length 2000, epsilon 3.4226344205860888e-06 total_time 721.0\n",
      "episode 2518, reward 704.0, memory_length 2000, epsilon 3.4055639601975774e-06 total_time 725.0\n",
      "episode 2519, reward 619.0, memory_length 2000, epsilon 3.388578639085438e-06 total_time 725.0\n",
      "episode 2520, reward 1236.0, memory_length 2000, epsilon 3.3716780326157707e-06 total_time 724.0\n",
      "Saving Model 2520\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2521, reward 926.0, memory_length 2000, epsilon 3.354861718272521e-06 total_time 730.0\n",
      "episode 2522, reward 920.0, memory_length 2000, epsilon 3.338129275646966e-06 total_time 727.0\n",
      "episode 2523, reward 1034.0, memory_length 2000, epsilon 3.321480286427158e-06 total_time 723.0\n",
      "episode 2524, reward 1061.0, memory_length 2000, epsilon 3.3049143343875045e-06 total_time 725.0\n",
      "episode 2525, reward 1252.0, memory_length 2000, epsilon 3.288431005378348e-06 total_time 723.0\n",
      "episode 2526, reward 938.0, memory_length 2000, epsilon 3.272029887315592e-06 total_time 730.0\n",
      "episode 2527, reward 1336.0, memory_length 2000, epsilon 3.2557105701704434e-06 total_time 724.0\n",
      "episode 2528, reward 1548.0, memory_length 2000, epsilon 3.2394726459591118e-06 total_time 726.0\n",
      "episode 2529, reward 840.0, memory_length 2000, epsilon 3.2233157087326576e-06 total_time 727.0\n",
      "episode 2530, reward 1278.0, memory_length 2000, epsilon 3.207239354566797e-06 total_time 722.0\n",
      "Saving Model 2530\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2531, reward 1568.0, memory_length 2000, epsilon 3.1912431815518444e-06 total_time 731.0\n",
      "episode 2532, reward 970.0, memory_length 2000, epsilon 3.1753267897826466e-06 total_time 731.0\n",
      "episode 2533, reward 852.0, memory_length 2000, epsilon 3.15948978134857e-06 total_time 726.0\n",
      "episode 2534, reward 927.0, memory_length 2000, epsilon 3.14373176032359e-06 total_time 729.0\n",
      "episode 2535, reward 755.0, memory_length 2000, epsilon 3.1280523327563475e-06 total_time 725.0\n",
      "episode 2536, reward 990.0, memory_length 2000, epsilon 3.11245110666035e-06 total_time 724.0\n",
      "episode 2537, reward 891.0, memory_length 2000, epsilon 3.0969276920041204e-06 total_time 729.0\n",
      "episode 2538, reward 1513.0, memory_length 2000, epsilon 3.0814817007014942e-06 total_time 721.0\n",
      "episode 2539, reward 1197.0, memory_length 2000, epsilon 3.0661127466018745e-06 total_time 728.0\n",
      "episode 2540, reward 1314.0, memory_length 2000, epsilon 3.0508204454806133e-06 total_time 724.0\n",
      "Saving Model 2540\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2541, reward 1340.0, memory_length 2000, epsilon 3.035604415029392e-06 total_time 722.0\n",
      "episode 2542, reward 343.0, memory_length 2000, epsilon 3.0204642748466445e-06 total_time 722.0\n",
      "episode 2543, reward 1435.0, memory_length 2000, epsilon 3.0053996464280903e-06 total_time 721.0\n",
      "episode 2544, reward 806.0, memory_length 2000, epsilon 2.9904101531572225e-06 total_time 729.0\n",
      "episode 2545, reward 771.0, memory_length 2000, epsilon 2.9754954202959402e-06 total_time 724.0\n",
      "episode 2546, reward 628.0, memory_length 2000, epsilon 2.960655074975133e-06 total_time 722.0\n",
      "episode 2547, reward 544.0, memory_length 2000, epsilon 2.945888746185407e-06 total_time 725.0\n",
      "episode 2548, reward 612.0, memory_length 2000, epsilon 2.9311960647677618e-06 total_time 736.0\n",
      "episode 2549, reward 1115.0, memory_length 2000, epsilon 2.9165766634044026e-06 total_time 722.0\n",
      "episode 2550, reward 906.0, memory_length 2000, epsilon 2.902030176609539e-06 total_time 721.0\n",
      "Saving Model 2550\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2551, reward 683.0, memory_length 2000, epsilon 2.8875562407202327e-06 total_time 724.0\n",
      "episode 2552, reward 639.0, memory_length 2000, epsilon 2.8731544938873435e-06 total_time 724.0\n",
      "episode 2553, reward 921.0, memory_length 2000, epsilon 2.8588245760664394e-06 total_time 721.0\n",
      "episode 2554, reward 995.0, memory_length 2000, epsilon 2.8445661290088397e-06 total_time 725.0\n",
      "episode 2555, reward 968.0, memory_length 2000, epsilon 2.830378796252615e-06 total_time 729.0\n",
      "episode 2556, reward 744.0, memory_length 2000, epsilon 2.8162622231137124e-06 total_time 731.0\n",
      "episode 2557, reward 1410.0, memory_length 2000, epsilon 2.8022160566770722e-06 total_time 721.0\n",
      "episode 2558, reward 1563.0, memory_length 2000, epsilon 2.788239945787794e-06 total_time 723.0\n",
      "episode 2559, reward 835.0, memory_length 2000, epsilon 2.7743335410423854e-06 total_time 721.0\n",
      "episode 2560, reward 695.0, memory_length 2000, epsilon 2.760496494779995e-06 total_time 729.0\n",
      "Saving Model 2560\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2561, reward 1176.0, memory_length 2000, epsilon 2.746728461073755e-06 total_time 724.0\n",
      "episode 2562, reward 1116.0, memory_length 2000, epsilon 2.733029095722096e-06 total_time 721.0\n",
      "episode 2563, reward 1149.0, memory_length 2000, epsilon 2.7193980562401803e-06 total_time 727.0\n",
      "episode 2564, reward 915.0, memory_length 2000, epsilon 2.705835001851301e-06 total_time 727.0\n",
      "episode 2565, reward 1172.0, memory_length 2000, epsilon 2.692339593478397e-06 total_time 739.0\n",
      "episode 2566, reward 1517.0, memory_length 2000, epsilon 2.6789114937355604e-06 total_time 729.0\n",
      "episode 2567, reward 1301.0, memory_length 2000, epsilon 2.66555036691959e-06 total_time 729.0\n",
      "episode 2568, reward 1029.0, memory_length 2000, epsilon 2.6522558790016277e-06 total_time 727.0\n",
      "episode 2569, reward 1058.0, memory_length 2000, epsilon 2.639027697618775e-06 total_time 721.0\n",
      "episode 2570, reward 748.0, memory_length 2000, epsilon 2.625865492065816e-06 total_time 722.0\n",
      "Saving Model 2570\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2571, reward 495.0, memory_length 2000, epsilon 2.612768933286918e-06 total_time 721.0\n",
      "episode 2572, reward 644.0, memory_length 2000, epsilon 2.599737693867439e-06 total_time 725.0\n",
      "episode 2573, reward 884.0, memory_length 2000, epsilon 2.586771448025705e-06 total_time 728.0\n",
      "episode 2574, reward 1393.0, memory_length 2000, epsilon 2.5738698716048994e-06 total_time 731.0\n",
      "episode 2575, reward 1102.0, memory_length 2000, epsilon 2.5610326420649447e-06 total_time 728.0\n",
      "episode 2576, reward 845.0, memory_length 2000, epsilon 2.5482594384744234e-06 total_time 725.0\n",
      "episode 2577, reward 1138.0, memory_length 2000, epsilon 2.5355499415025916e-06 total_time 722.0\n",
      "episode 2578, reward 1232.0, memory_length 2000, epsilon 2.522903833411352e-06 total_time 732.0\n",
      "episode 2579, reward 1482.0, memory_length 2000, epsilon 2.510320798047354e-06 total_time 727.0\n",
      "episode 2580, reward 878.0, memory_length 2000, epsilon 2.497800520834048e-06 total_time 727.0\n",
      "Saving Model 2580\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2581, reward 943.0, memory_length 2000, epsilon 2.4853426887638577e-06 total_time 722.0\n",
      "episode 2582, reward 1017.0, memory_length 2000, epsilon 2.4729469903903357e-06 total_time 723.0\n",
      "episode 2583, reward 985.0, memory_length 2000, epsilon 2.4606131158203684e-06 total_time 726.0\n",
      "episode 2584, reward 920.0, memory_length 2000, epsilon 2.4483407567064576e-06 total_time 725.0\n",
      "episode 2585, reward 1167.0, memory_length 2000, epsilon 2.4361296062389784e-06 total_time 725.0\n",
      "episode 2586, reward 1475.0, memory_length 2000, epsilon 2.4239793591385413e-06 total_time 728.0\n",
      "episode 2587, reward 1266.0, memory_length 2000, epsilon 2.4118897116483277e-06 total_time 728.0\n",
      "episode 2588, reward 1064.0, memory_length 2000, epsilon 2.399860361526528e-06 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2589, reward 1133.0, memory_length 2000, epsilon 2.387891008038756e-06 total_time 724.0\n",
      "episode 2590, reward 1119.0, memory_length 2000, epsilon 2.375981351950554e-06 total_time 724.0\n",
      "Saving Model 2590\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2591, reward 1415.0, memory_length 2000, epsilon 2.364131095519904e-06 total_time 721.0\n",
      "episode 2592, reward 1045.0, memory_length 2000, epsilon 2.35233994248977e-06 total_time 735.0\n",
      "episode 2593, reward 1066.0, memory_length 2000, epsilon 2.34060759808072e-06 total_time 726.0\n",
      "episode 2594, reward 833.0, memory_length 2000, epsilon 2.3289337689835246e-06 total_time 726.0\n",
      "episode 2595, reward 1111.0, memory_length 2000, epsilon 2.317318163351857e-06 total_time 721.0\n",
      "episode 2596, reward 867.0, memory_length 2000, epsilon 2.3057604907949625e-06 total_time 722.0\n",
      "episode 2597, reward 1284.0, memory_length 2000, epsilon 2.294260462370434e-06 total_time 731.0\n",
      "episode 2598, reward 802.0, memory_length 2000, epsilon 2.282817790576953e-06 total_time 729.0\n",
      "episode 2599, reward 823.0, memory_length 2000, epsilon 2.271432189347134e-06 total_time 724.0\n",
      "episode 2600, reward 881.0, memory_length 2000, epsilon 2.260103374040356e-06 total_time 729.0\n",
      "Saving Model 2600\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2601, reward 1124.0, memory_length 2000, epsilon 2.248831061435639e-06 total_time 725.0\n",
      "episode 2602, reward 1178.0, memory_length 2000, epsilon 2.237614969724589e-06 total_time 728.0\n",
      "episode 2603, reward 1071.0, memory_length 2000, epsilon 2.2264548185043204e-06 total_time 724.0\n",
      "episode 2604, reward 841.0, memory_length 2000, epsilon 2.2153503287704796e-06 total_time 731.0\n",
      "episode 2605, reward 1017.0, memory_length 2000, epsilon 2.204301222910237e-06 total_time 729.0\n",
      "episode 2606, reward 1163.0, memory_length 2000, epsilon 2.1933072246953744e-06 total_time 721.0\n",
      "episode 2607, reward 425.0, memory_length 2000, epsilon 2.1823680592753682e-06 total_time 722.0\n",
      "episode 2608, reward 964.0, memory_length 2000, epsilon 2.171483453170505e-06 total_time 723.0\n",
      "episode 2609, reward 956.0, memory_length 2000, epsilon 2.1606531342650734e-06 total_time 727.0\n",
      "episode 2610, reward 1183.0, memory_length 2000, epsilon 2.1498768318005286e-06 total_time 722.0\n",
      "Saving Model 2610\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2611, reward 1466.0, memory_length 2000, epsilon 2.1391542763687553e-06 total_time 724.0\n",
      "episode 2612, reward 1139.0, memory_length 2000, epsilon 2.128485199905302e-06 total_time 727.0\n",
      "episode 2613, reward 1499.0, memory_length 2000, epsilon 2.1178693356827085e-06 total_time 721.0\n",
      "episode 2614, reward 1063.0, memory_length 2000, epsilon 2.107306418303809e-06 total_time 730.0\n",
      "episode 2615, reward 1130.0, memory_length 2000, epsilon 2.0967961836951233e-06 total_time 726.0\n",
      "episode 2616, reward 1104.0, memory_length 2000, epsilon 2.0863383691002417e-06 total_time 722.0\n",
      "episode 2617, reward 822.0, memory_length 2000, epsilon 2.075932713073247e-06 total_time 726.0\n",
      "episode 2618, reward 1230.0, memory_length 2000, epsilon 2.065578955472205e-06 total_time 730.0\n",
      "episode 2619, reward 1217.0, memory_length 2000, epsilon 2.0552768374526283e-06 total_time 726.0\n",
      "episode 2620, reward 936.0, memory_length 2000, epsilon 2.0450261014610375e-06 total_time 723.0\n",
      "Saving Model 2620\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2621, reward 1092.0, memory_length 2000, epsilon 2.034826491228491e-06 total_time 729.0\n",
      "episode 2622, reward 951.0, memory_length 2000, epsilon 2.02467775176421e-06 total_time 725.0\n",
      "episode 2623, reward 1183.0, memory_length 2000, epsilon 2.014579629349171e-06 total_time 724.0\n",
      "episode 2624, reward 793.0, memory_length 2000, epsilon 2.004531871529792e-06 total_time 725.0\n",
      "episode 2625, reward 1404.0, memory_length 2000, epsilon 1.994534227111608e-06 total_time 724.0\n",
      "episode 2626, reward 1080.0, memory_length 2000, epsilon 1.98458644615298e-06 total_time 729.0\n",
      "episode 2627, reward 1260.0, memory_length 2000, epsilon 1.9746882799588733e-06 total_time 729.0\n",
      "episode 2628, reward 830.0, memory_length 2000, epsilon 1.96483948107461e-06 total_time 729.0\n",
      "episode 2629, reward 947.0, memory_length 2000, epsilon 1.955039803279713e-06 total_time 727.0\n",
      "episode 2630, reward 1253.0, memory_length 2000, epsilon 1.94528900158172e-06 total_time 728.0\n",
      "Saving Model 2630\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2631, reward 891.0, memory_length 2000, epsilon 1.9355868322100835e-06 total_time 724.0\n",
      "episode 2632, reward 1042.0, memory_length 2000, epsilon 1.9259330526100675e-06 total_time 721.0\n",
      "episode 2633, reward 1071.0, memory_length 2000, epsilon 1.916327421436672e-06 total_time 724.0\n",
      "episode 2634, reward 641.0, memory_length 2000, epsilon 1.9067696985486252e-06 total_time 728.0\n",
      "episode 2635, reward 1056.0, memory_length 2000, epsilon 1.8972596450023495e-06 total_time 723.0\n",
      "episode 2636, reward 699.0, memory_length 2000, epsilon 1.887797023046018e-06 total_time 726.0\n",
      "episode 2637, reward 992.0, memory_length 2000, epsilon 1.878381596113582e-06 total_time 730.0\n",
      "episode 2638, reward 1210.0, memory_length 2000, epsilon 1.869013128818885e-06 total_time 734.0\n",
      "episode 2639, reward 1181.0, memory_length 2000, epsilon 1.8596913869497495e-06 total_time 722.0\n",
      "episode 2640, reward 994.0, memory_length 2000, epsilon 1.8504161374621466e-06 total_time 725.0\n",
      "Saving Model 2640\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2641, reward 993.0, memory_length 2000, epsilon 1.8411871484743596e-06 total_time 721.0\n",
      "episode 2642, reward 1260.0, memory_length 2000, epsilon 1.8320041892611765e-06 total_time 724.0\n",
      "episode 2643, reward 687.0, memory_length 2000, epsilon 1.8228670302481449e-06 total_time 726.0\n",
      "episode 2644, reward 776.0, memory_length 2000, epsilon 1.8137754430058073e-06 total_time 723.0\n",
      "episode 2645, reward 902.0, memory_length 2000, epsilon 1.804729200244016e-06 total_time 730.0\n",
      "episode 2646, reward 724.0, memory_length 2000, epsilon 1.7957280758062236e-06 total_time 723.0\n",
      "episode 2647, reward 837.0, memory_length 2000, epsilon 1.7867718446638573e-06 total_time 728.0\n",
      "episode 2648, reward 1089.0, memory_length 2000, epsilon 1.7778602829106655e-06 total_time 721.0\n",
      "episode 2649, reward 914.0, memory_length 2000, epsilon 1.7689931677571435e-06 total_time 725.0\n",
      "episode 2650, reward 1048.0, memory_length 2000, epsilon 1.7601702775249537e-06 total_time 724.0\n",
      "Saving Model 2650\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2651, reward 1387.0, memory_length 2000, epsilon 1.7513913916413745e-06 total_time 731.0\n",
      "episode 2652, reward 1345.0, memory_length 2000, epsilon 1.7426562906338078e-06 total_time 722.0\n",
      "episode 2653, reward 711.0, memory_length 2000, epsilon 1.7339647561242672e-06 total_time 726.0\n",
      "episode 2654, reward 1066.0, memory_length 2000, epsilon 1.7253165708239437e-06 total_time 729.0\n",
      "episode 2655, reward 548.0, memory_length 2000, epsilon 1.716711518527748e-06 total_time 730.0\n",
      "episode 2656, reward 1480.0, memory_length 2000, epsilon 1.7081493841089276e-06 total_time 725.0\n",
      "episode 2657, reward 836.0, memory_length 2000, epsilon 1.699629953513679e-06 total_time 723.0\n",
      "episode 2658, reward 1148.0, memory_length 2000, epsilon 1.691153013755788e-06 total_time 730.0\n",
      "episode 2659, reward 1266.0, memory_length 2000, epsilon 1.6827183529113245e-06 total_time 723.0\n",
      "episode 2660, reward 1373.0, memory_length 2000, epsilon 1.6743257601133227e-06 total_time 734.0\n",
      "Saving Model 2660\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2661, reward 931.0, memory_length 2000, epsilon 1.665975025546531e-06 total_time 727.0\n",
      "episode 2662, reward 1009.0, memory_length 2000, epsilon 1.657665940442145e-06 total_time 722.0\n",
      "episode 2663, reward 1046.0, memory_length 2000, epsilon 1.6493982970726095e-06 total_time 721.0\n",
      "episode 2664, reward 573.0, memory_length 2000, epsilon 1.6411718887464043e-06 total_time 721.0\n",
      "episode 2665, reward 1143.0, memory_length 2000, epsilon 1.6329865098028953e-06 total_time 721.0\n",
      "episode 2666, reward 763.0, memory_length 2000, epsilon 1.6248419556071858e-06 total_time 722.0\n",
      "episode 2667, reward 909.0, memory_length 2000, epsilon 1.616738022544991e-06 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2668, reward 1397.0, memory_length 2000, epsilon 1.608674508017568e-06 total_time 725.0\n",
      "episode 2669, reward 1171.0, memory_length 2000, epsilon 1.6006512104366273e-06 total_time 722.0\n",
      "episode 2670, reward 947.0, memory_length 2000, epsilon 1.592667929219318e-06 total_time 731.0\n",
      "Saving Model 2670\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2671, reward 486.0, memory_length 2000, epsilon 1.584724464783188e-06 total_time 721.0\n",
      "episode 2672, reward 865.0, memory_length 2000, epsilon 1.576820618541218e-06 total_time 727.0\n",
      "episode 2673, reward 1231.0, memory_length 2000, epsilon 1.568956192896835e-06 total_time 735.0\n",
      "episode 2674, reward 1049.0, memory_length 2000, epsilon 1.5611309912389908e-06 total_time 726.0\n",
      "episode 2675, reward 800.0, memory_length 2000, epsilon 1.5533448179372393e-06 total_time 726.0\n",
      "episode 2676, reward 732.0, memory_length 2000, epsilon 1.545597478336837e-06 total_time 727.0\n",
      "episode 2677, reward 1126.0, memory_length 2000, epsilon 1.5378887787538958e-06 total_time 721.0\n",
      "episode 2678, reward 819.0, memory_length 2000, epsilon 1.5302185264705192e-06 total_time 723.0\n",
      "episode 2679, reward 1275.0, memory_length 2000, epsilon 1.522586529730006e-06 total_time 726.0\n",
      "episode 2680, reward 1486.0, memory_length 2000, epsilon 1.5149925977320347e-06 total_time 721.0\n",
      "Saving Model 2680\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2681, reward 1059.0, memory_length 2000, epsilon 1.5074365406279127e-06 total_time 721.0\n",
      "episode 2682, reward 1212.0, memory_length 2000, epsilon 1.4999181695158214e-06 total_time 722.0\n",
      "episode 2683, reward 1093.0, memory_length 2000, epsilon 1.4924372964360863e-06 total_time 725.0\n",
      "episode 2684, reward 1160.0, memory_length 2000, epsilon 1.484993734366496e-06 total_time 725.0\n",
      "episode 2685, reward 1079.0, memory_length 2000, epsilon 1.4775872972176055e-06 total_time 722.0\n",
      "episode 2686, reward 1282.0, memory_length 2000, epsilon 1.4702177998281058e-06 total_time 723.0\n",
      "episode 2687, reward 1023.0, memory_length 2000, epsilon 1.4628850579601732e-06 total_time 727.0\n",
      "episode 2688, reward 1149.0, memory_length 2000, epsilon 1.4555888882948842e-06 total_time 722.0\n",
      "episode 2689, reward 852.0, memory_length 2000, epsilon 1.4483291084276118e-06 total_time 735.0\n",
      "episode 2690, reward 968.0, memory_length 2000, epsilon 1.4411055368634843e-06 total_time 725.0\n",
      "Saving Model 2690\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2691, reward 1009.0, memory_length 2000, epsilon 1.4339179930128382e-06 total_time 724.0\n",
      "episode 2692, reward 1237.0, memory_length 2000, epsilon 1.4267662971866984e-06 total_time 726.0\n",
      "episode 2693, reward 1004.0, memory_length 2000, epsilon 1.4196502705923015e-06 total_time 722.0\n",
      "episode 2694, reward 1361.0, memory_length 2000, epsilon 1.4125697353286071e-06 total_time 728.0\n",
      "episode 2695, reward 1041.0, memory_length 2000, epsilon 1.4055245143818699e-06 total_time 728.0\n",
      "episode 2696, reward 921.0, memory_length 2000, epsilon 1.3985144316211942e-06 total_time 726.0\n",
      "episode 2697, reward 775.0, memory_length 2000, epsilon 1.3915393117941507e-06 total_time 726.0\n",
      "episode 2698, reward 838.0, memory_length 2000, epsilon 1.3845989805223758e-06 total_time 725.0\n",
      "episode 2699, reward 658.0, memory_length 2000, epsilon 1.3776932642972284e-06 total_time 727.0\n",
      "episode 2700, reward 1107.0, memory_length 2000, epsilon 1.370821990475446e-06 total_time 729.0\n",
      "Saving Model 2700\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2701, reward 1892.0, memory_length 2000, epsilon 1.3639849872748199e-06 total_time 728.0\n",
      "episode 2702, reward 1180.0, memory_length 2000, epsilon 1.3571820837699193e-06 total_time 726.0\n",
      "episode 2703, reward 1229.0, memory_length 2000, epsilon 1.3504131098877969e-06 total_time 727.0\n",
      "episode 2704, reward 750.0, memory_length 2000, epsilon 1.3436778964037582e-06 total_time 724.0\n",
      "episode 2705, reward 795.0, memory_length 2000, epsilon 1.3369762749371106e-06 total_time 722.0\n",
      "episode 2706, reward 883.0, memory_length 2000, epsilon 1.3303080779469707e-06 total_time 723.0\n",
      "episode 2707, reward 714.0, memory_length 2000, epsilon 1.3236731387280685e-06 total_time 729.0\n",
      "episode 2708, reward 835.0, memory_length 2000, epsilon 1.317071291406574e-06 total_time 722.0\n",
      "episode 2709, reward 728.0, memory_length 2000, epsilon 1.3105023709359641e-06 total_time 723.0\n",
      "episode 2710, reward 1239.0, memory_length 2000, epsilon 1.3039662130928808e-06 total_time 727.0\n",
      "Saving Model 2710\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2711, reward 690.0, memory_length 2000, epsilon 1.2974626544730422e-06 total_time 722.0\n",
      "episode 2712, reward 1324.0, memory_length 2000, epsilon 1.2909915324871392e-06 total_time 722.0\n",
      "episode 2713, reward 1315.0, memory_length 2000, epsilon 1.28455268535679e-06 total_time 729.0\n",
      "episode 2714, reward 945.0, memory_length 2000, epsilon 1.278145952110476e-06 total_time 727.0\n",
      "episode 2715, reward 978.0, memory_length 2000, epsilon 1.2717711725795352e-06 total_time 725.0\n",
      "episode 2716, reward 729.0, memory_length 2000, epsilon 1.2654281873941493e-06 total_time 725.0\n",
      "episode 2717, reward 728.0, memory_length 2000, epsilon 1.2591168379793536e-06 total_time 732.0\n",
      "episode 2718, reward 991.0, memory_length 2000, epsilon 1.2528369665510887e-06 total_time 722.0\n",
      "episode 2719, reward 1416.0, memory_length 2000, epsilon 1.2465884161122375e-06 total_time 725.0\n",
      "episode 2720, reward 1422.0, memory_length 2000, epsilon 1.2403710304487178e-06 total_time 726.0\n",
      "Saving Model 2720\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2721, reward 916.0, memory_length 2000, epsilon 1.2341846541255597e-06 total_time 722.0\n",
      "episode 2722, reward 724.0, memory_length 2000, epsilon 1.2280291324830376e-06 total_time 728.0\n",
      "episode 2723, reward 949.0, memory_length 2000, epsilon 1.2219043116327853e-06 total_time 725.0\n",
      "episode 2724, reward 497.0, memory_length 2000, epsilon 1.2158100384539644e-06 total_time 723.0\n",
      "episode 2725, reward 780.0, memory_length 2000, epsilon 1.209746160589431e-06 total_time 727.0\n",
      "episode 2726, reward 1015.0, memory_length 2000, epsilon 1.2037125264419173e-06 total_time 727.0\n",
      "episode 2727, reward 1536.0, memory_length 2000, epsilon 1.1977089851702607e-06 total_time 724.0\n",
      "episode 2728, reward 599.0, memory_length 2000, epsilon 1.1917353866856118e-06 total_time 729.0\n",
      "episode 2729, reward 916.0, memory_length 2000, epsilon 1.1857915816477015e-06 total_time 726.0\n",
      "episode 2730, reward 720.0, memory_length 2000, epsilon 1.1798774214610907e-06 total_time 722.0\n",
      "Saving Model 2730\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2731, reward 831.0, memory_length 2000, epsilon 1.1739927582714682e-06 total_time 734.0\n",
      "episode 2732, reward 902.0, memory_length 2000, epsilon 1.16813744496195e-06 total_time 728.0\n",
      "episode 2733, reward 1222.0, memory_length 2000, epsilon 1.1623113351493946e-06 total_time 728.0\n",
      "episode 2734, reward 966.0, memory_length 2000, epsilon 1.156514283180757e-06 total_time 723.0\n",
      "episode 2735, reward 1002.0, memory_length 2000, epsilon 1.1507461441294317e-06 total_time 721.0\n",
      "episode 2736, reward 766.0, memory_length 2000, epsilon 1.1450067737916469e-06 total_time 725.0\n",
      "episode 2737, reward 1140.0, memory_length 2000, epsilon 1.1392960286828405e-06 total_time 724.0\n",
      "episode 2738, reward 1010.0, memory_length 2000, epsilon 1.1336137660340914e-06 total_time 721.0\n",
      "episode 2739, reward 1116.0, memory_length 2000, epsilon 1.1279598437885336e-06 total_time 723.0\n",
      "episode 2740, reward 959.0, memory_length 2000, epsilon 1.1223341205978188e-06 total_time 726.0\n",
      "Saving Model 2740\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2741, reward 1068.0, memory_length 2000, epsilon 1.1167364558185756e-06 total_time 726.0\n",
      "episode 2742, reward 1123.0, memory_length 2000, epsilon 1.1111667095088894e-06 total_time 728.0\n",
      "episode 2743, reward 1761.0, memory_length 2000, epsilon 1.105624742424816e-06 total_time 721.0\n",
      "episode 2744, reward 1456.0, memory_length 2000, epsilon 1.1001104160168862e-06 total_time 727.0\n",
      "episode 2745, reward 1134.0, memory_length 2000, epsilon 1.0946235924266563e-06 total_time 724.0\n",
      "episode 2746, reward 1273.0, memory_length 2000, epsilon 1.0891641344832465e-06 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2747, reward 1093.0, memory_length 2000, epsilon 1.0837319056999284e-06 total_time 722.0\n",
      "episode 2748, reward 994.0, memory_length 2000, epsilon 1.0783267702706952e-06 total_time 722.0\n",
      "episode 2749, reward 762.0, memory_length 2000, epsilon 1.0729485930668814e-06 total_time 725.0\n",
      "episode 2750, reward 1028.0, memory_length 2000, epsilon 1.0675972396337793e-06 total_time 726.0\n",
      "Saving Model 2750\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2751, reward 985.0, memory_length 2000, epsilon 1.06227257618727e-06 total_time 727.0\n",
      "episode 2752, reward 924.0, memory_length 2000, epsilon 1.056974469610494e-06 total_time 726.0\n",
      "episode 2753, reward 1232.0, memory_length 2000, epsilon 1.0517027874505073e-06 total_time 723.0\n",
      "episode 2754, reward 990.0, memory_length 2000, epsilon 1.0464573979149849e-06 total_time 723.0\n",
      "episode 2755, reward 983.0, memory_length 2000, epsilon 1.0412381698689118e-06 total_time 723.0\n",
      "episode 2756, reward 531.0, memory_length 2000, epsilon 1.0360449728313162e-06 total_time 723.0\n",
      "episode 2757, reward 718.0, memory_length 2000, epsilon 1.030877676972004e-06 total_time 725.0\n",
      "episode 2758, reward 423.0, memory_length 2000, epsilon 1.0257361531083062e-06 total_time 721.0\n",
      "episode 2759, reward 763.0, memory_length 2000, epsilon 1.0206202727018615e-06 total_time 726.0\n",
      "episode 2760, reward 870.0, memory_length 2000, epsilon 1.01552990785539e-06 total_time 721.0\n",
      "Saving Model 2760\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2761, reward 1512.0, memory_length 2000, epsilon 1.0104649313095086e-06 total_time 723.0\n",
      "episode 2762, reward 1386.0, memory_length 2000, epsilon 1.0054252164395372e-06 total_time 722.0\n",
      "episode 2763, reward 1031.0, memory_length 2000, epsilon 1.000410637252344e-06 total_time 726.0\n",
      "episode 2764, reward 893.0, memory_length 2000, epsilon 9.95421068383185e-07 total_time 724.0\n",
      "episode 2765, reward 1122.0, memory_length 2000, epsilon 9.904563850925807e-07 total_time 723.0\n",
      "episode 2766, reward 492.0, memory_length 2000, epsilon 9.855164632631918e-07 total_time 731.0\n",
      "episode 2767, reward 1214.0, memory_length 2000, epsilon 9.806011793967118e-07 total_time 722.0\n",
      "episode 2768, reward 1050.0, memory_length 2000, epsilon 9.757104106107913e-07 total_time 726.0\n",
      "episode 2769, reward 781.0, memory_length 2000, epsilon 9.70844034635953e-07 total_time 727.0\n",
      "episode 2770, reward 750.0, memory_length 2000, epsilon 9.660019298125467e-07 total_time 722.0\n",
      "Saving Model 2770\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2771, reward 1160.0, memory_length 2000, epsilon 9.61183975087697e-07 total_time 724.0\n",
      "episode 2772, reward 1412.0, memory_length 2000, epsilon 9.563900500122877e-07 total_time 727.0\n",
      "episode 2773, reward 1009.0, memory_length 2000, epsilon 9.516200347379391e-07 total_time 722.0\n",
      "episode 2774, reward 881.0, memory_length 2000, epsilon 9.468738100140224e-07 total_time 729.0\n",
      "episode 2775, reward 1169.0, memory_length 2000, epsilon 9.421512571846742e-07 total_time 726.0\n",
      "episode 2776, reward 1011.0, memory_length 2000, epsilon 9.374522581858244e-07 total_time 721.0\n",
      "episode 2777, reward 1027.0, memory_length 2000, epsilon 9.327766955422566e-07 total_time 724.0\n",
      "episode 2778, reward 1294.0, memory_length 2000, epsilon 9.281244523646578e-07 total_time 725.0\n",
      "episode 2779, reward 1270.0, memory_length 2000, epsilon 9.234954123467097e-07 total_time 724.0\n",
      "episode 2780, reward 723.0, memory_length 2000, epsilon 9.188894597621673e-07 total_time 727.0\n",
      "Saving Model 2780\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2781, reward 1201.0, memory_length 2000, epsilon 9.143064794619779e-07 total_time 723.0\n",
      "episode 2782, reward 887.0, memory_length 2000, epsilon 9.097463568713968e-07 total_time 722.0\n",
      "episode 2783, reward 936.0, memory_length 2000, epsilon 9.052089779871185e-07 total_time 721.0\n",
      "episode 2784, reward 1021.0, memory_length 2000, epsilon 9.006942293744378e-07 total_time 729.0\n",
      "episode 2785, reward 512.0, memory_length 2000, epsilon 8.962019981644012e-07 total_time 726.0\n",
      "episode 2786, reward 1212.0, memory_length 2000, epsilon 8.917321720509975e-07 total_time 724.0\n",
      "episode 2787, reward 849.0, memory_length 2000, epsilon 8.872846392883378e-07 total_time 723.0\n",
      "episode 2788, reward 1414.0, memory_length 2000, epsilon 8.828592886878748e-07 total_time 721.0\n",
      "episode 2789, reward 892.0, memory_length 2000, epsilon 8.784560096156096e-07 total_time 721.0\n",
      "episode 2790, reward 1114.0, memory_length 2000, epsilon 8.740746919893378e-07 total_time 726.0\n",
      "Saving Model 2790\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2791, reward 997.0, memory_length 2000, epsilon 8.697152262758921e-07 total_time 725.0\n",
      "episode 2792, reward 1198.0, memory_length 2000, epsilon 8.653775034883993e-07 total_time 732.0\n",
      "episode 2793, reward 1008.0, memory_length 2000, epsilon 8.610614151835671e-07 total_time 726.0\n",
      "episode 2794, reward 971.0, memory_length 2000, epsilon 8.567668534589601e-07 total_time 726.0\n",
      "episode 2795, reward 1199.0, memory_length 2000, epsilon 8.524937109503142e-07 total_time 730.0\n",
      "episode 2796, reward 1121.0, memory_length 2000, epsilon 8.482418808288414e-07 total_time 721.0\n",
      "episode 2797, reward 1492.0, memory_length 2000, epsilon 8.440112567985701e-07 total_time 727.0\n",
      "episode 2798, reward 1018.0, memory_length 2000, epsilon 8.398017330936763e-07 total_time 726.0\n",
      "episode 2799, reward 1035.0, memory_length 2000, epsilon 8.356132044758494e-07 total_time 726.0\n",
      "episode 2800, reward 1316.0, memory_length 2000, epsilon 8.314455662316575e-07 total_time 729.0\n",
      "Saving Model 2800\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2801, reward 800.0, memory_length 2000, epsilon 8.272987141699244e-07 total_time 729.0\n",
      "episode 2802, reward 908.0, memory_length 2000, epsilon 8.231725446191356e-07 total_time 728.0\n",
      "episode 2803, reward 1077.0, memory_length 2000, epsilon 8.190669544248344e-07 total_time 725.0\n",
      "episode 2804, reward 1483.0, memory_length 2000, epsilon 8.14981840947055e-07 total_time 721.0\n",
      "episode 2805, reward 1601.0, memory_length 2000, epsilon 8.109171020577449e-07 total_time 723.0\n",
      "episode 2806, reward 943.0, memory_length 2000, epsilon 8.068726361382215e-07 total_time 722.0\n",
      "episode 2807, reward 1149.0, memory_length 2000, epsilon 8.028483420766277e-07 total_time 721.0\n",
      "episode 2808, reward 507.0, memory_length 2000, epsilon 7.988441192653993e-07 total_time 723.0\n",
      "episode 2809, reward 764.0, memory_length 2000, epsilon 7.948598675987606e-07 total_time 722.0\n",
      "episode 2810, reward 910.0, memory_length 2000, epsilon 7.908954874702093e-07 total_time 731.0\n",
      "Saving Model 2810\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2811, reward 1505.0, memory_length 2000, epsilon 7.869508797700388e-07 total_time 726.0\n",
      "episode 2812, reward 1683.0, memory_length 2000, epsilon 7.830259458828481e-07 total_time 729.0\n",
      "episode 2813, reward 485.0, memory_length 2000, epsilon 7.791205876850885e-07 total_time 721.0\n",
      "episode 2814, reward 719.0, memory_length 2000, epsilon 7.75234707542599e-07 total_time 724.0\n",
      "episode 2815, reward 998.0, memory_length 2000, epsilon 7.713682083081748e-07 total_time 723.0\n",
      "episode 2816, reward 1163.0, memory_length 2000, epsilon 7.675209933191352e-07 total_time 722.0\n",
      "episode 2817, reward 456.0, memory_length 2000, epsilon 7.636929663949023e-07 total_time 723.0\n",
      "episode 2818, reward 944.0, memory_length 2000, epsilon 7.598840318346063e-07 total_time 723.0\n",
      "episode 2819, reward 1164.0, memory_length 2000, epsilon 7.560940944146821e-07 total_time 723.0\n",
      "episode 2820, reward 1271.0, memory_length 2000, epsilon 7.523230593864997e-07 total_time 727.0\n",
      "Saving Model 2820\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2821, reward 806.0, memory_length 2000, epsilon 7.48570832473984e-07 total_time 726.0\n",
      "episode 2822, reward 817.0, memory_length 2000, epsilon 7.448373198712697e-07 total_time 721.0\n",
      "episode 2823, reward 722.0, memory_length 2000, epsilon 7.411224282403444e-07 total_time 727.0\n",
      "episode 2824, reward 1093.0, memory_length 2000, epsilon 7.374260647087253e-07 total_time 725.0\n",
      "episode 2825, reward 1238.0, memory_length 2000, epsilon 7.337481368671328e-07 total_time 721.0\n",
      "episode 2826, reward 1197.0, memory_length 2000, epsilon 7.300885527671769e-07 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2827, reward 1011.0, memory_length 2000, epsilon 7.264472209190669e-07 total_time 724.0\n",
      "episode 2828, reward 622.0, memory_length 2000, epsilon 7.228240502893143e-07 total_time 723.0\n",
      "episode 2829, reward 943.0, memory_length 2000, epsilon 7.192189502984674e-07 total_time 728.0\n",
      "episode 2830, reward 1100.0, memory_length 2000, epsilon 7.156318308188361e-07 total_time 721.0\n",
      "Saving Model 2830\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2831, reward 1227.0, memory_length 2000, epsilon 7.120626021722478e-07 total_time 722.0\n",
      "episode 2832, reward 731.0, memory_length 2000, epsilon 7.085111751278016e-07 total_time 728.0\n",
      "episode 2833, reward 862.0, memory_length 2000, epsilon 7.04977460899634e-07 total_time 724.0\n",
      "episode 2834, reward 842.0, memory_length 2000, epsilon 7.014613711447078e-07 total_time 729.0\n",
      "episode 2835, reward 1163.0, memory_length 2000, epsilon 6.979628179605934e-07 total_time 726.0\n",
      "episode 2836, reward 1303.0, memory_length 2000, epsilon 6.944817138832815e-07 total_time 726.0\n",
      "episode 2837, reward 761.0, memory_length 2000, epsilon 6.910179718849866e-07 total_time 730.0\n",
      "episode 2838, reward 656.0, memory_length 2000, epsilon 6.875715053719804e-07 total_time 727.0\n",
      "episode 2839, reward 1215.0, memory_length 2000, epsilon 6.841422281824183e-07 total_time 724.0\n",
      "episode 2840, reward 852.0, memory_length 2000, epsilon 6.807300545841933e-07 total_time 725.0\n",
      "Saving Model 2840\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2841, reward 643.0, memory_length 2000, epsilon 6.773348992727888e-07 total_time 726.0\n",
      "episode 2842, reward 1006.0, memory_length 2000, epsilon 6.739566773691429e-07 total_time 725.0\n",
      "episode 2843, reward 1249.0, memory_length 2000, epsilon 6.705953044175342e-07 total_time 723.0\n",
      "episode 2844, reward 574.0, memory_length 2000, epsilon 6.672506963834616e-07 total_time 723.0\n",
      "episode 2845, reward 959.0, memory_length 2000, epsilon 6.639227696515526e-07 total_time 726.0\n",
      "episode 2846, reward 587.0, memory_length 2000, epsilon 6.60611441023463e-07 total_time 726.0\n",
      "episode 2847, reward 850.0, memory_length 2000, epsilon 6.573166277158069e-07 total_time 728.0\n",
      "episode 2848, reward 783.0, memory_length 2000, epsilon 6.54038247358078e-07 total_time 737.0\n",
      "episode 2849, reward 998.0, memory_length 2000, epsilon 6.507762179905975e-07 total_time 722.0\n",
      "episode 2850, reward 1396.0, memory_length 2000, epsilon 6.475304580624625e-07 total_time 721.0\n",
      "Saving Model 2850\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2851, reward 944.0, memory_length 2000, epsilon 6.443008864295035e-07 total_time 722.0\n",
      "episode 2852, reward 849.0, memory_length 2000, epsilon 6.410874223522637e-07 total_time 724.0\n",
      "episode 2853, reward 1149.0, memory_length 2000, epsilon 6.378899854939717e-07 total_time 721.0\n",
      "episode 2854, reward 1301.0, memory_length 2000, epsilon 6.347084959185416e-07 total_time 723.0\n",
      "episode 2855, reward 809.0, memory_length 2000, epsilon 6.31542874088566e-07 total_time 725.0\n",
      "episode 2856, reward 1249.0, memory_length 2000, epsilon 6.283930408633355e-07 total_time 723.0\n",
      "episode 2857, reward 998.0, memory_length 2000, epsilon 6.252589174968566e-07 total_time 722.0\n",
      "episode 2858, reward 1126.0, memory_length 2000, epsilon 6.221404256358796e-07 total_time 731.0\n",
      "episode 2859, reward 1426.0, memory_length 2000, epsilon 6.190374873179479e-07 total_time 724.0\n",
      "episode 2860, reward 948.0, memory_length 2000, epsilon 6.159500249694395e-07 total_time 723.0\n",
      "Saving Model 2860\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2861, reward 985.0, memory_length 2000, epsilon 6.128779614036372e-07 total_time 723.0\n",
      "episode 2862, reward 1357.0, memory_length 2000, epsilon 6.098212198187897e-07 total_time 723.0\n",
      "episode 2863, reward 906.0, memory_length 2000, epsilon 6.067797237962002e-07 total_time 728.0\n",
      "episode 2864, reward 421.0, memory_length 2000, epsilon 6.037533972983076e-07 total_time 724.0\n",
      "episode 2865, reward 867.0, memory_length 2000, epsilon 6.007421646667932e-07 total_time 731.0\n",
      "episode 2866, reward 977.0, memory_length 2000, epsilon 5.97745950620685e-07 total_time 722.0\n",
      "episode 2867, reward 551.0, memory_length 2000, epsilon 5.947646802544741e-07 total_time 727.0\n",
      "episode 2868, reward 1551.0, memory_length 2000, epsilon 5.917982790362478e-07 total_time 724.0\n",
      "episode 2869, reward 965.0, memory_length 2000, epsilon 5.888466728058193e-07 total_time 730.0\n",
      "episode 2870, reward 925.0, memory_length 2000, epsilon 5.859097877728809e-07 total_time 723.0\n",
      "Saving Model 2870\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2871, reward 743.0, memory_length 2000, epsilon 5.829875505151521e-07 total_time 727.0\n",
      "episode 2872, reward 1100.0, memory_length 2000, epsilon 5.800798879765513e-07 total_time 723.0\n",
      "episode 2873, reward 1223.0, memory_length 2000, epsilon 5.771867274653613e-07 total_time 727.0\n",
      "episode 2874, reward 1277.0, memory_length 2000, epsilon 5.743079966524198e-07 total_time 727.0\n",
      "episode 2875, reward 1660.0, memory_length 2000, epsilon 5.714436235693074e-07 total_time 723.0\n",
      "episode 2876, reward 1547.0, memory_length 2000, epsilon 5.685935366065461e-07 total_time 731.0\n",
      "episode 2877, reward 1128.0, memory_length 2000, epsilon 5.657576645118151e-07 total_time 727.0\n",
      "episode 2878, reward 1057.0, memory_length 2000, epsilon 5.629359363881624e-07 total_time 721.0\n",
      "episode 2879, reward 882.0, memory_length 2000, epsilon 5.601282816922403e-07 total_time 724.0\n",
      "episode 2880, reward 707.0, memory_length 2000, epsilon 5.573346302325327e-07 total_time 725.0\n",
      "Saving Model 2880\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2881, reward 837.0, memory_length 2000, epsilon 5.545549121676087e-07 total_time 723.0\n",
      "episode 2882, reward 1141.0, memory_length 2000, epsilon 5.517890580043731e-07 total_time 729.0\n",
      "episode 2883, reward 918.0, memory_length 2000, epsilon 5.490369985963256e-07 total_time 726.0\n",
      "episode 2884, reward 1266.0, memory_length 2000, epsilon 5.462986651418398e-07 total_time 722.0\n",
      "episode 2885, reward 976.0, memory_length 2000, epsilon 5.435739891824345e-07 total_time 726.0\n",
      "episode 2886, reward 611.0, memory_length 2000, epsilon 5.40862902601071e-07 total_time 725.0\n",
      "episode 2887, reward 1149.0, memory_length 2000, epsilon 5.381653376204415e-07 total_time 731.0\n",
      "episode 2888, reward 976.0, memory_length 2000, epsilon 5.35481226801283e-07 total_time 725.0\n",
      "episode 2889, reward 1269.0, memory_length 2000, epsilon 5.328105030406831e-07 total_time 721.0\n",
      "episode 2890, reward 1630.0, memory_length 2000, epsilon 5.301530995704099e-07 total_time 723.0\n",
      "Saving Model 2890\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2891, reward 974.0, memory_length 2000, epsilon 5.275089499552391e-07 total_time 731.0\n",
      "episode 2892, reward 910.0, memory_length 2000, epsilon 5.248779880912906e-07 total_time 724.0\n",
      "episode 2893, reward 1314.0, memory_length 2000, epsilon 5.222601482043827e-07 total_time 725.0\n",
      "episode 2894, reward 985.0, memory_length 2000, epsilon 5.196553648483801e-07 total_time 721.0\n",
      "episode 2895, reward 1413.0, memory_length 2000, epsilon 5.170635729035652e-07 total_time 722.0\n",
      "episode 2896, reward 971.0, memory_length 2000, epsilon 5.144847075750021e-07 total_time 725.0\n",
      "episode 2897, reward 1120.0, memory_length 2000, epsilon 5.119187043909256e-07 total_time 724.0\n",
      "episode 2898, reward 1021.0, memory_length 2000, epsilon 5.093654992011203e-07 total_time 727.0\n",
      "episode 2899, reward 1045.0, memory_length 2000, epsilon 5.068250281753246e-07 total_time 727.0\n",
      "episode 2900, reward 860.0, memory_length 2000, epsilon 5.042972278016312e-07 total_time 725.0\n",
      "Saving Model 2900\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2901, reward 922.0, memory_length 2000, epsilon 5.017820348848977e-07 total_time 725.0\n",
      "episode 2902, reward 553.0, memory_length 2000, epsilon 4.992793865451715e-07 total_time 722.0\n",
      "episode 2903, reward 878.0, memory_length 2000, epsilon 4.967892202161122e-07 total_time 724.0\n",
      "episode 2904, reward 584.0, memory_length 2000, epsilon 4.943114736434337e-07 total_time 724.0\n",
      "episode 2905, reward 698.0, memory_length 2000, epsilon 4.918460848833409e-07 total_time 727.0\n",
      "episode 2906, reward 1463.0, memory_length 2000, epsilon 4.89392992300987e-07 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2907, reward 922.0, memory_length 2000, epsilon 4.86952134568931e-07 total_time 725.0\n",
      "episode 2908, reward 1283.0, memory_length 2000, epsilon 4.845234506656003e-07 total_time 736.0\n",
      "episode 2909, reward 1043.0, memory_length 2000, epsilon 4.821068798737727e-07 total_time 724.0\n",
      "episode 2910, reward 1685.0, memory_length 2000, epsilon 4.797023617790509e-07 total_time 730.0\n",
      "Saving Model 2910\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2911, reward 718.0, memory_length 2000, epsilon 4.77309836268359e-07 total_time 730.0\n",
      "episode 2912, reward 984.0, memory_length 2000, epsilon 4.7492924352843266e-07 total_time 725.0\n",
      "episode 2913, reward 1040.0, memory_length 2000, epsilon 4.7256052404433147e-07 total_time 726.0\n",
      "episode 2914, reward 1398.0, memory_length 2000, epsilon 4.7020361859794307e-07 total_time 723.0\n",
      "episode 2915, reward 911.0, memory_length 2000, epsilon 4.6785846826650934e-07 total_time 725.0\n",
      "episode 2916, reward 742.0, memory_length 2000, epsilon 4.6552501442115085e-07 total_time 727.0\n",
      "episode 2917, reward 843.0, memory_length 2000, epsilon 4.632031987253981e-07 total_time 721.0\n",
      "episode 2918, reward 859.0, memory_length 2000, epsilon 4.6089296313373956e-07 total_time 721.0\n",
      "episode 2919, reward 1040.0, memory_length 2000, epsilon 4.585942498901633e-07 total_time 729.0\n",
      "episode 2920, reward 843.0, memory_length 2000, epsilon 4.5630700152672036e-07 total_time 726.0\n",
      "Saving Model 2920\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2921, reward 820.0, memory_length 2000, epsilon 4.540311608620807e-07 total_time 729.0\n",
      "episode 2922, reward 702.0, memory_length 2000, epsilon 4.51766671000111e-07 total_time 723.0\n",
      "episode 2923, reward 975.0, memory_length 2000, epsilon 4.495134753284449e-07 total_time 725.0\n",
      "episode 2924, reward 1220.0, memory_length 2000, epsilon 4.472715175170743e-07 total_time 722.0\n",
      "episode 2925, reward 740.0, memory_length 2000, epsilon 4.450407415169377e-07 total_time 723.0\n",
      "episode 2926, reward 998.0, memory_length 2000, epsilon 4.4282109155851757e-07 total_time 722.0\n",
      "episode 2927, reward 782.0, memory_length 2000, epsilon 4.4061251215045077e-07 total_time 721.0\n",
      "episode 2928, reward 874.0, memory_length 2000, epsilon 4.3841494807813553e-07 total_time 721.0\n",
      "episode 2929, reward 667.0, memory_length 2000, epsilon 4.362283444023571e-07 total_time 726.0\n",
      "episode 2930, reward 1386.0, memory_length 2000, epsilon 4.340526464579083e-07 total_time 729.0\n",
      "Saving Model 2930\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2931, reward 919.0, memory_length 2000, epsilon 4.3188779985222785e-07 total_time 729.0\n",
      "episode 2932, reward 1164.0, memory_length 2000, epsilon 4.2973375046403866e-07 total_time 724.0\n",
      "episode 2933, reward 1179.0, memory_length 2000, epsilon 4.275904444419923e-07 total_time 728.0\n",
      "episode 2934, reward 817.0, memory_length 2000, epsilon 4.25457828203328e-07 total_time 730.0\n",
      "episode 2935, reward 984.0, memory_length 2000, epsilon 4.233358484325274e-07 total_time 727.0\n",
      "episode 2936, reward 732.0, memory_length 2000, epsilon 4.212244520799871e-07 total_time 725.0\n",
      "episode 2937, reward 1187.0, memory_length 2000, epsilon 4.1912358636068685e-07 total_time 733.0\n",
      "episode 2938, reward 979.0, memory_length 2000, epsilon 4.1703319875287574e-07 total_time 727.0\n",
      "episode 2939, reward 1336.0, memory_length 2000, epsilon 4.1495323699675315e-07 total_time 723.0\n",
      "episode 2940, reward 1165.0, memory_length 2000, epsilon 4.128836490931677e-07 total_time 730.0\n",
      "Saving Model 2940\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2941, reward 965.0, memory_length 2000, epsilon 4.108243833023147e-07 total_time 731.0\n",
      "episode 2942, reward 1311.0, memory_length 2000, epsilon 4.0877538814244064e-07 total_time 723.0\n",
      "episode 2943, reward 713.0, memory_length 2000, epsilon 4.0673661238856127e-07 total_time 722.0\n",
      "episode 2944, reward 937.0, memory_length 2000, epsilon 4.0470800507117506e-07 total_time 724.0\n",
      "episode 2945, reward 1175.0, memory_length 2000, epsilon 4.0268951547499496e-07 total_time 724.0\n",
      "episode 2946, reward 715.0, memory_length 2000, epsilon 4.006810931376744e-07 total_time 729.0\n",
      "episode 2947, reward 1070.0, memory_length 2000, epsilon 3.9868268784855186e-07 total_time 724.0\n",
      "episode 2948, reward 739.0, memory_length 2000, epsilon 3.9669424964738955e-07 total_time 730.0\n",
      "episode 2949, reward 1083.0, memory_length 2000, epsilon 3.947157288231296e-07 total_time 724.0\n",
      "episode 2950, reward 666.0, memory_length 2000, epsilon 3.927470759126491e-07 total_time 722.0\n",
      "Saving Model 2950\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2951, reward 589.0, memory_length 2000, epsilon 3.9078824169952125e-07 total_time 721.0\n",
      "episode 2952, reward 1295.0, memory_length 2000, epsilon 3.888391772127902e-07 total_time 724.0\n",
      "episode 2953, reward 1175.0, memory_length 2000, epsilon 3.8689983372574083e-07 total_time 721.0\n",
      "episode 2954, reward 1018.0, memory_length 2000, epsilon 3.8497016275468634e-07 total_time 731.0\n",
      "episode 2955, reward 803.0, memory_length 2000, epsilon 3.830501160577505e-07 total_time 722.0\n",
      "episode 2956, reward 979.0, memory_length 2000, epsilon 3.8113964563366674e-07 total_time 723.0\n",
      "episode 2957, reward 943.0, memory_length 2000, epsilon 3.7923870372057554e-07 total_time 726.0\n",
      "episode 2958, reward 1008.0, memory_length 2000, epsilon 3.773472427948287e-07 total_time 723.0\n",
      "episode 2959, reward 892.0, memory_length 2000, epsilon 3.754652155698059e-07 total_time 725.0\n",
      "episode 2960, reward 1377.0, memory_length 2000, epsilon 3.735925749947272e-07 total_time 723.0\n",
      "Saving Model 2960\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2961, reward 607.0, memory_length 2000, epsilon 3.71729274253482e-07 total_time 727.0\n",
      "episode 2962, reward 1384.0, memory_length 2000, epsilon 3.6987526676345335e-07 total_time 722.0\n",
      "episode 2963, reward 709.0, memory_length 2000, epsilon 3.680305061743588e-07 total_time 726.0\n",
      "episode 2964, reward 984.0, memory_length 2000, epsilon 3.661949463670862e-07 total_time 723.0\n",
      "episode 2965, reward 756.0, memory_length 2000, epsilon 3.643685414525455e-07 total_time 725.0\n",
      "episode 2966, reward 1144.0, memory_length 2000, epsilon 3.625512457705193e-07 total_time 723.0\n",
      "episode 2967, reward 690.0, memory_length 2000, epsilon 3.607430138885196e-07 total_time 722.0\n",
      "episode 2968, reward 935.0, memory_length 2000, epsilon 3.5894380060065645e-07 total_time 722.0\n",
      "episode 2969, reward 1225.0, memory_length 2000, epsilon 3.5715356092650273e-07 total_time 723.0\n",
      "episode 2970, reward 1064.0, memory_length 2000, epsilon 3.5537225010997457e-07 total_time 728.0\n",
      "Saving Model 2970\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2971, reward 555.0, memory_length 2000, epsilon 3.535998236182075e-07 total_time 734.0\n",
      "episode 2972, reward 1142.0, memory_length 2000, epsilon 3.5183623714044814e-07 total_time 724.0\n",
      "episode 2973, reward 1065.0, memory_length 2000, epsilon 3.500814465869415e-07 total_time 721.0\n",
      "episode 2974, reward 1278.0, memory_length 2000, epsilon 3.48335408087833e-07 total_time 723.0\n",
      "episode 2975, reward 1141.0, memory_length 2000, epsilon 3.465980779920698e-07 total_time 727.0\n",
      "episode 2976, reward 1049.0, memory_length 2000, epsilon 3.4486941286630774e-07 total_time 727.0\n",
      "episode 2977, reward 1139.0, memory_length 2000, epsilon 3.4314936949382994e-07 total_time 729.0\n",
      "episode 2978, reward 1257.0, memory_length 2000, epsilon 3.4143790487346126e-07 total_time 726.0\n",
      "episode 2979, reward 1072.0, memory_length 2000, epsilon 3.397349762184982e-07 total_time 723.0\n",
      "episode 2980, reward 1032.0, memory_length 2000, epsilon 3.380405409556346e-07 total_time 725.0\n",
      "Saving Model 2980\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2981, reward 1528.0, memory_length 2000, epsilon 3.363545567239012e-07 total_time 725.0\n",
      "episode 2982, reward 964.0, memory_length 2000, epsilon 3.3467698137360504e-07 total_time 727.0\n",
      "episode 2983, reward 1047.0, memory_length 2000, epsilon 3.330077729652736e-07 total_time 725.0\n",
      "episode 2984, reward 690.0, memory_length 2000, epsilon 3.313468897686111e-07 total_time 721.0\n",
      "episode 2985, reward 976.0, memory_length 2000, epsilon 3.296942902614499e-07 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2986, reward 901.0, memory_length 2000, epsilon 3.2804993312871745e-07 total_time 731.0\n",
      "episode 2987, reward 978.0, memory_length 2000, epsilon 3.264137772613985e-07 total_time 723.0\n",
      "episode 2988, reward 1321.0, memory_length 2000, epsilon 3.2478578175551245e-07 total_time 725.0\n",
      "episode 2989, reward 1224.0, memory_length 2000, epsilon 3.231659059110856e-07 total_time 721.0\n",
      "episode 2990, reward 775.0, memory_length 2000, epsilon 3.215541092311382e-07 total_time 721.0\n",
      "Saving Model 2990\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 2991, reward 723.0, memory_length 2000, epsilon 3.199503514206697e-07 total_time 725.0\n",
      "episode 2992, reward 1113.0, memory_length 2000, epsilon 3.1835459238565026e-07 total_time 721.0\n",
      "episode 2993, reward 585.0, memory_length 2000, epsilon 3.1676679223202197e-07 total_time 721.0\n",
      "episode 2994, reward 1301.0, memory_length 2000, epsilon 3.1518691126469724e-07 total_time 721.0\n",
      "episode 2995, reward 804.0, memory_length 2000, epsilon 3.1361490998657065e-07 total_time 727.0\n",
      "episode 2996, reward 447.0, memory_length 2000, epsilon 3.1205074909752733e-07 total_time 733.0\n",
      "episode 2997, reward 267.0, memory_length 2000, epsilon 3.104943894934647e-07 total_time 724.0\n",
      "episode 2998, reward 653.0, memory_length 2000, epsilon 3.089457922653104e-07 total_time 722.0\n",
      "episode 2999, reward 709.0, memory_length 2000, epsilon 3.074049186980537e-07 total_time 724.0\n",
      "episode 3000, reward 1497.0, memory_length 2000, epsilon 3.058717302697756e-07 total_time 723.0\n",
      "Saving Model 3000\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3001, reward 875.0, memory_length 2000, epsilon 3.043461886506846e-07 total_time 726.0\n",
      "episode 3002, reward 818.0, memory_length 2000, epsilon 3.028282557021618e-07 total_time 727.0\n",
      "episode 3003, reward 1225.0, memory_length 2000, epsilon 3.0131789347580327e-07 total_time 728.0\n",
      "episode 3004, reward 1393.0, memory_length 2000, epsilon 2.9981506421247587e-07 total_time 725.0\n",
      "episode 3005, reward 857.0, memory_length 2000, epsilon 2.9831973034136864e-07 total_time 724.0\n",
      "episode 3006, reward 1094.0, memory_length 2000, epsilon 2.968318544790575e-07 total_time 721.0\n",
      "episode 3007, reward 1269.0, memory_length 2000, epsilon 2.953513994285687e-07 total_time 726.0\n",
      "episode 3008, reward 1905.0, memory_length 2000, epsilon 2.9387832817844814e-07 total_time 724.0\n",
      "episode 3009, reward 910.0, memory_length 2000, epsilon 2.9241260390183865e-07 total_time 726.0\n",
      "episode 3010, reward 638.0, memory_length 2000, epsilon 2.909541899555561e-07 total_time 721.0\n",
      "Saving Model 3010\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3011, reward 914.0, memory_length 2000, epsilon 2.895030498791768e-07 total_time 723.0\n",
      "episode 3012, reward 1153.0, memory_length 2000, epsilon 2.8805914739412224e-07 total_time 721.0\n",
      "episode 3013, reward 1525.0, memory_length 2000, epsilon 2.866224464027561e-07 total_time 722.0\n",
      "episode 3014, reward 1020.0, memory_length 2000, epsilon 2.8519291098747784e-07 total_time 732.0\n",
      "episode 3015, reward 658.0, memory_length 2000, epsilon 2.837705054098281e-07 total_time 727.0\n",
      "episode 3016, reward 999.0, memory_length 2000, epsilon 2.823551941095938e-07 total_time 725.0\n",
      "episode 3017, reward 1243.0, memory_length 2000, epsilon 2.8094694170391774e-07 total_time 723.0\n",
      "episode 3018, reward 837.0, memory_length 2000, epsilon 2.7954571298641745e-07 total_time 731.0\n",
      "episode 3019, reward 998.0, memory_length 2000, epsilon 2.78151472926301e-07 total_time 727.0\n",
      "episode 3020, reward 1050.0, memory_length 2000, epsilon 2.767641866674953e-07 total_time 724.0\n",
      "Saving Model 3020\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3021, reward 959.0, memory_length 2000, epsilon 2.753838195277706e-07 total_time 721.0\n",
      "episode 3022, reward 939.0, memory_length 2000, epsilon 2.740103369978775e-07 total_time 727.0\n",
      "episode 3023, reward 908.0, memory_length 2000, epsilon 2.7264370474068026e-07 total_time 721.0\n",
      "episode 3024, reward 1383.0, memory_length 2000, epsilon 2.712838885903017e-07 total_time 725.0\n",
      "episode 3025, reward 686.0, memory_length 2000, epsilon 2.699308545512678e-07 total_time 727.0\n",
      "episode 3026, reward 1187.0, memory_length 2000, epsilon 2.685845687976561e-07 total_time 723.0\n",
      "episode 3027, reward 930.0, memory_length 2000, epsilon 2.672449976722536e-07 total_time 721.0\n",
      "episode 3028, reward 923.0, memory_length 2000, epsilon 2.659121076857115e-07 total_time 725.0\n",
      "episode 3029, reward 596.0, memory_length 2000, epsilon 2.6458586551571156e-07 total_time 728.0\n",
      "episode 3030, reward 1384.0, memory_length 2000, epsilon 2.6326623800612957e-07 total_time 731.0\n",
      "Saving Model 3030\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3031, reward 1275.0, memory_length 2000, epsilon 2.6195319216620954e-07 total_time 721.0\n",
      "episode 3032, reward 1285.0, memory_length 2000, epsilon 2.6064669516973754e-07 total_time 723.0\n",
      "episode 3033, reward 692.0, memory_length 2000, epsilon 2.593467143542197e-07 total_time 727.0\n",
      "episode 3034, reward 719.0, memory_length 2000, epsilon 2.5805321722006883e-07 total_time 722.0\n",
      "episode 3035, reward 788.0, memory_length 2000, epsilon 2.5676617142978825e-07 total_time 722.0\n",
      "episode 3036, reward 886.0, memory_length 2000, epsilon 2.5548554480716713e-07 total_time 722.0\n",
      "episode 3037, reward 1082.0, memory_length 2000, epsilon 2.542113053364723e-07 total_time 721.0\n",
      "episode 3038, reward 889.0, memory_length 2000, epsilon 2.529434211616515e-07 total_time 723.0\n",
      "episode 3039, reward 1151.0, memory_length 2000, epsilon 2.5168186058553345e-07 total_time 725.0\n",
      "episode 3040, reward 995.0, memory_length 2000, epsilon 2.5042659206903845e-07 total_time 725.0\n",
      "Saving Model 3040\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3041, reward 972.0, memory_length 2000, epsilon 2.491775842303887e-07 total_time 724.0\n",
      "episode 3042, reward 1197.0, memory_length 2000, epsilon 2.479348058443223e-07 total_time 725.0\n",
      "episode 3043, reward 926.0, memory_length 2000, epsilon 2.466982258413157e-07 total_time 722.0\n",
      "episode 3044, reward 502.0, memory_length 2000, epsilon 2.4546781330680364e-07 total_time 723.0\n",
      "episode 3045, reward 949.0, memory_length 2000, epsilon 2.442435374804094e-07 total_time 724.0\n",
      "episode 3046, reward 638.0, memory_length 2000, epsilon 2.4302536775517276e-07 total_time 723.0\n",
      "episode 3047, reward 471.0, memory_length 2000, epsilon 2.4181327367678804e-07 total_time 729.0\n",
      "episode 3048, reward 803.0, memory_length 2000, epsilon 2.406072249428393e-07 total_time 724.0\n",
      "episode 3049, reward 1372.0, memory_length 2000, epsilon 2.394071914020457e-07 total_time 721.0\n",
      "episode 3050, reward 1067.0, memory_length 2000, epsilon 2.3821314305350679e-07 total_time 726.0\n",
      "Saving Model 3050\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3051, reward 736.0, memory_length 2000, epsilon 2.3702505004595068e-07 total_time 731.0\n",
      "episode 3052, reward 919.0, memory_length 2000, epsilon 2.3584288267699124e-07 total_time 726.0\n",
      "episode 3053, reward 1335.0, memory_length 2000, epsilon 2.3466661139238175e-07 total_time 728.0\n",
      "episode 3054, reward 1102.0, memory_length 2000, epsilon 2.3349620678527974e-07 total_time 722.0\n",
      "episode 3055, reward 1422.0, memory_length 2000, epsilon 2.3233163959550821e-07 total_time 726.0\n",
      "episode 3056, reward 969.0, memory_length 2000, epsilon 2.311728807088272e-07 total_time 728.0\n",
      "episode 3057, reward 1345.0, memory_length 2000, epsilon 2.300199011562046e-07 total_time 722.0\n",
      "episode 3058, reward 1197.0, memory_length 2000, epsilon 2.288726721130907e-07 total_time 725.0\n",
      "episode 3059, reward 1211.0, memory_length 2000, epsilon 2.2773116489870048e-07 total_time 721.0\n",
      "episode 3060, reward 636.0, memory_length 2000, epsilon 2.2659535097529335e-07 total_time 722.0\n",
      "Saving Model 3060\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3061, reward 754.0, memory_length 2000, epsilon 2.2546520194746284e-07 total_time 736.0\n",
      "episode 3062, reward 877.0, memory_length 2000, epsilon 2.2434068956142362e-07 total_time 723.0\n",
      "episode 3063, reward 739.0, memory_length 2000, epsilon 2.2322178570430824e-07 total_time 727.0\n",
      "episode 3064, reward 869.0, memory_length 2000, epsilon 2.2210846240346122e-07 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3065, reward 1382.0, memory_length 2000, epsilon 2.2100069182574243e-07 total_time 732.0\n",
      "episode 3066, reward 1174.0, memory_length 2000, epsilon 2.1989844627683017e-07 total_time 735.0\n",
      "episode 3067, reward 1002.0, memory_length 2000, epsilon 2.1880169820052747e-07 total_time 722.0\n",
      "episode 3068, reward 478.0, memory_length 2000, epsilon 2.1771042017807613e-07 total_time 725.0\n",
      "episode 3069, reward 1015.0, memory_length 2000, epsilon 2.166245849274679e-07 total_time 738.0\n",
      "episode 3070, reward 1094.0, memory_length 2000, epsilon 2.1554416530276584e-07 total_time 727.0\n",
      "Saving Model 3070\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3071, reward 872.0, memory_length 2000, epsilon 2.144691342934222e-07 total_time 723.0\n",
      "episode 3072, reward 985.0, memory_length 2000, epsilon 2.1339946502360655e-07 total_time 722.0\n",
      "episode 3073, reward 1348.0, memory_length 2000, epsilon 2.123351307515307e-07 total_time 733.0\n",
      "episode 3074, reward 1758.0, memory_length 2000, epsilon 2.1127610486878274e-07 total_time 727.0\n",
      "episode 3075, reward 350.0, memory_length 2000, epsilon 2.1022236089966085e-07 total_time 729.0\n",
      "episode 3076, reward 891.0, memory_length 2000, epsilon 2.0917387250051018e-07 total_time 722.0\n",
      "episode 3077, reward 1105.0, memory_length 2000, epsilon 2.0813061345906687e-07 total_time 729.0\n",
      "episode 3078, reward 1108.0, memory_length 2000, epsilon 2.070925576937998e-07 total_time 730.0\n",
      "episode 3079, reward 701.0, memory_length 2000, epsilon 2.060596792532616e-07 total_time 721.0\n",
      "episode 3080, reward 1048.0, memory_length 2000, epsilon 2.0503195231543654e-07 total_time 727.0\n",
      "Saving Model 3080\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3081, reward 1285.0, memory_length 2000, epsilon 2.0400935118709818e-07 total_time 734.0\n",
      "episode 3082, reward 894.0, memory_length 2000, epsilon 2.0299185030316535e-07 total_time 721.0\n",
      "episode 3083, reward 1498.0, memory_length 2000, epsilon 2.0197942422606226e-07 total_time 728.0\n",
      "episode 3084, reward 891.0, memory_length 2000, epsilon 2.0097204764508493e-07 total_time 726.0\n",
      "episode 3085, reward 816.0, memory_length 2000, epsilon 1.9996969537576567e-07 total_time 723.0\n",
      "episode 3086, reward 689.0, memory_length 2000, epsilon 1.9897234235924625e-07 total_time 723.0\n",
      "episode 3087, reward 1667.0, memory_length 2000, epsilon 1.9797996366164862e-07 total_time 728.0\n",
      "episode 3088, reward 1013.0, memory_length 2000, epsilon 1.9699253447345433e-07 total_time 734.0\n",
      "episode 3089, reward 709.0, memory_length 2000, epsilon 1.9601003010888158e-07 total_time 725.0\n",
      "episode 3090, reward 1340.0, memory_length 2000, epsilon 1.9503242600527043e-07 total_time 722.0\n",
      "Saving Model 3090\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3091, reward 585.0, memory_length 2000, epsilon 1.940596977224677e-07 total_time 725.0\n",
      "episode 3092, reward 1103.0, memory_length 2000, epsilon 1.9309182094221494e-07 total_time 724.0\n",
      "episode 3093, reward 982.0, memory_length 2000, epsilon 1.9212877146754297e-07 total_time 724.0\n",
      "episode 3094, reward 747.0, memory_length 2000, epsilon 1.9117052522216407e-07 total_time 727.0\n",
      "episode 3095, reward 1101.0, memory_length 2000, epsilon 1.9021705824987285e-07 total_time 725.0\n",
      "episode 3096, reward 837.0, memory_length 2000, epsilon 1.892683467139447e-07 total_time 724.0\n",
      "episode 3097, reward 1021.0, memory_length 2000, epsilon 1.8832436689654217e-07 total_time 722.0\n",
      "episode 3098, reward 1351.0, memory_length 2000, epsilon 1.8738509519812088e-07 total_time 722.0\n",
      "episode 3099, reward 1177.0, memory_length 2000, epsilon 1.8645050813683894e-07 total_time 724.0\n",
      "episode 3100, reward 960.0, memory_length 2000, epsilon 1.8552058234797167e-07 total_time 722.0\n",
      "Saving Model 3100\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3101, reward 1437.0, memory_length 2000, epsilon 1.845952945833253e-07 total_time 722.0\n",
      "episode 3102, reward 890.0, memory_length 2000, epsilon 1.8367462171065822e-07 total_time 727.0\n",
      "episode 3103, reward 460.0, memory_length 2000, epsilon 1.8275854071309997e-07 total_time 724.0\n",
      "episode 3104, reward 962.0, memory_length 2000, epsilon 1.8184702868857857e-07 total_time 725.0\n",
      "episode 3105, reward 1426.0, memory_length 2000, epsilon 1.8094006284924523e-07 total_time 721.0\n",
      "episode 3106, reward 1264.0, memory_length 2000, epsilon 1.8003762052090712e-07 total_time 729.0\n",
      "episode 3107, reward 754.0, memory_length 2000, epsilon 1.791396791424593e-07 total_time 721.0\n",
      "episode 3108, reward 669.0, memory_length 2000, epsilon 1.7824621626531992e-07 total_time 727.0\n",
      "episode 3109, reward 1273.0, memory_length 2000, epsilon 1.7735720955287117e-07 total_time 722.0\n",
      "episode 3110, reward 830.0, memory_length 2000, epsilon 1.7647263677989828e-07 total_time 728.0\n",
      "Saving Model 3110\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3111, reward 1150.0, memory_length 2000, epsilon 1.755924758320365e-07 total_time 725.0\n",
      "episode 3112, reward 1295.0, memory_length 2000, epsilon 1.7471670470521565e-07 total_time 722.0\n",
      "episode 3113, reward 1491.0, memory_length 2000, epsilon 1.7384530150511257e-07 total_time 727.0\n",
      "episode 3114, reward 1013.0, memory_length 2000, epsilon 1.7297824444660129e-07 total_time 726.0\n",
      "episode 3115, reward 1259.0, memory_length 2000, epsilon 1.7211551185321044e-07 total_time 724.0\n",
      "episode 3116, reward 560.0, memory_length 2000, epsilon 1.712570821565806e-07 total_time 729.0\n",
      "episode 3117, reward 1087.0, memory_length 2000, epsilon 1.70402933895924e-07 total_time 726.0\n",
      "episode 3118, reward 1022.0, memory_length 2000, epsilon 1.6955304571749026e-07 total_time 723.0\n",
      "episode 3119, reward 1682.0, memory_length 2000, epsilon 1.6870739637403004e-07 total_time 726.0\n",
      "episode 3120, reward 773.0, memory_length 2000, epsilon 1.6786596472426635e-07 total_time 723.0\n",
      "Saving Model 3120\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3121, reward 818.0, memory_length 2000, epsilon 1.670287297323635e-07 total_time 723.0\n",
      "episode 3122, reward 1020.0, memory_length 2000, epsilon 1.6619567046740335e-07 total_time 727.0\n",
      "episode 3123, reward 443.0, memory_length 2000, epsilon 1.6536676610286122e-07 total_time 721.0\n",
      "episode 3124, reward 1336.0, memory_length 2000, epsilon 1.6454199591608426e-07 total_time 729.0\n",
      "episode 3125, reward 699.0, memory_length 2000, epsilon 1.6372133928777537e-07 total_time 730.0\n",
      "episode 3126, reward 663.0, memory_length 2000, epsilon 1.6290477570147552e-07 total_time 721.0\n",
      "episode 3127, reward 999.0, memory_length 2000, epsilon 1.6209228474305316e-07 total_time 725.0\n",
      "episode 3128, reward 925.0, memory_length 2000, epsilon 1.6128384610019143e-07 total_time 726.0\n",
      "episode 3129, reward 633.0, memory_length 2000, epsilon 1.6047943956188264e-07 total_time 722.0\n",
      "episode 3130, reward 1612.0, memory_length 2000, epsilon 1.5967904501792093e-07 total_time 721.0\n",
      "Saving Model 3130\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3131, reward 923.0, memory_length 2000, epsilon 1.5888264245840132e-07 total_time 725.0\n",
      "episode 3132, reward 1108.0, memory_length 2000, epsilon 1.5809021197321857e-07 total_time 726.0\n",
      "episode 3133, reward 1182.0, memory_length 2000, epsilon 1.5730173375156876e-07 total_time 728.0\n",
      "episode 3134, reward 799.0, memory_length 2000, epsilon 1.5651718808145582e-07 total_time 724.0\n",
      "episode 3135, reward 949.0, memory_length 2000, epsilon 1.557365553491966e-07 total_time 723.0\n",
      "episode 3136, reward 794.0, memory_length 2000, epsilon 1.5495981603893265e-07 total_time 721.0\n",
      "episode 3137, reward 671.0, memory_length 2000, epsilon 1.5418695073214021e-07 total_time 725.0\n",
      "episode 3138, reward 859.0, memory_length 2000, epsilon 1.5341794010714694e-07 total_time 722.0\n",
      "episode 3139, reward 825.0, memory_length 2000, epsilon 1.526527649386466e-07 total_time 724.0\n",
      "episode 3140, reward 994.0, memory_length 2000, epsilon 1.5189140609722044e-07 total_time 739.0\n",
      "Saving Model 3140\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3141, reward 829.0, memory_length 2000, epsilon 1.5113384454885795e-07 total_time 723.0\n",
      "episode 3142, reward 1456.0, memory_length 2000, epsilon 1.503800613544805e-07 total_time 727.0\n",
      "episode 3143, reward 902.0, memory_length 2000, epsilon 1.4963003766946946e-07 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3144, reward 1691.0, memory_length 2000, epsilon 1.4888375474319312e-07 total_time 725.0\n",
      "episode 3145, reward 673.0, memory_length 2000, epsilon 1.4814119391854004e-07 total_time 722.0\n",
      "episode 3146, reward 1084.0, memory_length 2000, epsilon 1.474023366314503e-07 total_time 725.0\n",
      "episode 3147, reward 1026.0, memory_length 2000, epsilon 1.466671644104536e-07 total_time 727.0\n",
      "episode 3148, reward 1235.0, memory_length 2000, epsilon 1.459356588762063e-07 total_time 723.0\n",
      "episode 3149, reward 1011.0, memory_length 2000, epsilon 1.452078017410315e-07 total_time 722.0\n",
      "episode 3150, reward 1198.0, memory_length 2000, epsilon 1.4448357480846338e-07 total_time 729.0\n",
      "Saving Model 3150\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3151, reward 1367.0, memory_length 2000, epsilon 1.4376295997279042e-07 total_time 721.0\n",
      "episode 3152, reward 1395.0, memory_length 2000, epsilon 1.4304593921860468e-07 total_time 723.0\n",
      "episode 3153, reward 1026.0, memory_length 2000, epsilon 1.423324946203495e-07 total_time 726.0\n",
      "episode 3154, reward 670.0, memory_length 2000, epsilon 1.416226083418732e-07 total_time 726.0\n",
      "episode 3155, reward 642.0, memory_length 2000, epsilon 1.409162626359814e-07 total_time 726.0\n",
      "episode 3156, reward 1385.0, memory_length 2000, epsilon 1.402134398439949e-07 total_time 721.0\n",
      "episode 3157, reward 1257.0, memory_length 2000, epsilon 1.395141223953075e-07 total_time 725.0\n",
      "episode 3158, reward 1235.0, memory_length 2000, epsilon 1.3881829280694613e-07 total_time 731.0\n",
      "episode 3159, reward 1011.0, memory_length 2000, epsilon 1.3812593368313533e-07 total_time 721.0\n",
      "episode 3160, reward 1011.0, memory_length 2000, epsilon 1.374370277148604e-07 total_time 725.0\n",
      "Saving Model 3160\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3161, reward 685.0, memory_length 2000, epsilon 1.3675155767943677e-07 total_time 721.0\n",
      "episode 3162, reward 980.0, memory_length 2000, epsilon 1.3606950644007735e-07 total_time 730.0\n",
      "episode 3163, reward 535.0, memory_length 2000, epsilon 1.3539085694546615e-07 total_time 730.0\n",
      "episode 3164, reward 684.0, memory_length 2000, epsilon 1.3471559222932996e-07 total_time 724.0\n",
      "episode 3165, reward 945.0, memory_length 2000, epsilon 1.3404369541001597e-07 total_time 731.0\n",
      "episode 3166, reward 1205.0, memory_length 2000, epsilon 1.333751496900689e-07 total_time 727.0\n",
      "episode 3167, reward 1062.0, memory_length 2000, epsilon 1.3270993835581045e-07 total_time 722.0\n",
      "episode 3168, reward 815.0, memory_length 2000, epsilon 1.3204804477692312e-07 total_time 725.0\n",
      "episode 3169, reward 1031.0, memory_length 2000, epsilon 1.313894524060325e-07 total_time 723.0\n",
      "episode 3170, reward 1130.0, memory_length 2000, epsilon 1.3073414477829546e-07 total_time 721.0\n",
      "Saving Model 3170\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3171, reward 1104.0, memory_length 2000, epsilon 1.3008210551098673e-07 total_time 725.0\n",
      "episode 3172, reward 398.0, memory_length 2000, epsilon 1.294333183030909e-07 total_time 723.0\n",
      "episode 3173, reward 1402.0, memory_length 2000, epsilon 1.287877669348942e-07 total_time 733.0\n",
      "episode 3174, reward 1165.0, memory_length 2000, epsilon 1.281454352675783e-07 total_time 723.0\n",
      "episode 3175, reward 1104.0, memory_length 2000, epsilon 1.275063072428186e-07 total_time 723.0\n",
      "episode 3176, reward 1242.0, memory_length 2000, epsilon 1.2687036688238072e-07 total_time 733.0\n",
      "episode 3177, reward 915.0, memory_length 2000, epsilon 1.2623759828772295e-07 total_time 724.0\n",
      "episode 3178, reward 911.0, memory_length 2000, epsilon 1.25607985639597e-07 total_time 721.0\n",
      "episode 3179, reward 1434.0, memory_length 2000, epsilon 1.2498151319765438e-07 total_time 725.0\n",
      "episode 3180, reward 807.0, memory_length 2000, epsilon 1.2435816530005094e-07 total_time 722.0\n",
      "Saving Model 3180\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3181, reward 940.0, memory_length 2000, epsilon 1.23737926363057e-07 total_time 728.0\n",
      "episode 3182, reward 941.0, memory_length 2000, epsilon 1.2312078088066701e-07 total_time 722.0\n",
      "episode 3183, reward 772.0, memory_length 2000, epsilon 1.225067134242114e-07 total_time 723.0\n",
      "episode 3184, reward 933.0, memory_length 2000, epsilon 1.2189570864197217e-07 total_time 732.0\n",
      "episode 3185, reward 1074.0, memory_length 2000, epsilon 1.212877512587975e-07 total_time 721.0\n",
      "episode 3186, reward 1087.0, memory_length 2000, epsilon 1.2068282607572157e-07 total_time 735.0\n",
      "episode 3187, reward 1273.0, memory_length 2000, epsilon 1.200809179695829e-07 total_time 725.0\n",
      "episode 3188, reward 802.0, memory_length 2000, epsilon 1.1948201189264795e-07 total_time 721.0\n",
      "episode 3189, reward 1079.0, memory_length 2000, epsilon 1.1888609287223309e-07 total_time 727.0\n",
      "episode 3190, reward 947.0, memory_length 2000, epsilon 1.1829314601033203e-07 total_time 724.0\n",
      "Saving Model 3190\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3191, reward 818.0, memory_length 2000, epsilon 1.1770315648324254e-07 total_time 725.0\n",
      "episode 3192, reward 559.0, memory_length 2000, epsilon 1.171161095411953e-07 total_time 723.0\n",
      "episode 3193, reward 932.0, memory_length 2000, epsilon 1.1653199050798663e-07 total_time 725.0\n",
      "episode 3194, reward 794.0, memory_length 2000, epsilon 1.159507847806098e-07 total_time 730.0\n",
      "episode 3195, reward 1125.0, memory_length 2000, epsilon 1.1537247782889181e-07 total_time 724.0\n",
      "episode 3196, reward 864.0, memory_length 2000, epsilon 1.1479705519512833e-07 total_time 727.0\n",
      "episode 3197, reward 1169.0, memory_length 2000, epsilon 1.1422450249372374e-07 total_time 721.0\n",
      "episode 3198, reward 950.0, memory_length 2000, epsilon 1.1365480541083089e-07 total_time 727.0\n",
      "episode 3199, reward 837.0, memory_length 2000, epsilon 1.1308794970399264e-07 total_time 730.0\n",
      "episode 3200, reward 982.0, memory_length 2000, epsilon 1.1252392120178719e-07 total_time 722.0\n",
      "Saving Model 3200\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3201, reward 647.0, memory_length 2000, epsilon 1.1196270580347242e-07 total_time 725.0\n",
      "episode 3202, reward 661.0, memory_length 2000, epsilon 1.1140428947863373e-07 total_time 725.0\n",
      "episode 3203, reward 725.0, memory_length 2000, epsilon 1.1084865826683471e-07 total_time 726.0\n",
      "episode 3204, reward 790.0, memory_length 2000, epsilon 1.1029579827726572e-07 total_time 731.0\n",
      "episode 3205, reward 1044.0, memory_length 2000, epsilon 1.0974569568839826e-07 total_time 732.0\n",
      "episode 3206, reward 982.0, memory_length 2000, epsilon 1.0919833674763854e-07 total_time 727.0\n",
      "episode 3207, reward 1110.0, memory_length 2000, epsilon 1.0865370777098532e-07 total_time 721.0\n",
      "episode 3208, reward 1306.0, memory_length 2000, epsilon 1.0811179514268542e-07 total_time 729.0\n",
      "episode 3209, reward 793.0, memory_length 2000, epsilon 1.0757258531489453e-07 total_time 724.0\n",
      "episode 3210, reward 1386.0, memory_length 2000, epsilon 1.0703606480733965e-07 total_time 724.0\n",
      "Saving Model 3210\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3211, reward 989.0, memory_length 2000, epsilon 1.0650222020697974e-07 total_time 726.0\n",
      "episode 3212, reward 1097.0, memory_length 2000, epsilon 1.0597103816767201e-07 total_time 723.0\n",
      "episode 3213, reward 619.0, memory_length 2000, epsilon 1.0544250540983741e-07 total_time 723.0\n",
      "episode 3214, reward 591.0, memory_length 2000, epsilon 1.0491660872013025e-07 total_time 723.0\n",
      "episode 3215, reward 547.0, memory_length 2000, epsilon 1.043933349511055e-07 total_time 721.0\n",
      "episode 3216, reward 1054.0, memory_length 2000, epsilon 1.0387267102089129e-07 total_time 726.0\n",
      "episode 3217, reward 1316.0, memory_length 2000, epsilon 1.0335460391286304e-07 total_time 721.0\n",
      "episode 3218, reward 936.0, memory_length 2000, epsilon 1.0283912067531568e-07 total_time 729.0\n",
      "episode 3219, reward 1379.0, memory_length 2000, epsilon 1.0232620842114137e-07 total_time 722.0\n",
      "episode 3220, reward 632.0, memory_length 2000, epsilon 1.0181585432750673e-07 total_time 721.0\n",
      "Saving Model 3220\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3221, reward 853.0, memory_length 2000, epsilon 1.0130804563553359e-07 total_time 723.0\n",
      "episode 3222, reward 1139.0, memory_length 2000, epsilon 1.0080276964997777e-07 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3223, reward 983.0, memory_length 2000, epsilon 1.0030001373891299e-07 total_time 724.0\n",
      "episode 3224, reward 839.0, memory_length 2000, epsilon 9.979976533341602e-08 total_time 730.0\n",
      "episode 3225, reward 1015.0, memory_length 2000, epsilon 9.930201192725029e-08 total_time 733.0\n",
      "episode 3226, reward 827.0, memory_length 2000, epsilon 9.880674107655471e-08 total_time 723.0\n",
      "episode 3227, reward 1273.0, memory_length 2000, epsilon 9.831394039953189e-08 total_time 721.0\n",
      "episode 3228, reward 1111.0, memory_length 2000, epsilon 9.782359757613994e-08 total_time 724.0\n",
      "episode 3229, reward 897.0, memory_length 2000, epsilon 9.733570034778236e-08 total_time 721.0\n",
      "episode 3230, reward 895.0, memory_length 2000, epsilon 9.685023651700304e-08 total_time 723.0\n",
      "Saving Model 3230\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3231, reward 1125.0, memory_length 2000, epsilon 9.636719394718061e-08 total_time 723.0\n",
      "episode 3232, reward 903.0, memory_length 2000, epsilon 9.588656056222632e-08 total_time 726.0\n",
      "episode 3233, reward 735.0, memory_length 2000, epsilon 9.540832434628019e-08 total_time 723.0\n",
      "episode 3234, reward 1784.0, memory_length 2000, epsilon 9.493247334341155e-08 total_time 723.0\n",
      "episode 3235, reward 1249.0, memory_length 2000, epsilon 9.445899565732125e-08 total_time 722.0\n",
      "episode 3236, reward 1055.0, memory_length 2000, epsilon 9.398787945104212e-08 total_time 730.0\n",
      "episode 3237, reward 1103.0, memory_length 2000, epsilon 9.351911294664447e-08 total_time 733.0\n",
      "episode 3238, reward 1064.0, memory_length 2000, epsilon 9.305268442494096e-08 total_time 723.0\n",
      "episode 3239, reward 1016.0, memory_length 2000, epsilon 9.25885822251949e-08 total_time 721.0\n",
      "episode 3240, reward 850.0, memory_length 2000, epsilon 9.212679474482678e-08 total_time 729.0\n",
      "Saving Model 3240\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3241, reward 1505.0, memory_length 2000, epsilon 9.166731043912524e-08 total_time 724.0\n",
      "episode 3242, reward 492.0, memory_length 2000, epsilon 9.121011782095934e-08 total_time 725.0\n",
      "episode 3243, reward 939.0, memory_length 2000, epsilon 9.07552054604895e-08 total_time 729.0\n",
      "episode 3244, reward 1118.0, memory_length 2000, epsilon 9.0302561984883e-08 total_time 722.0\n",
      "episode 3245, reward 1073.0, memory_length 2000, epsilon 8.985217607802908e-08 total_time 722.0\n",
      "episode 3246, reward 982.0, memory_length 2000, epsilon 8.940403648025722e-08 total_time 726.0\n",
      "episode 3247, reward 1062.0, memory_length 2000, epsilon 8.895813198805384e-08 total_time 728.0\n",
      "episode 3248, reward 762.0, memory_length 2000, epsilon 8.851445145378308e-08 total_time 726.0\n",
      "episode 3249, reward 1234.0, memory_length 2000, epsilon 8.80729837854091e-08 total_time 722.0\n",
      "episode 3250, reward 940.0, memory_length 2000, epsilon 8.763371794621691e-08 total_time 730.0\n",
      "Saving Model 3250\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3251, reward 1672.0, memory_length 2000, epsilon 8.719664295453765e-08 total_time 728.0\n",
      "episode 3252, reward 1200.0, memory_length 2000, epsilon 8.67617478834734e-08 total_time 723.0\n",
      "episode 3253, reward 816.0, memory_length 2000, epsilon 8.632902186062542e-08 total_time 724.0\n",
      "episode 3254, reward 861.0, memory_length 2000, epsilon 8.589845406782026e-08 total_time 721.0\n",
      "episode 3255, reward 873.0, memory_length 2000, epsilon 8.547003374084066e-08 total_time 732.0\n",
      "episode 3256, reward 1559.0, memory_length 2000, epsilon 8.504375016915586e-08 total_time 724.0\n",
      "episode 3257, reward 700.0, memory_length 2000, epsilon 8.461959269565495e-08 total_time 721.0\n",
      "episode 3258, reward 510.0, memory_length 2000, epsilon 8.419755071637872e-08 total_time 722.0\n",
      "episode 3259, reward 999.0, memory_length 2000, epsilon 8.377761368025537e-08 total_time 722.0\n",
      "episode 3260, reward 603.0, memory_length 2000, epsilon 8.335977108883775e-08 total_time 722.0\n",
      "Saving Model 3260\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3261, reward 832.0, memory_length 2000, epsilon 8.294401249603902e-08 total_time 723.0\n",
      "episode 3262, reward 923.0, memory_length 2000, epsilon 8.253032750787269e-08 total_time 731.0\n",
      "episode 3263, reward 871.0, memory_length 2000, epsilon 8.211870578219222e-08 total_time 721.0\n",
      "episode 3264, reward 722.0, memory_length 2000, epsilon 8.170913702843363e-08 total_time 722.0\n",
      "episode 3265, reward 722.0, memory_length 2000, epsilon 8.130161100735642e-08 total_time 728.0\n",
      "episode 3266, reward 710.0, memory_length 2000, epsilon 8.089611753078856e-08 total_time 724.0\n",
      "episode 3267, reward 794.0, memory_length 2000, epsilon 8.049264646137263e-08 total_time 731.0\n",
      "episode 3268, reward 562.0, memory_length 2000, epsilon 8.009118771231055e-08 total_time 722.0\n",
      "episode 3269, reward 645.0, memory_length 2000, epsilon 7.969173124711268e-08 total_time 728.0\n",
      "episode 3270, reward 1250.0, memory_length 2000, epsilon 7.929426707934634e-08 total_time 724.0\n",
      "Saving Model 3270\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3271, reward 1250.0, memory_length 2000, epsilon 7.889878527238717e-08 total_time 723.0\n",
      "episode 3272, reward 1348.0, memory_length 2000, epsilon 7.850527593916913e-08 total_time 727.0\n",
      "episode 3273, reward 688.0, memory_length 2000, epsilon 7.81137292419381e-08 total_time 721.0\n",
      "episode 3274, reward 908.0, memory_length 2000, epsilon 7.772413539200684e-08 total_time 726.0\n",
      "episode 3275, reward 1056.0, memory_length 2000, epsilon 7.733648464950851e-08 total_time 728.0\n",
      "episode 3276, reward 1060.0, memory_length 2000, epsilon 7.695076732315436e-08 total_time 729.0\n",
      "episode 3277, reward 563.0, memory_length 2000, epsilon 7.656697376999086e-08 total_time 724.0\n",
      "episode 3278, reward 1174.0, memory_length 2000, epsilon 7.618509439515977e-08 total_time 722.0\n",
      "episode 3279, reward 919.0, memory_length 2000, epsilon 7.580511965165652e-08 total_time 722.0\n",
      "episode 3280, reward 732.0, memory_length 2000, epsilon 7.542704004009273e-08 total_time 725.0\n",
      "Saving Model 3280\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3281, reward 967.0, memory_length 2000, epsilon 7.50508461084582e-08 total_time 722.0\n",
      "episode 3282, reward 1053.0, memory_length 2000, epsilon 7.467652845188555e-08 total_time 725.0\n",
      "episode 3283, reward 1145.0, memory_length 2000, epsilon 7.43040777124136e-08 total_time 729.0\n",
      "episode 3284, reward 952.0, memory_length 2000, epsilon 7.393348457875419e-08 total_time 725.0\n",
      "episode 3285, reward 948.0, memory_length 2000, epsilon 7.356473978606024e-08 total_time 722.0\n",
      "episode 3286, reward 717.0, memory_length 2000, epsilon 7.319783411569242e-08 total_time 725.0\n",
      "episode 3287, reward 818.0, memory_length 2000, epsilon 7.283275839498988e-08 total_time 726.0\n",
      "episode 3288, reward 512.0, memory_length 2000, epsilon 7.246950349704035e-08 total_time 721.0\n",
      "episode 3289, reward 1479.0, memory_length 2000, epsilon 7.210806034045295e-08 total_time 722.0\n",
      "episode 3290, reward 1011.0, memory_length 2000, epsilon 7.174841988912969e-08 total_time 721.0\n",
      "Saving Model 3290\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3291, reward 970.0, memory_length 2000, epsilon 7.13905731520403e-08 total_time 721.0\n",
      "episode 3292, reward 693.0, memory_length 2000, epsilon 7.103451118299824e-08 total_time 729.0\n",
      "episode 3293, reward 1181.0, memory_length 2000, epsilon 7.068022508043546e-08 total_time 731.0\n",
      "episode 3294, reward 1295.0, memory_length 2000, epsilon 7.032770598718096e-08 total_time 730.0\n",
      "episode 3295, reward 1396.0, memory_length 2000, epsilon 6.997694509023879e-08 total_time 727.0\n",
      "episode 3296, reward 653.0, memory_length 2000, epsilon 6.962793362056876e-08 total_time 730.0\n",
      "episode 3297, reward 1011.0, memory_length 2000, epsilon 6.928066285286572e-08 total_time 725.0\n",
      "episode 3298, reward 722.0, memory_length 2000, epsilon 6.893512410534211e-08 total_time 726.0\n",
      "episode 3299, reward 1118.0, memory_length 2000, epsilon 6.859130873951176e-08 total_time 721.0\n",
      "episode 3300, reward 1099.0, memory_length 2000, epsilon 6.824920815997237e-08 total_time 728.0\n",
      "Saving Model 3300\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3301, reward 1058.0, memory_length 2000, epsilon 6.790881381419161e-08 total_time 728.0\n",
      "episode 3302, reward 1143.0, memory_length 2000, epsilon 6.75701171922929e-08 total_time 727.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3303, reward 509.0, memory_length 2000, epsilon 6.72331098268435e-08 total_time 726.0\n",
      "episode 3304, reward 782.0, memory_length 2000, epsilon 6.689778329264152e-08 total_time 722.0\n",
      "episode 3305, reward 585.0, memory_length 2000, epsilon 6.656412920650611e-08 total_time 727.0\n",
      "episode 3306, reward 824.0, memory_length 2000, epsilon 6.62321392270675e-08 total_time 723.0\n",
      "episode 3307, reward 1040.0, memory_length 2000, epsilon 6.590180505455941e-08 total_time 731.0\n",
      "episode 3308, reward 1115.0, memory_length 2000, epsilon 6.557311843061006e-08 total_time 729.0\n",
      "episode 3309, reward 1380.0, memory_length 2000, epsilon 6.524607113803652e-08 total_time 725.0\n",
      "episode 3310, reward 822.0, memory_length 2000, epsilon 6.49206550006399e-08 total_time 724.0\n",
      "Saving Model 3310\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3311, reward 586.0, memory_length 2000, epsilon 6.459686188299957e-08 total_time 723.0\n",
      "episode 3312, reward 870.0, memory_length 2000, epsilon 6.427468369027076e-08 total_time 723.0\n",
      "episode 3313, reward 1275.0, memory_length 2000, epsilon 6.39541123679816e-08 total_time 730.0\n",
      "episode 3314, reward 1204.0, memory_length 2000, epsilon 6.363513990183283e-08 total_time 730.0\n",
      "episode 3315, reward 892.0, memory_length 2000, epsilon 6.331775831749593e-08 total_time 725.0\n",
      "episode 3316, reward 1804.0, memory_length 2000, epsilon 6.300195968041455e-08 total_time 724.0\n",
      "episode 3317, reward 1046.0, memory_length 2000, epsilon 6.268773609560675e-08 total_time 726.0\n",
      "episode 3318, reward 1041.0, memory_length 2000, epsilon 6.237507970746633e-08 total_time 730.0\n",
      "episode 3319, reward 1113.0, memory_length 2000, epsilon 6.206398269956731e-08 total_time 725.0\n",
      "episode 3320, reward 900.0, memory_length 2000, epsilon 6.175443729446805e-08 total_time 721.0\n",
      "Saving Model 3320\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3321, reward 988.0, memory_length 2000, epsilon 6.144643575351775e-08 total_time 724.0\n",
      "episode 3322, reward 810.0, memory_length 2000, epsilon 6.113997037666164e-08 total_time 723.0\n",
      "episode 3323, reward 632.0, memory_length 2000, epsilon 6.08350335022491e-08 total_time 724.0\n",
      "episode 3324, reward 1045.0, memory_length 2000, epsilon 6.053161750684283e-08 total_time 722.0\n",
      "episode 3325, reward 865.0, memory_length 2000, epsilon 6.02297148050269e-08 total_time 721.0\n",
      "episode 3326, reward 557.0, memory_length 2000, epsilon 5.992931784921807e-08 total_time 729.0\n",
      "episode 3327, reward 1195.0, memory_length 2000, epsilon 5.96304191294766e-08 total_time 727.0\n",
      "episode 3328, reward 1090.0, memory_length 2000, epsilon 5.933301117331932e-08 total_time 728.0\n",
      "episode 3329, reward 979.0, memory_length 2000, epsilon 5.903708654553164e-08 total_time 726.0\n",
      "episode 3330, reward 1022.0, memory_length 2000, epsilon 5.874263784798244e-08 total_time 729.0\n",
      "Saving Model 3330\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3331, reward 773.0, memory_length 2000, epsilon 5.8449657719438753e-08 total_time 721.0\n",
      "episode 3332, reward 1281.0, memory_length 2000, epsilon 5.8158138835382513e-08 total_time 729.0\n",
      "episode 3333, reward 1283.0, memory_length 2000, epsilon 5.786807390782623e-08 total_time 734.0\n",
      "episode 3334, reward 1266.0, memory_length 2000, epsilon 5.75794556851314e-08 total_time 724.0\n",
      "episode 3335, reward 1039.0, memory_length 2000, epsilon 5.729227695182784e-08 total_time 724.0\n",
      "episode 3336, reward 829.0, memory_length 2000, epsilon 5.7006530528432044e-08 total_time 725.0\n",
      "episode 3337, reward 1032.0, memory_length 2000, epsilon 5.6722209271268555e-08 total_time 723.0\n",
      "episode 3338, reward 628.0, memory_length 2000, epsilon 5.6439306072290925e-08 total_time 724.0\n",
      "episode 3339, reward 976.0, memory_length 2000, epsilon 5.6157813858904864e-08 total_time 722.0\n",
      "episode 3340, reward 1015.0, memory_length 2000, epsilon 5.587772559379016e-08 total_time 725.0\n",
      "Saving Model 3340\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3341, reward 940.0, memory_length 2000, epsilon 5.55990342747254e-08 total_time 725.0\n",
      "episode 3342, reward 597.0, memory_length 2000, epsilon 5.532173293441349e-08 total_time 721.0\n",
      "episode 3343, reward 1228.0, memory_length 2000, epsilon 5.504581464030629e-08 total_time 724.0\n",
      "episode 3344, reward 1192.0, memory_length 2000, epsilon 5.4771272494432066e-08 total_time 725.0\n",
      "episode 3345, reward 628.0, memory_length 2000, epsilon 5.449809963322267e-08 total_time 726.0\n",
      "episode 3346, reward 790.0, memory_length 2000, epsilon 5.422628922734276e-08 total_time 724.0\n",
      "episode 3347, reward 1168.0, memory_length 2000, epsilon 5.395583448151781e-08 total_time 721.0\n",
      "episode 3348, reward 1263.0, memory_length 2000, epsilon 5.368672863436492e-08 total_time 730.0\n",
      "episode 3349, reward 853.0, memory_length 2000, epsilon 5.341896495822426e-08 total_time 721.0\n",
      "episode 3350, reward 591.0, memory_length 2000, epsilon 5.315253675898979e-08 total_time 723.0\n",
      "Saving Model 3350\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3351, reward 1205.0, memory_length 2000, epsilon 5.288743737594267e-08 total_time 728.0\n",
      "episode 3352, reward 1074.0, memory_length 2000, epsilon 5.26236601815843e-08 total_time 726.0\n",
      "episode 3353, reward 820.0, memory_length 2000, epsilon 5.2361198581471494e-08 total_time 727.0\n",
      "episode 3354, reward 504.0, memory_length 2000, epsilon 5.210004601405036e-08 total_time 723.0\n",
      "episode 3355, reward 587.0, memory_length 2000, epsilon 5.1840195950493124e-08 total_time 734.0\n",
      "episode 3356, reward 1066.0, memory_length 2000, epsilon 5.158164189453448e-08 total_time 726.0\n",
      "episode 3357, reward 1361.0, memory_length 2000, epsilon 5.132437738230993e-08 total_time 735.0\n",
      "episode 3358, reward 1102.0, memory_length 2000, epsilon 5.106839598219309e-08 total_time 722.0\n",
      "episode 3359, reward 1561.0, memory_length 2000, epsilon 5.081369129463543e-08 total_time 726.0\n",
      "episode 3360, reward 974.0, memory_length 2000, epsilon 5.0560256952006865e-08 total_time 724.0\n",
      "Saving Model 3360\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3361, reward 948.0, memory_length 2000, epsilon 5.0308086618435454e-08 total_time 729.0\n",
      "episode 3362, reward 1074.0, memory_length 2000, epsilon 5.005717398964972e-08 total_time 722.0\n",
      "episode 3363, reward 893.0, memory_length 2000, epsilon 4.980751279282069e-08 total_time 730.0\n",
      "episode 3364, reward 695.0, memory_length 2000, epsilon 4.955909678640581e-08 total_time 725.0\n",
      "episode 3365, reward 545.0, memory_length 2000, epsilon 4.931191975999179e-08 total_time 723.0\n",
      "episode 3366, reward 752.0, memory_length 2000, epsilon 4.906597553413992e-08 total_time 726.0\n",
      "episode 3367, reward 808.0, memory_length 2000, epsilon 4.882125796023211e-08 total_time 722.0\n",
      "episode 3368, reward 1083.0, memory_length 2000, epsilon 4.857776092031607e-08 total_time 724.0\n",
      "episode 3369, reward 1284.0, memory_length 2000, epsilon 4.833547832695314e-08 total_time 722.0\n",
      "episode 3370, reward 1437.0, memory_length 2000, epsilon 4.8094404123065685e-08 total_time 721.0\n",
      "Saving Model 3370\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3371, reward 1108.0, memory_length 2000, epsilon 4.78545322817864e-08 total_time 724.0\n",
      "episode 3372, reward 1040.0, memory_length 2000, epsilon 4.761585680630658e-08 total_time 726.0\n",
      "episode 3373, reward 520.0, memory_length 2000, epsilon 4.737837172972675e-08 total_time 721.0\n",
      "episode 3374, reward 1428.0, memory_length 2000, epsilon 4.7142071114907946e-08 total_time 723.0\n",
      "episode 3375, reward 510.0, memory_length 2000, epsilon 4.6906949054322345e-08 total_time 729.0\n",
      "episode 3376, reward 894.0, memory_length 2000, epsilon 4.667299966990617e-08 total_time 727.0\n",
      "episode 3377, reward 1358.0, memory_length 2000, epsilon 4.644021711291246e-08 total_time 723.0\n",
      "episode 3378, reward 1061.0, memory_length 2000, epsilon 4.62085955637655e-08 total_time 729.0\n",
      "episode 3379, reward 1928.0, memory_length 2000, epsilon 4.5978129231914333e-08 total_time 729.0\n",
      "episode 3380, reward 765.0, memory_length 2000, epsilon 4.574881235568867e-08 total_time 725.0\n",
      "Saving Model 3380\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3381, reward 801.0, memory_length 2000, epsilon 4.5520639202154486e-08 total_time 724.0\n",
      "episode 3382, reward 980.0, memory_length 2000, epsilon 4.529360406697138e-08 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3383, reward 856.0, memory_length 2000, epsilon 4.5067701274249e-08 total_time 721.0\n",
      "episode 3384, reward 1387.0, memory_length 2000, epsilon 4.484292517640559e-08 total_time 728.0\n",
      "episode 3385, reward 1076.0, memory_length 2000, epsilon 4.4619270154027314e-08 total_time 721.0\n",
      "episode 3386, reward 1222.0, memory_length 2000, epsilon 4.439673061572682e-08 total_time 726.0\n",
      "episode 3387, reward 1544.0, memory_length 2000, epsilon 4.4175300998004056e-08 total_time 727.0\n",
      "episode 3388, reward 781.0, memory_length 2000, epsilon 4.3954975765106876e-08 total_time 725.0\n",
      "episode 3389, reward 605.0, memory_length 2000, epsilon 4.37357494088933e-08 total_time 721.0\n",
      "episode 3390, reward 743.0, memory_length 2000, epsilon 4.351761644869286e-08 total_time 723.0\n",
      "Saving Model 3390\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3391, reward 920.0, memory_length 2000, epsilon 4.3300571431170016e-08 total_time 722.0\n",
      "episode 3392, reward 964.0, memory_length 2000, epsilon 4.3084608930188355e-08 total_time 723.0\n",
      "episode 3393, reward 1315.0, memory_length 2000, epsilon 4.286972354667394e-08 total_time 730.0\n",
      "episode 3394, reward 1260.0, memory_length 2000, epsilon 4.265590990848099e-08 total_time 727.0\n",
      "episode 3395, reward 1207.0, memory_length 2000, epsilon 4.244316267025726e-08 total_time 731.0\n",
      "episode 3396, reward 1072.0, memory_length 2000, epsilon 4.223147651331103e-08 total_time 723.0\n",
      "episode 3397, reward 1093.0, memory_length 2000, epsilon 4.202084614547718e-08 total_time 733.0\n",
      "episode 3398, reward 877.0, memory_length 2000, epsilon 4.181126630098541e-08 total_time 724.0\n",
      "episode 3399, reward 1031.0, memory_length 2000, epsilon 4.160273174032899e-08 total_time 723.0\n",
      "episode 3400, reward 951.0, memory_length 2000, epsilon 4.1395237250132886e-08 total_time 726.0\n",
      "Saving Model 3400\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3401, reward 754.0, memory_length 2000, epsilon 4.118877764302403e-08 total_time 728.0\n",
      "episode 3402, reward 1173.0, memory_length 2000, epsilon 4.0983347757501365e-08 total_time 728.0\n",
      "episode 3403, reward 1279.0, memory_length 2000, epsilon 4.077894245780733e-08 total_time 726.0\n",
      "episode 3404, reward 963.0, memory_length 2000, epsilon 4.0575556633798646e-08 total_time 729.0\n",
      "episode 3405, reward 1417.0, memory_length 2000, epsilon 4.037318520081912e-08 total_time 721.0\n",
      "episode 3406, reward 1203.0, memory_length 2000, epsilon 4.0171823099572234e-08 total_time 725.0\n",
      "episode 3407, reward 991.0, memory_length 2000, epsilon 3.997146529599528e-08 total_time 730.0\n",
      "episode 3408, reward 1080.0, memory_length 2000, epsilon 3.977210678113257e-08 total_time 721.0\n",
      "episode 3409, reward 776.0, memory_length 2000, epsilon 3.95737425710107e-08 total_time 729.0\n",
      "episode 3410, reward 926.0, memory_length 2000, epsilon 3.937636770651439e-08 total_time 723.0\n",
      "Saving Model 3410\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3411, reward 1219.0, memory_length 2000, epsilon 3.91799772532616e-08 total_time 730.0\n",
      "episode 3412, reward 829.0, memory_length 2000, epsilon 3.898456630148076e-08 total_time 727.0\n",
      "episode 3413, reward 1458.0, memory_length 2000, epsilon 3.8790129965887773e-08 total_time 728.0\n",
      "episode 3414, reward 900.0, memory_length 2000, epsilon 3.859666338556439e-08 total_time 726.0\n",
      "episode 3415, reward 1150.0, memory_length 2000, epsilon 3.840416172383588e-08 total_time 722.0\n",
      "episode 3416, reward 314.0, memory_length 2000, epsilon 3.821262016815056e-08 total_time 728.0\n",
      "episode 3417, reward 1207.0, memory_length 2000, epsilon 3.8022033929959824e-08 total_time 725.0\n",
      "episode 3418, reward 900.0, memory_length 2000, epsilon 3.783239824459765e-08 total_time 721.0\n",
      "episode 3419, reward 733.0, memory_length 2000, epsilon 3.7643708371162025e-08 total_time 721.0\n",
      "episode 3420, reward 870.0, memory_length 2000, epsilon 3.7455959592396154e-08 total_time 728.0\n",
      "Saving Model 3420\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3421, reward 463.0, memory_length 2000, epsilon 3.726914721457107e-08 total_time 726.0\n",
      "episode 3422, reward 1027.0, memory_length 2000, epsilon 3.708326656736745e-08 total_time 726.0\n",
      "episode 3423, reward 887.0, memory_length 2000, epsilon 3.68983130037593e-08 total_time 731.0\n",
      "episode 3424, reward 738.0, memory_length 2000, epsilon 3.671428189989817e-08 total_time 723.0\n",
      "episode 3425, reward 1070.0, memory_length 2000, epsilon 3.653116865499673e-08 total_time 721.0\n",
      "episode 3426, reward 1689.0, memory_length 2000, epsilon 3.634896869121434e-08 total_time 728.0\n",
      "episode 3427, reward 1114.0, memory_length 2000, epsilon 3.616767745354228e-08 total_time 721.0\n",
      "episode 3428, reward 953.0, memory_length 2000, epsilon 3.598729040969042e-08 total_time 734.0\n",
      "episode 3429, reward 1136.0, memory_length 2000, epsilon 3.5807803049973136e-08 total_time 730.0\n",
      "episode 3430, reward 1017.0, memory_length 2000, epsilon 3.5629210887196975e-08 total_time 735.0\n",
      "Saving Model 3430\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3431, reward 837.0, memory_length 2000, epsilon 3.5451509456548804e-08 total_time 729.0\n",
      "episode 3432, reward 1329.0, memory_length 2000, epsilon 3.527469431548348e-08 total_time 727.0\n",
      "episode 3433, reward 1074.0, memory_length 2000, epsilon 3.509876104361327e-08 total_time 725.0\n",
      "episode 3434, reward 894.0, memory_length 2000, epsilon 3.492370524259709e-08 total_time 721.0\n",
      "episode 3435, reward 851.0, memory_length 2000, epsilon 3.474952253603104e-08 total_time 722.0\n",
      "episode 3436, reward 682.0, memory_length 2000, epsilon 3.457620856933826e-08 total_time 721.0\n",
      "episode 3437, reward 1439.0, memory_length 2000, epsilon 3.440375900966057e-08 total_time 727.0\n",
      "episode 3438, reward 1175.0, memory_length 2000, epsilon 3.4232169545749855e-08 total_time 727.0\n",
      "episode 3439, reward 1166.0, memory_length 2000, epsilon 3.4061435887860835e-08 total_time 726.0\n",
      "episode 3440, reward 1051.0, memory_length 2000, epsilon 3.389155376764305e-08 total_time 722.0\n",
      "Saving Model 3440\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3441, reward 775.0, memory_length 2000, epsilon 3.3722518938034516e-08 total_time 723.0\n",
      "episode 3442, reward 1181.0, memory_length 2000, epsilon 3.355432717315594e-08 total_time 721.0\n",
      "episode 3443, reward 1782.0, memory_length 2000, epsilon 3.338697426820431e-08 total_time 725.0\n",
      "episode 3444, reward 835.0, memory_length 2000, epsilon 3.3220456039348296e-08 total_time 721.0\n",
      "episode 3445, reward 1524.0, memory_length 2000, epsilon 3.3054768323623376e-08 total_time 731.0\n",
      "episode 3446, reward 1268.0, memory_length 2000, epsilon 3.288990697882827e-08 total_time 725.0\n",
      "episode 3447, reward 1172.0, memory_length 2000, epsilon 3.2725867883420654e-08 total_time 726.0\n",
      "episode 3448, reward 1079.0, memory_length 2000, epsilon 3.256264693641448e-08 total_time 723.0\n",
      "episode 3449, reward 858.0, memory_length 2000, epsilon 3.2400240057277807e-08 total_time 722.0\n",
      "episode 3450, reward 991.0, memory_length 2000, epsilon 3.223864318583008e-08 total_time 722.0\n",
      "Saving Model 3450\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3451, reward 1068.0, memory_length 2000, epsilon 3.2077852282141087e-08 total_time 721.0\n",
      "episode 3452, reward 1109.0, memory_length 2000, epsilon 3.191786332642977e-08 total_time 723.0\n",
      "episode 3453, reward 1069.0, memory_length 2000, epsilon 3.175867231896411e-08 total_time 722.0\n",
      "episode 3454, reward 1272.0, memory_length 2000, epsilon 3.160027527996052e-08 total_time 731.0\n",
      "episode 3455, reward 1037.0, memory_length 2000, epsilon 3.144266824948467e-08 total_time 726.0\n",
      "episode 3456, reward 854.0, memory_length 2000, epsilon 3.128584728735281e-08 total_time 722.0\n",
      "episode 3457, reward 820.0, memory_length 2000, epsilon 3.1129808473032603e-08 total_time 723.0\n",
      "episode 3458, reward 538.0, memory_length 2000, epsilon 3.0974547905545575e-08 total_time 729.0\n",
      "episode 3459, reward 1120.0, memory_length 2000, epsilon 3.082006170336933e-08 total_time 725.0\n",
      "episode 3460, reward 1320.0, memory_length 2000, epsilon 3.066634600434099e-08 total_time 722.0\n",
      "Saving Model 3460\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3461, reward 998.0, memory_length 2000, epsilon 3.0513396965559965e-08 total_time 723.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3462, reward 614.0, memory_length 2000, epsilon 3.036121076329232e-08 total_time 725.0\n",
      "episode 3463, reward 1381.0, memory_length 2000, epsilon 3.0209783592874965e-08 total_time 725.0\n",
      "episode 3464, reward 1220.0, memory_length 2000, epsilon 3.0059111668620965e-08 total_time 729.0\n",
      "episode 3465, reward 1040.0, memory_length 2000, epsilon 2.990919122372426e-08 total_time 729.0\n",
      "episode 3466, reward 782.0, memory_length 2000, epsilon 2.9760018510165816e-08 total_time 722.0\n",
      "episode 3467, reward 696.0, memory_length 2000, epsilon 2.9611589798620235e-08 total_time 725.0\n",
      "episode 3468, reward 1292.0, memory_length 2000, epsilon 2.9463901378361888e-08 total_time 727.0\n",
      "episode 3469, reward 1011.0, memory_length 2000, epsilon 2.9316949557172582e-08 total_time 723.0\n",
      "episode 3470, reward 1244.0, memory_length 2000, epsilon 2.9170730661249026e-08 total_time 726.0\n",
      "Saving Model 3470\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3471, reward 536.0, memory_length 2000, epsilon 2.902524103511142e-08 total_time 723.0\n",
      "episode 3472, reward 830.0, memory_length 2000, epsilon 2.8880477041511415e-08 total_time 730.0\n",
      "episode 3473, reward 792.0, memory_length 2000, epsilon 2.8736435061341543e-08 total_time 726.0\n",
      "episode 3474, reward 1409.0, memory_length 2000, epsilon 2.8593111493544998e-08 total_time 723.0\n",
      "episode 3475, reward 957.0, memory_length 2000, epsilon 2.8450502755025017e-08 total_time 722.0\n",
      "episode 3476, reward 1236.0, memory_length 2000, epsilon 2.8308605280555707e-08 total_time 731.0\n",
      "episode 3477, reward 1174.0, memory_length 2000, epsilon 2.816741552269272e-08 total_time 725.0\n",
      "episode 3478, reward 701.0, memory_length 2000, epsilon 2.8026929951684954e-08 total_time 725.0\n",
      "episode 3479, reward 1146.0, memory_length 2000, epsilon 2.788714505538572e-08 total_time 721.0\n",
      "episode 3480, reward 920.0, memory_length 2000, epsilon 2.7748057339165227e-08 total_time 723.0\n",
      "Saving Model 3480\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3481, reward 612.0, memory_length 2000, epsilon 2.760966332582352e-08 total_time 722.0\n",
      "episode 3482, reward 871.0, memory_length 2000, epsilon 2.7471959555502967e-08 total_time 724.0\n",
      "episode 3483, reward 624.0, memory_length 2000, epsilon 2.7334942585602135e-08 total_time 728.0\n",
      "episode 3484, reward 1139.0, memory_length 2000, epsilon 2.7198608990689538e-08 total_time 728.0\n",
      "episode 3485, reward 946.0, memory_length 2000, epsilon 2.7062955362418407e-08 total_time 723.0\n",
      "episode 3486, reward 822.0, memory_length 2000, epsilon 2.6927978309440863e-08 total_time 722.0\n",
      "episode 3487, reward 1131.0, memory_length 2000, epsilon 2.679367445732355e-08 total_time 724.0\n",
      "episode 3488, reward 948.0, memory_length 2000, epsilon 2.6660040448463087e-08 total_time 729.0\n",
      "episode 3489, reward 1425.0, memory_length 2000, epsilon 2.6527072942002473e-08 total_time 722.0\n",
      "episode 3490, reward 1076.0, memory_length 2000, epsilon 2.6394768613747025e-08 total_time 721.0\n",
      "Saving Model 3490\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3491, reward 1057.0, memory_length 2000, epsilon 2.626312415608156e-08 total_time 722.0\n",
      "episode 3492, reward 870.0, memory_length 2000, epsilon 2.613213627788796e-08 total_time 724.0\n",
      "episode 3493, reward 1222.0, memory_length 2000, epsilon 2.600180170446236e-08 total_time 726.0\n",
      "episode 3494, reward 1170.0, memory_length 2000, epsilon 2.587211717743363e-08 total_time 723.0\n",
      "episode 3495, reward 885.0, memory_length 2000, epsilon 2.574307945468175e-08 total_time 721.0\n",
      "episode 3496, reward 844.0, memory_length 2000, epsilon 2.561468531025712e-08 total_time 726.0\n",
      "episode 3497, reward 1055.0, memory_length 2000, epsilon 2.5486931534299343e-08 total_time 721.0\n",
      "episode 3498, reward 1405.0, memory_length 2000, epsilon 2.535981493295728e-08 total_time 728.0\n",
      "episode 3499, reward 1041.0, memory_length 2000, epsilon 2.5233332328309453e-08 total_time 721.0\n",
      "episode 3500, reward 991.0, memory_length 2000, epsilon 2.5107480558284076e-08 total_time 728.0\n",
      "Saving Model 3500\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3501, reward 1130.0, memory_length 2000, epsilon 2.4982256476580332e-08 total_time 722.0\n",
      "episode 3502, reward 1143.0, memory_length 2000, epsilon 2.485765695258958e-08 total_time 722.0\n",
      "episode 3503, reward 947.0, memory_length 2000, epsilon 2.4733678871317397e-08 total_time 730.0\n",
      "episode 3504, reward 614.0, memory_length 2000, epsilon 2.4610319133305214e-08 total_time 723.0\n",
      "episode 3505, reward 1275.0, memory_length 2000, epsilon 2.4487574654553062e-08 total_time 722.0\n",
      "episode 3506, reward 1285.0, memory_length 2000, epsilon 2.4365442366442757e-08 total_time 729.0\n",
      "episode 3507, reward 918.0, memory_length 2000, epsilon 2.424391921566065e-08 total_time 735.0\n",
      "episode 3508, reward 652.0, memory_length 2000, epsilon 2.4123002164121638e-08 total_time 721.0\n",
      "episode 3509, reward 855.0, memory_length 2000, epsilon 2.4002688188893045e-08 total_time 727.0\n",
      "episode 3510, reward 1228.0, memory_length 2000, epsilon 2.388297428211941e-08 total_time 726.0\n",
      "Saving Model 3510\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3511, reward 1056.0, memory_length 2000, epsilon 2.376385745094673e-08 total_time 725.0\n",
      "episode 3512, reward 1034.0, memory_length 2000, epsilon 2.3645334717448025e-08 total_time 726.0\n",
      "episode 3513, reward 1003.0, memory_length 2000, epsilon 2.3527403118548702e-08 total_time 727.0\n",
      "episode 3514, reward 1583.0, memory_length 2000, epsilon 2.3410059705952812e-08 total_time 722.0\n",
      "episode 3515, reward 1191.0, memory_length 2000, epsilon 2.3293301546068842e-08 total_time 724.0\n",
      "episode 3516, reward 1300.0, memory_length 2000, epsilon 2.3177125719936643e-08 total_time 731.0\n",
      "episode 3517, reward 1617.0, memory_length 2000, epsilon 2.3061529323154664e-08 total_time 722.0\n",
      "episode 3518, reward 1228.0, memory_length 2000, epsilon 2.2946509465806886e-08 total_time 724.0\n",
      "episode 3519, reward 658.0, memory_length 2000, epsilon 2.2832063272390883e-08 total_time 723.0\n",
      "episode 3520, reward 1394.0, memory_length 2000, epsilon 2.2718187881745782e-08 total_time 726.0\n",
      "Saving Model 3520\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3521, reward 1040.0, memory_length 2000, epsilon 2.2604880446981044e-08 total_time 731.0\n",
      "episode 3522, reward 1013.0, memory_length 2000, epsilon 2.249213813540482e-08 total_time 724.0\n",
      "episode 3523, reward 901.0, memory_length 2000, epsilon 2.237995812845337e-08 total_time 727.0\n",
      "episode 3524, reward 967.0, memory_length 2000, epsilon 2.2268337621620833e-08 total_time 725.0\n",
      "episode 3525, reward 1354.0, memory_length 2000, epsilon 2.2157273824388642e-08 total_time 724.0\n",
      "episode 3526, reward 1412.0, memory_length 2000, epsilon 2.2046763960156093e-08 total_time 735.0\n",
      "episode 3527, reward 1288.0, memory_length 2000, epsilon 2.1936805266170734e-08 total_time 724.0\n",
      "episode 3528, reward 1407.0, memory_length 2000, epsilon 2.1827394993459656e-08 total_time 722.0\n",
      "episode 3529, reward 1124.0, memory_length 2000, epsilon 2.1718530406760256e-08 total_time 728.0\n",
      "episode 3530, reward 1270.0, memory_length 2000, epsilon 2.161020878445212e-08 total_time 725.0\n",
      "Saving Model 3530\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3531, reward 1515.0, memory_length 2000, epsilon 2.1502427418489204e-08 total_time 727.0\n",
      "episode 3532, reward 635.0, memory_length 2000, epsilon 2.1395183614331675e-08 total_time 721.0\n",
      "episode 3533, reward 1328.0, memory_length 2000, epsilon 2.1288474690878834e-08 total_time 722.0\n",
      "episode 3534, reward 1212.0, memory_length 2000, epsilon 2.1182297980401967e-08 total_time 728.0\n",
      "episode 3535, reward 947.0, memory_length 2000, epsilon 2.1076650828477928e-08 total_time 727.0\n",
      "episode 3536, reward 561.0, memory_length 2000, epsilon 2.0971530593922347e-08 total_time 725.0\n",
      "episode 3537, reward 1107.0, memory_length 2000, epsilon 2.086693464872388e-08 total_time 731.0\n",
      "episode 3538, reward 779.0, memory_length 2000, epsilon 2.0762860377978378e-08 total_time 726.0\n",
      "episode 3539, reward 859.0, memory_length 2000, epsilon 2.06593051798238e-08 total_time 727.0\n",
      "episode 3540, reward 1666.0, memory_length 2000, epsilon 2.0556266465374725e-08 total_time 724.0\n",
      "Saving Model 3540\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3541, reward 852.0, memory_length 2000, epsilon 2.0453741658657848e-08 total_time 723.0\n",
      "episode 3542, reward 1019.0, memory_length 2000, epsilon 2.0351728196547813e-08 total_time 725.0\n",
      "episode 3543, reward 839.0, memory_length 2000, epsilon 2.0250223528702677e-08 total_time 726.0\n",
      "episode 3544, reward 637.0, memory_length 2000, epsilon 2.0149225117500456e-08 total_time 722.0\n",
      "episode 3545, reward 1176.0, memory_length 2000, epsilon 2.004873043797554e-08 total_time 724.0\n",
      "episode 3546, reward 1104.0, memory_length 2000, epsilon 1.9948736977755857e-08 total_time 728.0\n",
      "episode 3547, reward 1325.0, memory_length 2000, epsilon 1.984924223699961e-08 total_time 732.0\n",
      "episode 3548, reward 783.0, memory_length 2000, epsilon 1.975024372833304e-08 total_time 734.0\n",
      "episode 3549, reward 1003.0, memory_length 2000, epsilon 1.9651738976788398e-08 total_time 732.0\n",
      "episode 3550, reward 1073.0, memory_length 2000, epsilon 1.9553725519741712e-08 total_time 722.0\n",
      "Saving Model 3550\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3551, reward 1029.0, memory_length 2000, epsilon 1.945620090685144e-08 total_time 728.0\n",
      "episode 3552, reward 1221.0, memory_length 2000, epsilon 1.9359162699997117e-08 total_time 725.0\n",
      "episode 3553, reward 1463.0, memory_length 2000, epsilon 1.926260847321865e-08 total_time 725.0\n",
      "episode 3554, reward 1428.0, memory_length 2000, epsilon 1.9166535812655277e-08 total_time 726.0\n",
      "episode 3555, reward 1560.0, memory_length 2000, epsilon 1.907094231648541e-08 total_time 721.0\n",
      "episode 3556, reward 847.0, memory_length 2000, epsilon 1.8975825594866803e-08 total_time 721.0\n",
      "episode 3557, reward 649.0, memory_length 2000, epsilon 1.888118326987639e-08 total_time 728.0\n",
      "episode 3558, reward 416.0, memory_length 2000, epsilon 1.878701297545112e-08 total_time 729.0\n",
      "episode 3559, reward 755.0, memory_length 2000, epsilon 1.8693312357328665e-08 total_time 723.0\n",
      "episode 3560, reward 855.0, memory_length 2000, epsilon 1.860007907298882e-08 total_time 721.0\n",
      "Saving Model 3560\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3561, reward 1123.0, memory_length 2000, epsilon 1.8507310791594553e-08 total_time 724.0\n",
      "episode 3562, reward 1037.0, memory_length 2000, epsilon 1.8415005193933998e-08 total_time 726.0\n",
      "episode 3563, reward 1091.0, memory_length 2000, epsilon 1.832315997236234e-08 total_time 726.0\n",
      "episode 3564, reward 886.0, memory_length 2000, epsilon 1.8231772830744392e-08 total_time 722.0\n",
      "episode 3565, reward 694.0, memory_length 2000, epsilon 1.8140841484396784e-08 total_time 722.0\n",
      "episode 3566, reward 1262.0, memory_length 2000, epsilon 1.8050363660031054e-08 total_time 723.0\n",
      "episode 3567, reward 786.0, memory_length 2000, epsilon 1.7960337095697016e-08 total_time 721.0\n",
      "episode 3568, reward 546.0, memory_length 2000, epsilon 1.7870759540725807e-08 total_time 723.0\n",
      "episode 3569, reward 746.0, memory_length 2000, epsilon 1.7781628755673883e-08 total_time 721.0\n",
      "episode 3570, reward 813.0, memory_length 2000, epsilon 1.7692942512266918e-08 total_time 724.0\n",
      "Saving Model 3570\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3571, reward 985.0, memory_length 2000, epsilon 1.7604698593344324e-08 total_time 725.0\n",
      "episode 3572, reward 849.0, memory_length 2000, epsilon 1.7516894792803483e-08 total_time 726.0\n",
      "episode 3573, reward 1467.0, memory_length 2000, epsilon 1.7429528915544737e-08 total_time 724.0\n",
      "episode 3574, reward 863.0, memory_length 2000, epsilon 1.734259877741673e-08 total_time 727.0\n",
      "episode 3575, reward 992.0, memory_length 2000, epsilon 1.7256102205161417e-08 total_time 724.0\n",
      "episode 3576, reward 1139.0, memory_length 2000, epsilon 1.7170037036359994e-08 total_time 725.0\n",
      "episode 3577, reward 932.0, memory_length 2000, epsilon 1.7084401119378688e-08 total_time 723.0\n",
      "episode 3578, reward 1313.0, memory_length 2000, epsilon 1.699919231331524e-08 total_time 730.0\n",
      "episode 3579, reward 1205.0, memory_length 2000, epsilon 1.6914408487945002e-08 total_time 726.0\n",
      "episode 3580, reward 1060.0, memory_length 2000, epsilon 1.6830047523667864e-08 total_time 729.0\n",
      "Saving Model 3580\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3581, reward 1052.0, memory_length 2000, epsilon 1.674610731145544e-08 total_time 725.0\n",
      "episode 3582, reward 978.0, memory_length 2000, epsilon 1.6662585752798e-08 total_time 721.0\n",
      "episode 3583, reward 759.0, memory_length 2000, epsilon 1.657948075965222e-08 total_time 726.0\n",
      "episode 3584, reward 1206.0, memory_length 2000, epsilon 1.649679025438889e-08 total_time 728.0\n",
      "episode 3585, reward 1063.0, memory_length 2000, epsilon 1.6414512169741186e-08 total_time 723.0\n",
      "episode 3586, reward 919.0, memory_length 2000, epsilon 1.6332644448752646e-08 total_time 727.0\n",
      "episode 3587, reward 1005.0, memory_length 2000, epsilon 1.6251185044725987e-08 total_time 732.0\n",
      "episode 3588, reward 1165.0, memory_length 2000, epsilon 1.6170131921171806e-08 total_time 729.0\n",
      "episode 3589, reward 1307.0, memory_length 2000, epsilon 1.6089483051757906e-08 total_time 723.0\n",
      "episode 3590, reward 680.0, memory_length 2000, epsilon 1.6009236420258296e-08 total_time 725.0\n",
      "Saving Model 3590\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3591, reward 716.0, memory_length 2000, epsilon 1.5929390020502947e-08 total_time 725.0\n",
      "episode 3592, reward 1491.0, memory_length 2000, epsilon 1.5849941856327828e-08 total_time 724.0\n",
      "episode 3593, reward 884.0, memory_length 2000, epsilon 1.577088994152463e-08 total_time 721.0\n",
      "episode 3594, reward 1121.0, memory_length 2000, epsilon 1.5692232299791377e-08 total_time 726.0\n",
      "episode 3595, reward 1187.0, memory_length 2000, epsilon 1.5613966964682865e-08 total_time 722.0\n",
      "episode 3596, reward 1228.0, memory_length 2000, epsilon 1.553609197956175e-08 total_time 726.0\n",
      "episode 3597, reward 795.0, memory_length 2000, epsilon 1.5458605397549302e-08 total_time 721.0\n",
      "episode 3598, reward 759.0, memory_length 2000, epsilon 1.5381505281476873e-08 total_time 729.0\n",
      "episode 3599, reward 1154.0, memory_length 2000, epsilon 1.5304789703837656e-08 total_time 721.0\n",
      "episode 3600, reward 542.0, memory_length 2000, epsilon 1.5228456746738157e-08 total_time 725.0\n",
      "Saving Model 3600\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3601, reward 1311.0, memory_length 2000, epsilon 1.515250450185048e-08 total_time 727.0\n",
      "episode 3602, reward 1300.0, memory_length 2000, epsilon 1.5076931070364487e-08 total_time 729.0\n",
      "episode 3603, reward 1230.0, memory_length 2000, epsilon 1.500173456294056e-08 total_time 727.0\n",
      "episode 3604, reward 1441.0, memory_length 2000, epsilon 1.4926913099662053e-08 total_time 733.0\n",
      "episode 3605, reward 956.0, memory_length 2000, epsilon 1.485246480998843e-08 total_time 722.0\n",
      "episode 3606, reward 1079.0, memory_length 2000, epsilon 1.4778387832708673e-08 total_time 724.0\n",
      "episode 3607, reward 1075.0, memory_length 2000, epsilon 1.4704680315894443e-08 total_time 725.0\n",
      "episode 3608, reward 1240.0, memory_length 2000, epsilon 1.463134041685398e-08 total_time 721.0\n",
      "episode 3609, reward 1142.0, memory_length 2000, epsilon 1.4558366302085936e-08 total_time 722.0\n",
      "episode 3610, reward 709.0, memory_length 2000, epsilon 1.4485756147233742e-08 total_time 724.0\n",
      "Saving Model 3610\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3611, reward 1108.0, memory_length 2000, epsilon 1.4413508137039698e-08 total_time 722.0\n",
      "episode 3612, reward 856.0, memory_length 2000, epsilon 1.4341620465299785e-08 total_time 731.0\n",
      "episode 3613, reward 896.0, memory_length 2000, epsilon 1.4270091334818412e-08 total_time 723.0\n",
      "episode 3614, reward 1525.0, memory_length 2000, epsilon 1.4198918957363696e-08 total_time 722.0\n",
      "episode 3615, reward 1091.0, memory_length 2000, epsilon 1.4128101553622442e-08 total_time 727.0\n",
      "episode 3616, reward 1044.0, memory_length 2000, epsilon 1.4057637353155817e-08 total_time 725.0\n",
      "episode 3617, reward 1366.0, memory_length 2000, epsilon 1.3987524594355238e-08 total_time 725.0\n",
      "episode 3618, reward 1063.0, memory_length 2000, epsilon 1.3917761524398037e-08 total_time 723.0\n",
      "episode 3619, reward 969.0, memory_length 2000, epsilon 1.3848346399203831e-08 total_time 721.0\n",
      "episode 3620, reward 1599.0, memory_length 2000, epsilon 1.3779277483390823e-08 total_time 725.0\n",
      "Saving Model 3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3621, reward 1298.0, memory_length 2000, epsilon 1.3710553050232622e-08 total_time 723.0\n",
      "episode 3622, reward 1638.0, memory_length 2000, epsilon 1.3642171381614767e-08 total_time 724.0\n",
      "episode 3623, reward 1235.0, memory_length 2000, epsilon 1.3574130767991935e-08 total_time 721.0\n",
      "episode 3624, reward 731.0, memory_length 2000, epsilon 1.3506429508345337e-08 total_time 723.0\n",
      "episode 3625, reward 1021.0, memory_length 2000, epsilon 1.3439065910139907e-08 total_time 734.0\n",
      "episode 3626, reward 1526.0, memory_length 2000, epsilon 1.3372038289282184e-08 total_time 725.0\n",
      "episode 3627, reward 1060.0, memory_length 2000, epsilon 1.3305344970078108e-08 total_time 726.0\n",
      "episode 3628, reward 1278.0, memory_length 2000, epsilon 1.3238984285191317e-08 total_time 724.0\n",
      "episode 3629, reward 1311.0, memory_length 2000, epsilon 1.3172954575601185e-08 total_time 724.0\n",
      "episode 3630, reward 1292.0, memory_length 2000, epsilon 1.310725419056149e-08 total_time 722.0\n",
      "Saving Model 3630\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3631, reward 1524.0, memory_length 2000, epsilon 1.3041881487559275e-08 total_time 722.0\n",
      "episode 3632, reward 1002.0, memory_length 2000, epsilon 1.2976834832273515e-08 total_time 724.0\n",
      "episode 3633, reward 1251.0, memory_length 2000, epsilon 1.2912112598534439e-08 total_time 729.0\n",
      "episode 3634, reward 1216.0, memory_length 2000, epsilon 1.2847713168282787e-08 total_time 725.0\n",
      "episode 3635, reward 942.0, memory_length 2000, epsilon 1.278363493152954e-08 total_time 724.0\n",
      "episode 3636, reward 1056.0, memory_length 2000, epsilon 1.2719876286315396e-08 total_time 722.0\n",
      "episode 3637, reward 1141.0, memory_length 2000, epsilon 1.2656435638670905e-08 total_time 725.0\n",
      "episode 3638, reward 1283.0, memory_length 2000, epsilon 1.2593311402576523e-08 total_time 722.0\n",
      "episode 3639, reward 1020.0, memory_length 2000, epsilon 1.2530501999923155e-08 total_time 724.0\n",
      "episode 3640, reward 1013.0, memory_length 2000, epsilon 1.2468005860472413e-08 total_time 724.0\n",
      "Saving Model 3640\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3641, reward 975.0, memory_length 2000, epsilon 1.2405821421817517e-08 total_time 724.0\n",
      "episode 3642, reward 968.0, memory_length 2000, epsilon 1.2343947129344347e-08 total_time 722.0\n",
      "episode 3643, reward 1308.0, memory_length 2000, epsilon 1.2282381436192324e-08 total_time 724.0\n",
      "episode 3644, reward 1140.0, memory_length 2000, epsilon 1.2221122803215915e-08 total_time 722.0\n",
      "episode 3645, reward 1011.0, memory_length 2000, epsilon 1.216016969894606e-08 total_time 724.0\n",
      "episode 3646, reward 891.0, memory_length 2000, epsilon 1.2099520599552064e-08 total_time 725.0\n",
      "episode 3647, reward 1043.0, memory_length 2000, epsilon 1.2039173988803242e-08 total_time 724.0\n",
      "episode 3648, reward 1121.0, memory_length 2000, epsilon 1.1979128358031136e-08 total_time 722.0\n",
      "episode 3649, reward 905.0, memory_length 2000, epsilon 1.1919382206091939e-08 total_time 724.0\n",
      "episode 3650, reward 650.0, memory_length 2000, epsilon 1.1859934039328696e-08 total_time 721.0\n",
      "Saving Model 3650\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3651, reward 660.0, memory_length 2000, epsilon 1.180078237153414e-08 total_time 723.0\n",
      "episode 3652, reward 1245.0, memory_length 2000, epsilon 1.1741925723913455e-08 total_time 723.0\n",
      "episode 3653, reward 1181.0, memory_length 2000, epsilon 1.1683362625047472e-08 total_time 727.0\n",
      "episode 3654, reward 1299.0, memory_length 2000, epsilon 1.162509161085562e-08 total_time 728.0\n",
      "episode 3655, reward 1026.0, memory_length 2000, epsilon 1.1567111224559473e-08 total_time 726.0\n",
      "episode 3656, reward 1609.0, memory_length 2000, epsilon 1.1509420016646438e-08 total_time 729.0\n",
      "episode 3657, reward 1254.0, memory_length 2000, epsilon 1.1452016544833265e-08 total_time 723.0\n",
      "episode 3658, reward 1210.0, memory_length 2000, epsilon 1.1394899374030173e-08 total_time 725.0\n",
      "episode 3659, reward 647.0, memory_length 2000, epsilon 1.1338067076304877e-08 total_time 721.0\n",
      "episode 3660, reward 1287.0, memory_length 2000, epsilon 1.1281518230847056e-08 total_time 723.0\n",
      "Saving Model 3660\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3661, reward 1524.0, memory_length 2000, epsilon 1.1225251423932584e-08 total_time 726.0\n",
      "episode 3662, reward 895.0, memory_length 2000, epsilon 1.1169265248888359e-08 total_time 721.0\n",
      "episode 3663, reward 1060.0, memory_length 2000, epsilon 1.1113558306057048e-08 total_time 722.0\n",
      "episode 3664, reward 1321.0, memory_length 2000, epsilon 1.1058129202762262e-08 total_time 729.0\n",
      "episode 3665, reward 1177.0, memory_length 2000, epsilon 1.1002976553273489e-08 total_time 723.0\n",
      "episode 3666, reward 679.0, memory_length 2000, epsilon 1.0948098978771579e-08 total_time 721.0\n",
      "episode 3667, reward 1144.0, memory_length 2000, epsilon 1.0893495107314394e-08 total_time 721.0\n",
      "episode 3668, reward 1339.0, memory_length 2000, epsilon 1.0839163573802261e-08 total_time 721.0\n",
      "episode 3669, reward 1442.0, memory_length 2000, epsilon 1.0785103019944013e-08 total_time 722.0\n",
      "episode 3670, reward 1296.0, memory_length 2000, epsilon 1.073131209422295e-08 total_time 723.0\n",
      "Saving Model 3670\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3671, reward 925.0, memory_length 2000, epsilon 1.0677789451863204e-08 total_time 725.0\n",
      "episode 3672, reward 1290.0, memory_length 2000, epsilon 1.062453375479589e-08 total_time 729.0\n",
      "episode 3673, reward 800.0, memory_length 2000, epsilon 1.0571543671625768e-08 total_time 725.0\n",
      "episode 3674, reward 648.0, memory_length 2000, epsilon 1.0518817877598078e-08 total_time 722.0\n",
      "episode 3675, reward 994.0, memory_length 2000, epsilon 1.0466355054565184e-08 total_time 725.0\n",
      "episode 3676, reward 1158.0, memory_length 2000, epsilon 1.0414153890953775e-08 total_time 722.0\n",
      "episode 3677, reward 1058.0, memory_length 2000, epsilon 1.0362213081732008e-08 total_time 726.0\n",
      "episode 3678, reward 902.0, memory_length 2000, epsilon 1.031053132837702e-08 total_time 723.0\n",
      "episode 3679, reward 1693.0, memory_length 2000, epsilon 1.0259107338842248e-08 total_time 721.0\n",
      "episode 3680, reward 1087.0, memory_length 2000, epsilon 1.0207939827525242e-08 total_time 721.0\n",
      "Saving Model 3680\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3681, reward 1190.0, memory_length 2000, epsilon 1.0157027515235623e-08 total_time 722.0\n",
      "episode 3682, reward 588.0, memory_length 2000, epsilon 1.0106369129162898e-08 total_time 721.0\n",
      "episode 3683, reward 1084.0, memory_length 2000, epsilon 1.0055963402844774e-08 total_time 728.0\n",
      "episode 3684, reward 1106.0, memory_length 2000, epsilon 1.0005809076135435e-08 total_time 728.0\n",
      "episode 3685, reward 1053.0, memory_length 2000, epsilon 9.955904895174171e-09 total_time 726.0\n",
      "episode 3686, reward 1393.0, memory_length 2000, epsilon 9.906249612353825e-09 total_time 726.0\n",
      "episode 3687, reward 1032.0, memory_length 2000, epsilon 9.856841986289736e-09 total_time 732.0\n",
      "episode 3688, reward 938.0, memory_length 2000, epsilon 9.807680781788648e-09 total_time 723.0\n",
      "episode 3689, reward 1120.0, memory_length 2000, epsilon 9.758764769817957e-09 total_time 727.0\n",
      "episode 3690, reward 1143.0, memory_length 2000, epsilon 9.710092727474781e-09 total_time 728.0\n",
      "Saving Model 3690\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3691, reward 1178.0, memory_length 2000, epsilon 9.661663437955493e-09 total_time 729.0\n",
      "episode 3692, reward 1477.0, memory_length 2000, epsilon 9.613475690525398e-09 total_time 722.0\n",
      "episode 3693, reward 1523.0, memory_length 2000, epsilon 9.56552828048827e-09 total_time 722.0\n",
      "episode 3694, reward 1186.0, memory_length 2000, epsilon 9.517820009156358e-09 total_time 722.0\n",
      "episode 3695, reward 1237.0, memory_length 2000, epsilon 9.470349683820361e-09 total_time 725.0\n",
      "episode 3696, reward 1073.0, memory_length 2000, epsilon 9.423116117719742e-09 total_time 728.0\n",
      "episode 3697, reward 800.0, memory_length 2000, epsilon 9.376118130012854e-09 total_time 729.0\n",
      "episode 3698, reward 1184.0, memory_length 2000, epsilon 9.329354545747522e-09 total_time 730.0\n",
      "episode 3699, reward 1208.0, memory_length 2000, epsilon 9.282824195831772e-09 total_time 734.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3700, reward 985.0, memory_length 2000, epsilon 9.236525917004398e-09 total_time 721.0\n",
      "Saving Model 3700\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3701, reward 1056.0, memory_length 2000, epsilon 9.190458551806018e-09 total_time 728.0\n",
      "episode 3702, reward 1042.0, memory_length 2000, epsilon 9.14462094855007e-09 total_time 728.0\n",
      "episode 3703, reward 1106.0, memory_length 2000, epsilon 9.099011961294153e-09 total_time 722.0\n",
      "episode 3704, reward 1465.0, memory_length 2000, epsilon 9.053630449811176e-09 total_time 731.0\n",
      "episode 3705, reward 1207.0, memory_length 2000, epsilon 9.008475279560954e-09 total_time 727.0\n",
      "episode 3706, reward 1128.0, memory_length 2000, epsilon 8.963545321661945e-09 total_time 723.0\n",
      "episode 3707, reward 1200.0, memory_length 2000, epsilon 8.918839452862832e-09 total_time 724.0\n",
      "episode 3708, reward 926.0, memory_length 2000, epsilon 8.874356555514561e-09 total_time 722.0\n",
      "episode 3709, reward 792.0, memory_length 2000, epsilon 8.830095517542354e-09 total_time 734.0\n",
      "episode 3710, reward 1123.0, memory_length 2000, epsilon 8.786055232418017e-09 total_time 723.0\n",
      "Saving Model 3710\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3711, reward 931.0, memory_length 2000, epsilon 8.742234599132099e-09 total_time 721.0\n",
      "episode 3712, reward 1530.0, memory_length 2000, epsilon 8.698632522166483e-09 total_time 725.0\n",
      "episode 3713, reward 1071.0, memory_length 2000, epsilon 8.655247911466945e-09 total_time 723.0\n",
      "episode 3714, reward 550.0, memory_length 2000, epsilon 8.61207968241602e-09 total_time 727.0\n",
      "episode 3715, reward 664.0, memory_length 2000, epsilon 8.569126755805702e-09 total_time 728.0\n",
      "episode 3716, reward 1009.0, memory_length 2000, epsilon 8.526388057810554e-09 total_time 723.0\n",
      "episode 3717, reward 925.0, memory_length 2000, epsilon 8.483862519960968e-09 total_time 730.0\n",
      "episode 3718, reward 1376.0, memory_length 2000, epsilon 8.441549079116248e-09 total_time 723.0\n",
      "episode 3719, reward 1405.0, memory_length 2000, epsilon 8.39944667743817e-09 total_time 723.0\n",
      "episode 3720, reward 1326.0, memory_length 2000, epsilon 8.357554262364471e-09 total_time 725.0\n",
      "Saving Model 3720\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3721, reward 966.0, memory_length 2000, epsilon 8.315870786582649e-09 total_time 727.0\n",
      "episode 3722, reward 1262.0, memory_length 2000, epsilon 8.274395208003611e-09 total_time 723.0\n",
      "episode 3723, reward 1150.0, memory_length 2000, epsilon 8.233126489735703e-09 total_time 727.0\n",
      "episode 3724, reward 1006.0, memory_length 2000, epsilon 8.192063600058876e-09 total_time 727.0\n",
      "episode 3725, reward 1175.0, memory_length 2000, epsilon 8.15120551239872e-09 total_time 724.0\n",
      "episode 3726, reward 1215.0, memory_length 2000, epsilon 8.110551205300917e-09 total_time 723.0\n",
      "episode 3727, reward 1162.0, memory_length 2000, epsilon 8.070099662405643e-09 total_time 726.0\n",
      "episode 3728, reward 1063.0, memory_length 2000, epsilon 8.029849872422276e-09 total_time 725.0\n",
      "episode 3729, reward 1118.0, memory_length 2000, epsilon 7.98980082910394e-09 total_time 729.0\n",
      "episode 3730, reward 818.0, memory_length 2000, epsilon 7.94995153122244e-09 total_time 730.0\n",
      "Saving Model 3730\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3731, reward 767.0, memory_length 2000, epsilon 7.910300982543309e-09 total_time 723.0\n",
      "episode 3732, reward 1079.0, memory_length 2000, epsilon 7.870848191800735e-09 total_time 730.0\n",
      "episode 3733, reward 763.0, memory_length 2000, epsilon 7.8315921726729e-09 total_time 727.0\n",
      "episode 3734, reward 1123.0, memory_length 2000, epsilon 7.792531943757246e-09 total_time 721.0\n",
      "episode 3735, reward 1131.0, memory_length 2000, epsilon 7.753666528546076e-09 total_time 729.0\n",
      "episode 3736, reward 1112.0, memory_length 2000, epsilon 7.714994955401958e-09 total_time 731.0\n",
      "episode 3737, reward 1158.0, memory_length 2000, epsilon 7.67651625753355e-09 total_time 723.0\n",
      "episode 3738, reward 1173.0, memory_length 2000, epsilon 7.638229472971368e-09 total_time 722.0\n",
      "episode 3739, reward 1439.0, memory_length 2000, epsilon 7.600133644543863e-09 total_time 725.0\n",
      "episode 3740, reward 1399.0, memory_length 2000, epsilon 7.562227819853314e-09 total_time 723.0\n",
      "Saving Model 3740\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3741, reward 972.0, memory_length 2000, epsilon 7.524511051252098e-09 total_time 727.0\n",
      "episode 3742, reward 1281.0, memory_length 2000, epsilon 7.486982395819094e-09 total_time 729.0\n",
      "episode 3743, reward 877.0, memory_length 2000, epsilon 7.449640915335933e-09 total_time 725.0\n",
      "episode 3744, reward 1038.0, memory_length 2000, epsilon 7.4124856762636575e-09 total_time 721.0\n",
      "episode 3745, reward 865.0, memory_length 2000, epsilon 7.375515749719329e-09 total_time 723.0\n",
      "episode 3746, reward 805.0, memory_length 2000, epsilon 7.338730211452912e-09 total_time 724.0\n",
      "episode 3747, reward 1027.0, memory_length 2000, epsilon 7.302128141824006e-09 total_time 723.0\n",
      "episode 3748, reward 1041.0, memory_length 2000, epsilon 7.265708625778941e-09 total_time 726.0\n",
      "episode 3749, reward 969.0, memory_length 2000, epsilon 7.2294707528279685e-09 total_time 723.0\n",
      "episode 3750, reward 946.0, memory_length 2000, epsilon 7.193413617022351e-09 total_time 722.0\n",
      "Saving Model 3750\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3751, reward 903.0, memory_length 2000, epsilon 7.157536316931817e-09 total_time 725.0\n",
      "episode 3752, reward 713.0, memory_length 2000, epsilon 7.121837955621969e-09 total_time 722.0\n",
      "episode 3753, reward 1581.0, memory_length 2000, epsilon 7.086317640631967e-09 total_time 722.0\n",
      "episode 3754, reward 777.0, memory_length 2000, epsilon 7.05097448395206e-09 total_time 726.0\n",
      "episode 3755, reward 862.0, memory_length 2000, epsilon 7.015807602001464e-09 total_time 724.0\n",
      "episode 3756, reward 888.0, memory_length 2000, epsilon 6.980816115606352e-09 total_time 725.0\n",
      "episode 3757, reward 1226.0, memory_length 2000, epsilon 6.945999149977714e-09 total_time 725.0\n",
      "episode 3758, reward 1536.0, memory_length 2000, epsilon 6.911355834689596e-09 total_time 723.0\n",
      "episode 3759, reward 1581.0, memory_length 2000, epsilon 6.876885303657287e-09 total_time 723.0\n",
      "episode 3760, reward 1812.0, memory_length 2000, epsilon 6.842586695115766e-09 total_time 724.0\n",
      "Saving Model 3760\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3761, reward 1269.0, memory_length 2000, epsilon 6.8084591515980075e-09 total_time 722.0\n",
      "episode 3762, reward 1023.0, memory_length 2000, epsilon 6.7745018199136464e-09 total_time 722.0\n",
      "episode 3763, reward 1275.0, memory_length 2000, epsilon 6.740713851127599e-09 total_time 722.0\n",
      "episode 3764, reward 1023.0, memory_length 2000, epsilon 6.707094400538932e-09 total_time 726.0\n",
      "episode 3765, reward 931.0, memory_length 2000, epsilon 6.673642627659607e-09 total_time 721.0\n",
      "episode 3766, reward 1169.0, memory_length 2000, epsilon 6.640357696193535e-09 total_time 723.0\n",
      "episode 3767, reward 1401.0, memory_length 2000, epsilon 6.607238774015744e-09 total_time 728.0\n",
      "episode 3768, reward 1563.0, memory_length 2000, epsilon 6.574285033151431e-09 total_time 726.0\n",
      "episode 3769, reward 693.0, memory_length 2000, epsilon 6.541495649755358e-09 total_time 722.0\n",
      "episode 3770, reward 870.0, memory_length 2000, epsilon 6.508869804091208e-09 total_time 722.0\n",
      "Saving Model 3770\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3771, reward 1099.0, memory_length 2000, epsilon 6.476406680511187e-09 total_time 729.0\n",
      "episode 3772, reward 1387.0, memory_length 2000, epsilon 6.4441054674354935e-09 total_time 723.0\n",
      "episode 3773, reward 808.0, memory_length 2000, epsilon 6.411965357332093e-09 total_time 721.0\n",
      "episode 3774, reward 1584.0, memory_length 2000, epsilon 6.379985546696605e-09 total_time 722.0\n",
      "episode 3775, reward 1486.0, memory_length 2000, epsilon 6.348165236032076e-09 total_time 721.0\n",
      "episode 3776, reward 963.0, memory_length 2000, epsilon 6.316503629829081e-09 total_time 721.0\n",
      "episode 3777, reward 1368.0, memory_length 2000, epsilon 6.284999936545795e-09 total_time 723.0\n",
      "episode 3778, reward 1098.0, memory_length 2000, epsilon 6.253653368588288e-09 total_time 721.0\n",
      "episode 3779, reward 923.0, memory_length 2000, epsilon 6.222463142290709e-09 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3780, reward 1458.0, memory_length 2000, epsilon 6.19142847789575e-09 total_time 726.0\n",
      "Saving Model 3780\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3781, reward 1381.0, memory_length 2000, epsilon 6.160548599535232e-09 total_time 725.0\n",
      "episode 3782, reward 956.0, memory_length 2000, epsilon 6.129822735210564e-09 total_time 724.0\n",
      "episode 3783, reward 1603.0, memory_length 2000, epsilon 6.099250116773539e-09 total_time 729.0\n",
      "episode 3784, reward 975.0, memory_length 2000, epsilon 6.068829979907081e-09 total_time 721.0\n",
      "episode 3785, reward 1039.0, memory_length 2000, epsilon 6.0385615641062265e-09 total_time 726.0\n",
      "episode 3786, reward 1563.0, memory_length 2000, epsilon 6.0084441126589835e-09 total_time 727.0\n",
      "episode 3787, reward 1089.0, memory_length 2000, epsilon 5.978476872627497e-09 total_time 726.0\n",
      "episode 3788, reward 1345.0, memory_length 2000, epsilon 5.948659094829185e-09 total_time 730.0\n",
      "episode 3789, reward 895.0, memory_length 2000, epsilon 5.9189900338180916e-09 total_time 722.0\n",
      "episode 3790, reward 1364.0, memory_length 2000, epsilon 5.889468947866123e-09 total_time 730.0\n",
      "Saving Model 3790\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3791, reward 994.0, memory_length 2000, epsilon 5.860095098944574e-09 total_time 728.0\n",
      "episode 3792, reward 1217.0, memory_length 2000, epsilon 5.830867752705734e-09 total_time 722.0\n",
      "episode 3793, reward 996.0, memory_length 2000, epsilon 5.801786178464402e-09 total_time 722.0\n",
      "episode 3794, reward 481.0, memory_length 2000, epsilon 5.772849649179708e-09 total_time 725.0\n",
      "episode 3795, reward 1129.0, memory_length 2000, epsilon 5.7440574414368924e-09 total_time 723.0\n",
      "episode 3796, reward 1087.0, memory_length 2000, epsilon 5.715408835429304e-09 total_time 729.0\n",
      "episode 3797, reward 886.0, memory_length 2000, epsilon 5.686903114940279e-09 total_time 724.0\n",
      "episode 3798, reward 1211.0, memory_length 2000, epsilon 5.6585395673253005e-09 total_time 723.0\n",
      "episode 3799, reward 1695.0, memory_length 2000, epsilon 5.6303174834942404e-09 total_time 727.0\n",
      "episode 3800, reward 639.0, memory_length 2000, epsilon 5.602236157893514e-09 total_time 722.0\n",
      "Saving Model 3800\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3801, reward 995.0, memory_length 2000, epsilon 5.5742948884885175e-09 total_time 729.0\n",
      "episode 3802, reward 1317.0, memory_length 2000, epsilon 5.546492976746043e-09 total_time 726.0\n",
      "episode 3803, reward 1971.0, memory_length 2000, epsilon 5.518829727616886e-09 total_time 722.0\n",
      "episode 3804, reward 921.0, memory_length 2000, epsilon 5.491304449518359e-09 total_time 731.0\n",
      "episode 3805, reward 1513.0, memory_length 2000, epsilon 5.463916454317056e-09 total_time 725.0\n",
      "episode 3806, reward 1217.0, memory_length 2000, epsilon 5.436665057311709e-09 total_time 723.0\n",
      "episode 3807, reward 1956.0, memory_length 2000, epsilon 5.409549577215956e-09 total_time 724.0\n",
      "episode 3808, reward 1565.0, memory_length 2000, epsilon 5.38256933614138e-09 total_time 726.0\n",
      "episode 3809, reward 765.0, memory_length 2000, epsilon 5.355723659580531e-09 total_time 722.0\n",
      "episode 3810, reward 1332.0, memory_length 2000, epsilon 5.329011876390134e-09 total_time 721.0\n",
      "Saving Model 3810\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3811, reward 1076.0, memory_length 2000, epsilon 5.302433318774202e-09 total_time 723.0\n",
      "episode 3812, reward 1269.0, memory_length 2000, epsilon 5.275987322267405e-09 total_time 723.0\n",
      "episode 3813, reward 1084.0, memory_length 2000, epsilon 5.249673225718439e-09 total_time 724.0\n",
      "episode 3814, reward 908.0, memory_length 2000, epsilon 5.223490371273555e-09 total_time 725.0\n",
      "episode 3815, reward 1472.0, memory_length 2000, epsilon 5.1974381043600095e-09 total_time 723.0\n",
      "episode 3816, reward 1298.0, memory_length 2000, epsilon 5.171515773669755e-09 total_time 726.0\n",
      "episode 3817, reward 1337.0, memory_length 2000, epsilon 5.145722731143211e-09 total_time 724.0\n",
      "episode 3818, reward 933.0, memory_length 2000, epsilon 5.120058331952951e-09 total_time 730.0\n",
      "episode 3819, reward 856.0, memory_length 2000, epsilon 5.09452193448766e-09 total_time 727.0\n",
      "episode 3820, reward 1363.0, memory_length 2000, epsilon 5.069112900336055e-09 total_time 725.0\n",
      "Saving Model 3820\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3821, reward 1006.0, memory_length 2000, epsilon 5.043830594270991e-09 total_time 726.0\n",
      "episode 3822, reward 1279.0, memory_length 2000, epsilon 5.018674384233484e-09 total_time 723.0\n",
      "episode 3823, reward 979.0, memory_length 2000, epsilon 4.993643641316954e-09 total_time 722.0\n",
      "episode 3824, reward 855.0, memory_length 2000, epsilon 4.968737739751561e-09 total_time 727.0\n",
      "episode 3825, reward 577.0, memory_length 2000, epsilon 4.94395605688845e-09 total_time 723.0\n",
      "episode 3826, reward 996.0, memory_length 2000, epsilon 4.9192979731842595e-09 total_time 722.0\n",
      "episode 3827, reward 1185.0, memory_length 2000, epsilon 4.894762872185595e-09 total_time 721.0\n",
      "episode 3828, reward 1248.0, memory_length 2000, epsilon 4.870350140513688e-09 total_time 724.0\n",
      "episode 3829, reward 1333.0, memory_length 2000, epsilon 4.8460591678489585e-09 total_time 724.0\n",
      "episode 3830, reward 894.0, memory_length 2000, epsilon 4.821889346915807e-09 total_time 734.0\n",
      "Saving Model 3830\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3831, reward 1186.0, memory_length 2000, epsilon 4.797840073467485e-09 total_time 723.0\n",
      "episode 3832, reward 726.0, memory_length 2000, epsilon 4.7739107462708886e-09 total_time 730.0\n",
      "episode 3833, reward 958.0, memory_length 2000, epsilon 4.75010076709159e-09 total_time 729.0\n",
      "episode 3834, reward 916.0, memory_length 2000, epsilon 4.726409540678852e-09 total_time 729.0\n",
      "episode 3835, reward 1306.0, memory_length 2000, epsilon 4.702836474750817e-09 total_time 721.0\n",
      "episode 3836, reward 1106.0, memory_length 2000, epsilon 4.6793809799795896e-09 total_time 728.0\n",
      "episode 3837, reward 1301.0, memory_length 2000, epsilon 4.656042469976579e-09 total_time 722.0\n",
      "episode 3838, reward 589.0, memory_length 2000, epsilon 4.632820361277804e-09 total_time 732.0\n",
      "episode 3839, reward 988.0, memory_length 2000, epsilon 4.6097140733293705e-09 total_time 727.0\n",
      "episode 3840, reward 893.0, memory_length 2000, epsilon 4.586723028472859e-09 total_time 723.0\n",
      "Saving Model 3840\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3841, reward 1166.0, memory_length 2000, epsilon 4.563846651930937e-09 total_time 723.0\n",
      "episode 3842, reward 1255.0, memory_length 2000, epsilon 4.541084371793028e-09 total_time 727.0\n",
      "episode 3843, reward 1358.0, memory_length 2000, epsilon 4.51843561900093e-09 total_time 723.0\n",
      "episode 3844, reward 687.0, memory_length 2000, epsilon 4.495899827334642e-09 total_time 723.0\n",
      "episode 3845, reward 1467.0, memory_length 2000, epsilon 4.4734764333981834e-09 total_time 728.0\n",
      "episode 3846, reward 1070.0, memory_length 2000, epsilon 4.451164876605569e-09 total_time 722.0\n",
      "episode 3847, reward 1350.0, memory_length 2000, epsilon 4.4289645991667005e-09 total_time 728.0\n",
      "episode 3848, reward 948.0, memory_length 2000, epsilon 4.406875046073472e-09 total_time 726.0\n",
      "episode 3849, reward 1387.0, memory_length 2000, epsilon 4.384895665085936e-09 total_time 730.0\n",
      "episode 3850, reward 993.0, memory_length 2000, epsilon 4.363025906718407e-09 total_time 721.0\n",
      "Saving Model 3850\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3851, reward 1181.0, memory_length 2000, epsilon 4.3412652242257875e-09 total_time 724.0\n",
      "episode 3852, reward 787.0, memory_length 2000, epsilon 4.319613073589866e-09 total_time 723.0\n",
      "episode 3853, reward 1058.0, memory_length 2000, epsilon 4.298068913505779e-09 total_time 726.0\n",
      "episode 3854, reward 922.0, memory_length 2000, epsilon 4.2766322053683875e-09 total_time 729.0\n",
      "episode 3855, reward 1183.0, memory_length 2000, epsilon 4.255302413258857e-09 total_time 724.0\n",
      "episode 3856, reward 1341.0, memory_length 2000, epsilon 4.234079003931303e-09 total_time 729.0\n",
      "episode 3857, reward 978.0, memory_length 2000, epsilon 4.212961446799373e-09 total_time 721.0\n",
      "episode 3858, reward 1080.0, memory_length 2000, epsilon 4.191949213923039e-09 total_time 726.0\n",
      "episode 3859, reward 1223.0, memory_length 2000, epsilon 4.171041779995367e-09 total_time 724.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3860, reward 1502.0, memory_length 2000, epsilon 4.1502386223294535e-09 total_time 730.0\n",
      "Saving Model 3860\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3861, reward 1094.0, memory_length 2000, epsilon 4.129539220845256e-09 total_time 728.0\n",
      "episode 3862, reward 1718.0, memory_length 2000, epsilon 4.10894305805666e-09 total_time 731.0\n",
      "episode 3863, reward 1154.0, memory_length 2000, epsilon 4.088449619058509e-09 total_time 721.0\n",
      "episode 3864, reward 1233.0, memory_length 2000, epsilon 4.068058391513788e-09 total_time 723.0\n",
      "episode 3865, reward 1228.0, memory_length 2000, epsilon 4.047768865640734e-09 total_time 724.0\n",
      "episode 3866, reward 1613.0, memory_length 2000, epsilon 4.027580534200127e-09 total_time 721.0\n",
      "episode 3867, reward 961.0, memory_length 2000, epsilon 4.00749289248266e-09 total_time 726.0\n",
      "episode 3868, reward 1150.0, memory_length 2000, epsilon 3.987505438296229e-09 total_time 721.0\n",
      "episode 3869, reward 1135.0, memory_length 2000, epsilon 3.967617671953438e-09 total_time 724.0\n",
      "episode 3870, reward 1149.0, memory_length 2000, epsilon 3.947829096259079e-09 total_time 728.0\n",
      "Saving Model 3870\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3871, reward 1496.0, memory_length 2000, epsilon 3.928139216497757e-09 total_time 723.0\n",
      "episode 3872, reward 1291.0, memory_length 2000, epsilon 3.908547540421437e-09 total_time 722.0\n",
      "episode 3873, reward 1390.0, memory_length 2000, epsilon 3.889053578237186e-09 total_time 726.0\n",
      "episode 3874, reward 1016.0, memory_length 2000, epsilon 3.869656842594958e-09 total_time 726.0\n",
      "episode 3875, reward 1414.0, memory_length 2000, epsilon 3.8503568485753395e-09 total_time 735.0\n",
      "episode 3876, reward 938.0, memory_length 2000, epsilon 3.831153113677477e-09 total_time 728.0\n",
      "episode 3877, reward 974.0, memory_length 2000, epsilon 3.81204515780698e-09 total_time 727.0\n",
      "episode 3878, reward 1152.0, memory_length 2000, epsilon 3.793032503263987e-09 total_time 727.0\n",
      "episode 3879, reward 1130.0, memory_length 2000, epsilon 3.774114674731129e-09 total_time 726.0\n",
      "episode 3880, reward 1237.0, memory_length 2000, epsilon 3.7552911992616955e-09 total_time 727.0\n",
      "Saving Model 3880\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3881, reward 1023.0, memory_length 2000, epsilon 3.736561606267844e-09 total_time 730.0\n",
      "episode 3882, reward 1013.0, memory_length 2000, epsilon 3.7179254275087627e-09 total_time 724.0\n",
      "episode 3883, reward 1330.0, memory_length 2000, epsilon 3.699382197079011e-09 total_time 727.0\n",
      "episode 3884, reward 900.0, memory_length 2000, epsilon 3.6809314513968492e-09 total_time 724.0\n",
      "episode 3885, reward 1151.0, memory_length 2000, epsilon 3.6625727291927007e-09 total_time 721.0\n",
      "episode 3886, reward 1524.0, memory_length 2000, epsilon 3.644305571497542e-09 total_time 723.0\n",
      "episode 3887, reward 1555.0, memory_length 2000, epsilon 3.6261295216314774e-09 total_time 727.0\n",
      "episode 3888, reward 655.0, memory_length 2000, epsilon 3.6080441251923025e-09 total_time 723.0\n",
      "episode 3889, reward 851.0, memory_length 2000, epsilon 3.5900489300441892e-09 total_time 724.0\n",
      "episode 3890, reward 1147.0, memory_length 2000, epsilon 3.5721434863063086e-09 total_time 726.0\n",
      "Saving Model 3890\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3891, reward 1512.0, memory_length 2000, epsilon 3.554327346341622e-09 total_time 728.0\n",
      "episode 3892, reward 1297.0, memory_length 2000, epsilon 3.536600064745729e-09 total_time 724.0\n",
      "episode 3893, reward 1005.0, memory_length 2000, epsilon 3.5189611983356522e-09 total_time 721.0\n",
      "episode 3894, reward 925.0, memory_length 2000, epsilon 3.501410306138813e-09 total_time 728.0\n",
      "episode 3895, reward 662.0, memory_length 2000, epsilon 3.48394694938198e-09 total_time 729.0\n",
      "episode 3896, reward 1070.0, memory_length 2000, epsilon 3.4665706914803496e-09 total_time 730.0\n",
      "episode 3897, reward 818.0, memory_length 2000, epsilon 3.4492810980265574e-09 total_time 726.0\n",
      "episode 3898, reward 1294.0, memory_length 2000, epsilon 3.4320777367798536e-09 total_time 733.0\n",
      "episode 3899, reward 1335.0, memory_length 2000, epsilon 3.414960177655336e-09 total_time 726.0\n",
      "episode 3900, reward 997.0, memory_length 2000, epsilon 3.3979279927131214e-09 total_time 725.0\n",
      "Saving Model 3900\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3901, reward 1169.0, memory_length 2000, epsilon 3.380980756147701e-09 total_time 721.0\n",
      "episode 3902, reward 1799.0, memory_length 2000, epsilon 3.364118044277265e-09 total_time 721.0\n",
      "episode 3903, reward 787.0, memory_length 2000, epsilon 3.3473394355331628e-09 total_time 736.0\n",
      "episode 3904, reward 1035.0, memory_length 2000, epsilon 3.3306445104492894e-09 total_time 721.0\n",
      "episode 3905, reward 686.0, memory_length 2000, epsilon 3.3140328516516366e-09 total_time 723.0\n",
      "episode 3906, reward 1283.0, memory_length 2000, epsilon 3.2975040438478933e-09 total_time 722.0\n",
      "episode 3907, reward 1139.0, memory_length 2000, epsilon 3.2810576738169906e-09 total_time 724.0\n",
      "episode 3908, reward 785.0, memory_length 2000, epsilon 3.2646933303988226e-09 total_time 721.0\n",
      "episode 3909, reward 1206.0, memory_length 2000, epsilon 3.2484106044839386e-09 total_time 722.0\n",
      "episode 3910, reward 996.0, memory_length 2000, epsilon 3.2322090890033667e-09 total_time 721.0\n",
      "Saving Model 3910\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3911, reward 793.0, memory_length 2000, epsilon 3.216088378918364e-09 total_time 724.0\n",
      "episode 3912, reward 1387.0, memory_length 2000, epsilon 3.2000480712103396e-09 total_time 729.0\n",
      "episode 3913, reward 1119.0, memory_length 2000, epsilon 3.1840877648707532e-09 total_time 723.0\n",
      "episode 3914, reward 605.0, memory_length 2000, epsilon 3.1682070608911377e-09 total_time 735.0\n",
      "episode 3915, reward 972.0, memory_length 2000, epsilon 3.1524055622530555e-09 total_time 724.0\n",
      "episode 3916, reward 1276.0, memory_length 2000, epsilon 3.1366828739182062e-09 total_time 724.0\n",
      "episode 3917, reward 1588.0, memory_length 2000, epsilon 3.1210386028185854e-09 total_time 726.0\n",
      "episode 3918, reward 1038.0, memory_length 2000, epsilon 3.105472357846589e-09 total_time 724.0\n",
      "episode 3919, reward 870.0, memory_length 2000, epsilon 3.089983749845282e-09 total_time 723.0\n",
      "episode 3920, reward 1571.0, memory_length 2000, epsilon 3.0745723915986475e-09 total_time 728.0\n",
      "Saving Model 3920\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3921, reward 1241.0, memory_length 2000, epsilon 3.059237897821948e-09 total_time 723.0\n",
      "episode 3922, reward 1056.0, memory_length 2000, epsilon 3.043979885152029e-09 total_time 727.0\n",
      "episode 3923, reward 1272.0, memory_length 2000, epsilon 3.0287979721377693e-09 total_time 722.0\n",
      "episode 3924, reward 681.0, memory_length 2000, epsilon 3.0136917792305734e-09 total_time 726.0\n",
      "episode 3925, reward 809.0, memory_length 2000, epsilon 2.9986609287748217e-09 total_time 726.0\n",
      "episode 3926, reward 1195.0, memory_length 2000, epsilon 2.9837050449984693e-09 total_time 725.0\n",
      "episode 3927, reward 780.0, memory_length 2000, epsilon 2.9688237540036332e-09 total_time 723.0\n",
      "episode 3928, reward 942.0, memory_length 2000, epsilon 2.954016683757284e-09 total_time 728.0\n",
      "episode 3929, reward 1274.0, memory_length 2000, epsilon 2.939283464081884e-09 total_time 724.0\n",
      "episode 3930, reward 1047.0, memory_length 2000, epsilon 2.924623726646163e-09 total_time 726.0\n",
      "Saving Model 3930\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3931, reward 1178.0, memory_length 2000, epsilon 2.9100371049559434e-09 total_time 721.0\n",
      "episode 3932, reward 1025.0, memory_length 2000, epsilon 2.8955232343449122e-09 total_time 726.0\n",
      "episode 3933, reward 977.0, memory_length 2000, epsilon 2.881081751965548e-09 total_time 728.0\n",
      "episode 3934, reward 1213.0, memory_length 2000, epsilon 2.8667122967800293e-09 total_time 723.0\n",
      "episode 3935, reward 1463.0, memory_length 2000, epsilon 2.852414509551248e-09 total_time 722.0\n",
      "episode 3936, reward 1271.0, memory_length 2000, epsilon 2.8381880328337692e-09 total_time 728.0\n",
      "episode 3937, reward 1283.0, memory_length 2000, epsilon 2.8240325109649335e-09 total_time 725.0\n",
      "episode 3938, reward 1068.0, memory_length 2000, epsilon 2.809947590055947e-09 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3939, reward 1170.0, memory_length 2000, epsilon 2.7959329179830736e-09 total_time 729.0\n",
      "episode 3940, reward 1281.0, memory_length 2000, epsilon 2.7819881443787714e-09 total_time 730.0\n",
      "Saving Model 3940\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3941, reward 942.0, memory_length 2000, epsilon 2.7681129206229642e-09 total_time 723.0\n",
      "episode 3942, reward 1007.0, memory_length 2000, epsilon 2.754306899834355e-09 total_time 730.0\n",
      "episode 3943, reward 842.0, memory_length 2000, epsilon 2.740569736861695e-09 total_time 721.0\n",
      "episode 3944, reward 1126.0, memory_length 2000, epsilon 2.7269010882751947e-09 total_time 721.0\n",
      "episode 3945, reward 1018.0, memory_length 2000, epsilon 2.713300612357918e-09 total_time 727.0\n",
      "episode 3946, reward 1466.0, memory_length 2000, epsilon 2.6997679690972783e-09 total_time 723.0\n",
      "episode 3947, reward 1219.0, memory_length 2000, epsilon 2.6863028201764784e-09 total_time 728.0\n",
      "episode 3948, reward 594.0, memory_length 2000, epsilon 2.672904828966085e-09 total_time 726.0\n",
      "episode 3949, reward 1125.0, memory_length 2000, epsilon 2.6595736605156395e-09 total_time 723.0\n",
      "episode 3950, reward 1251.0, memory_length 2000, epsilon 2.646308981545226e-09 total_time 726.0\n",
      "Saving Model 3950\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3951, reward 1527.0, memory_length 2000, epsilon 2.6331104604371805e-09 total_time 728.0\n",
      "episode 3952, reward 1390.0, memory_length 2000, epsilon 2.6199777672277775e-09 total_time 723.0\n",
      "episode 3953, reward 756.0, memory_length 2000, epsilon 2.6069105735990214e-09 total_time 723.0\n",
      "episode 3954, reward 1322.0, memory_length 2000, epsilon 2.5939085528703822e-09 total_time 730.0\n",
      "episode 3955, reward 1215.0, memory_length 2000, epsilon 2.5809713799906557e-09 total_time 736.0\n",
      "episode 3956, reward 647.0, memory_length 2000, epsilon 2.5680987315298633e-09 total_time 727.0\n",
      "episode 3957, reward 1156.0, memory_length 2000, epsilon 2.5552902856711145e-09 total_time 721.0\n",
      "episode 3958, reward 1259.0, memory_length 2000, epsilon 2.5425457222025955e-09 total_time 727.0\n",
      "episode 3959, reward 877.0, memory_length 2000, epsilon 2.529864722509547e-09 total_time 727.0\n",
      "episode 3960, reward 1293.0, memory_length 2000, epsilon 2.517246969566334e-09 total_time 726.0\n",
      "Saving Model 3960\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3961, reward 1054.0, memory_length 2000, epsilon 2.5046921479284674e-09 total_time 726.0\n",
      "episode 3962, reward 1729.0, memory_length 2000, epsilon 2.492199943724751e-09 total_time 726.0\n",
      "episode 3963, reward 876.0, memory_length 2000, epsilon 2.4797700446494215e-09 total_time 725.0\n",
      "episode 3964, reward 1171.0, memory_length 2000, epsilon 2.4674021399543723e-09 total_time 727.0\n",
      "episode 3965, reward 1477.0, memory_length 2000, epsilon 2.455095920441332e-09 total_time 724.0\n",
      "episode 3966, reward 1530.0, memory_length 2000, epsilon 2.442851078454164e-09 total_time 721.0\n",
      "episode 3967, reward 894.0, memory_length 2000, epsilon 2.4306673078711974e-09 total_time 721.0\n",
      "episode 3968, reward 1174.0, memory_length 2000, epsilon 2.4185443040975255e-09 total_time 722.0\n",
      "episode 3969, reward 1121.0, memory_length 2000, epsilon 2.406481764057422e-09 total_time 727.0\n",
      "episode 3970, reward 1189.0, memory_length 2000, epsilon 2.394479386186749e-09 total_time 723.0\n",
      "Saving Model 3970\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3971, reward 1306.0, memory_length 2000, epsilon 2.3825368704254515e-09 total_time 721.0\n",
      "episode 3972, reward 1855.0, memory_length 2000, epsilon 2.370653918210005e-09 total_time 731.0\n",
      "episode 3973, reward 1304.0, memory_length 2000, epsilon 2.358830232465978e-09 total_time 722.0\n",
      "episode 3974, reward 1517.0, memory_length 2000, epsilon 2.3470655176006263e-09 total_time 721.0\n",
      "episode 3975, reward 1103.0, memory_length 2000, epsilon 2.3353594794954573e-09 total_time 727.0\n",
      "episode 3976, reward 1464.0, memory_length 2000, epsilon 2.3237118254989096e-09 total_time 727.0\n",
      "episode 3977, reward 1227.0, memory_length 2000, epsilon 2.312122264419018e-09 total_time 725.0\n",
      "episode 3978, reward 1083.0, memory_length 2000, epsilon 2.3005905065161674e-09 total_time 730.0\n",
      "episode 3979, reward 1616.0, memory_length 2000, epsilon 2.289116263495803e-09 total_time 724.0\n",
      "episode 3980, reward 1499.0, memory_length 2000, epsilon 2.2776992485012425e-09 total_time 726.0\n",
      "Saving Model 3980\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3981, reward 1047.0, memory_length 2000, epsilon 2.2663391761065327e-09 total_time 722.0\n",
      "episode 3982, reward 778.0, memory_length 2000, epsilon 2.2550357623092643e-09 total_time 721.0\n",
      "episode 3983, reward 1173.0, memory_length 2000, epsilon 2.243788724523504e-09 total_time 722.0\n",
      "episode 3984, reward 1189.0, memory_length 2000, epsilon 2.2325977815727123e-09 total_time 728.0\n",
      "episode 3985, reward 1763.0, memory_length 2000, epsilon 2.2214626536827494e-09 total_time 722.0\n",
      "episode 3986, reward 1430.0, memory_length 2000, epsilon 2.2103830624748296e-09 total_time 726.0\n",
      "episode 3987, reward 1114.0, memory_length 2000, epsilon 2.199358730958596e-09 total_time 722.0\n",
      "episode 3988, reward 773.0, memory_length 2000, epsilon 2.1883893835251785e-09 total_time 732.0\n",
      "episode 3989, reward 1258.0, memory_length 2000, epsilon 2.177474745940336e-09 total_time 722.0\n",
      "episode 3990, reward 930.0, memory_length 2000, epsilon 2.1666145453375514e-09 total_time 724.0\n",
      "Saving Model 3990\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 3991, reward 1101.0, memory_length 2000, epsilon 2.155808510211238e-09 total_time 724.0\n",
      "episode 3992, reward 1073.0, memory_length 2000, epsilon 2.145056370409969e-09 total_time 722.0\n",
      "episode 3993, reward 1174.0, memory_length 2000, epsilon 2.134357857129682e-09 total_time 723.0\n",
      "episode 3994, reward 1478.0, memory_length 2000, epsilon 2.123712702906988e-09 total_time 724.0\n",
      "episode 3995, reward 916.0, memory_length 2000, epsilon 2.113120641612469e-09 total_time 722.0\n",
      "episode 3996, reward 836.0, memory_length 2000, epsilon 2.1025814084440566e-09 total_time 724.0\n",
      "episode 3997, reward 1113.0, memory_length 2000, epsilon 2.0920947399203644e-09 total_time 722.0\n",
      "episode 3998, reward 865.0, memory_length 2000, epsilon 2.0816603738741263e-09 total_time 729.0\n",
      "episode 3999, reward 1497.0, memory_length 2000, epsilon 2.0712780494456625e-09 total_time 728.0\n",
      "episode 4000, reward 1064.0, memory_length 2000, epsilon 2.060947507076314e-09 total_time 726.0\n",
      "Saving Model 4000\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4001, reward 1176.0, memory_length 2000, epsilon 2.0506684885019834e-09 total_time 724.0\n",
      "episode 4002, reward 961.0, memory_length 2000, epsilon 2.040440736746664e-09 total_time 725.0\n",
      "episode 4003, reward 1127.0, memory_length 2000, epsilon 2.0302639961160433e-09 total_time 728.0\n",
      "episode 4004, reward 952.0, memory_length 2000, epsilon 2.0201380121910687e-09 total_time 727.0\n",
      "episode 4005, reward 935.0, memory_length 2000, epsilon 2.010062531821607e-09 total_time 721.0\n",
      "episode 4006, reward 927.0, memory_length 2000, epsilon 2.000037303120139e-09 total_time 722.0\n",
      "episode 4007, reward 955.0, memory_length 2000, epsilon 1.990062075455418e-09 total_time 727.0\n",
      "episode 4008, reward 765.0, memory_length 2000, epsilon 1.9801365994462323e-09 total_time 722.0\n",
      "episode 4009, reward 1136.0, memory_length 2000, epsilon 1.970260626955158e-09 total_time 725.0\n",
      "episode 4010, reward 1044.0, memory_length 2000, epsilon 1.960433911082382e-09 total_time 726.0\n",
      "Saving Model 4010\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4011, reward 1043.0, memory_length 2000, epsilon 1.9506562061594896e-09 total_time 728.0\n",
      "episode 4012, reward 640.0, memory_length 2000, epsilon 1.9409272677433473e-09 total_time 728.0\n",
      "episode 4013, reward 1381.0, memory_length 2000, epsilon 1.931246852609982e-09 total_time 722.0\n",
      "episode 4014, reward 1338.0, memory_length 2000, epsilon 1.9216147187485252e-09 total_time 736.0\n",
      "episode 4015, reward 1165.0, memory_length 2000, epsilon 1.912030625355121e-09 total_time 731.0\n",
      "episode 4016, reward 937.0, memory_length 2000, epsilon 1.9024943328269284e-09 total_time 721.0\n",
      "episode 4017, reward 1277.0, memory_length 2000, epsilon 1.8930056027561523e-09 total_time 721.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4018, reward 1477.0, memory_length 2000, epsilon 1.8835641979240386e-09 total_time 724.0\n",
      "episode 4019, reward 1322.0, memory_length 2000, epsilon 1.874169882294976e-09 total_time 722.0\n",
      "episode 4020, reward 1402.0, memory_length 2000, epsilon 1.8648224210105767e-09 total_time 728.0\n",
      "Saving Model 4020\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4021, reward 1198.0, memory_length 2000, epsilon 1.8555215803838358e-09 total_time 726.0\n",
      "episode 4022, reward 949.0, memory_length 2000, epsilon 1.8462671278932464e-09 total_time 727.0\n",
      "episode 4023, reward 1208.0, memory_length 2000, epsilon 1.8370588321770075e-09 total_time 722.0\n",
      "episode 4024, reward 1082.0, memory_length 2000, epsilon 1.8278964630272596e-09 total_time 731.0\n",
      "episode 4025, reward 1156.0, memory_length 2000, epsilon 1.8187797913842906e-09 total_time 725.0\n",
      "episode 4026, reward 1224.0, memory_length 2000, epsilon 1.8097085893308343e-09 total_time 725.0\n",
      "episode 4027, reward 1208.0, memory_length 2000, epsilon 1.8006826300863605e-09 total_time 725.0\n",
      "episode 4028, reward 1116.0, memory_length 2000, epsilon 1.7917016880014311e-09 total_time 726.0\n",
      "episode 4029, reward 927.0, memory_length 2000, epsilon 1.7827655385520197e-09 total_time 728.0\n",
      "episode 4030, reward 1713.0, memory_length 2000, epsilon 1.7738739583339179e-09 total_time 721.0\n",
      "Saving Model 4030\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4031, reward 939.0, memory_length 2000, epsilon 1.7650267250571702e-09 total_time 738.0\n",
      "episode 4032, reward 1330.0, memory_length 2000, epsilon 1.7562236175404777e-09 total_time 722.0\n",
      "episode 4033, reward 794.0, memory_length 2000, epsilon 1.7474644157056934e-09 total_time 724.0\n",
      "episode 4034, reward 927.0, memory_length 2000, epsilon 1.7387489005723096e-09 total_time 721.0\n",
      "episode 4035, reward 1169.0, memory_length 2000, epsilon 1.7300768542520063e-09 total_time 727.0\n",
      "episode 4036, reward 1509.0, memory_length 2000, epsilon 1.7214480599431672e-09 total_time 721.0\n",
      "episode 4037, reward 1545.0, memory_length 2000, epsilon 1.7128623019254857e-09 total_time 730.0\n",
      "episode 4038, reward 1243.0, memory_length 2000, epsilon 1.704319365554558e-09 total_time 721.0\n",
      "episode 4039, reward 1034.0, memory_length 2000, epsilon 1.6958190372565419e-09 total_time 724.0\n",
      "episode 4040, reward 1153.0, memory_length 2000, epsilon 1.687361104522781e-09 total_time 730.0\n",
      "Saving Model 4040\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4041, reward 918.0, memory_length 2000, epsilon 1.678945355904511e-09 total_time 724.0\n",
      "episode 4042, reward 1348.0, memory_length 2000, epsilon 1.6705715810075893e-09 total_time 725.0\n",
      "episode 4043, reward 1251.0, memory_length 2000, epsilon 1.6622395704872021e-09 total_time 722.0\n",
      "episode 4044, reward 1156.0, memory_length 2000, epsilon 1.653949116042652e-09 total_time 728.0\n",
      "episode 4045, reward 1141.0, memory_length 2000, epsilon 1.6457000104121403e-09 total_time 726.0\n",
      "episode 4046, reward 1620.0, memory_length 2000, epsilon 1.6374920473676087e-09 total_time 724.0\n",
      "episode 4047, reward 967.0, memory_length 2000, epsilon 1.629325021709547e-09 total_time 727.0\n",
      "episode 4048, reward 1441.0, memory_length 2000, epsilon 1.621198729261883e-09 total_time 722.0\n",
      "episode 4049, reward 1160.0, memory_length 2000, epsilon 1.613112966866894e-09 total_time 728.0\n",
      "episode 4050, reward 1576.0, memory_length 2000, epsilon 1.6050675323800932e-09 total_time 737.0\n",
      "Saving Model 4050\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4051, reward 1406.0, memory_length 2000, epsilon 1.5970622246651988e-09 total_time 730.0\n",
      "episode 4052, reward 1190.0, memory_length 2000, epsilon 1.5890968435890962e-09 total_time 723.0\n",
      "episode 4053, reward 1368.0, memory_length 2000, epsilon 1.5811711900168542e-09 total_time 730.0\n",
      "episode 4054, reward 812.0, memory_length 2000, epsilon 1.5732850658067154e-09 total_time 724.0\n",
      "episode 4055, reward 651.0, memory_length 2000, epsilon 1.5654382738051583e-09 total_time 725.0\n",
      "episode 4056, reward 1083.0, memory_length 2000, epsilon 1.557630617841985e-09 total_time 724.0\n",
      "episode 4057, reward 1412.0, memory_length 2000, epsilon 1.5498619027253846e-09 total_time 729.0\n",
      "episode 4058, reward 1305.0, memory_length 2000, epsilon 1.5421319342370743e-09 total_time 726.0\n",
      "episode 4059, reward 1115.0, memory_length 2000, epsilon 1.5344405191274338e-09 total_time 725.0\n",
      "episode 4060, reward 1603.0, memory_length 2000, epsilon 1.526787465110696e-09 total_time 724.0\n",
      "Saving Model 4060\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4061, reward 1178.0, memory_length 2000, epsilon 1.519172580860106e-09 total_time 723.0\n",
      "episode 4062, reward 1296.0, memory_length 2000, epsilon 1.5115956760031613e-09 total_time 725.0\n",
      "episode 4063, reward 1237.0, memory_length 2000, epsilon 1.5040565611168403e-09 total_time 727.0\n",
      "episode 4064, reward 1306.0, memory_length 2000, epsilon 1.4965550477228887e-09 total_time 726.0\n",
      "episode 4065, reward 1144.0, memory_length 2000, epsilon 1.489090948283076e-09 total_time 721.0\n",
      "episode 4066, reward 1588.0, memory_length 2000, epsilon 1.4816640761945219e-09 total_time 723.0\n",
      "episode 4067, reward 1245.0, memory_length 2000, epsilon 1.474274245785048e-09 total_time 726.0\n",
      "episode 4068, reward 714.0, memory_length 2000, epsilon 1.466921272308504e-09 total_time 721.0\n",
      "episode 4069, reward 1304.0, memory_length 2000, epsilon 1.45960497194017e-09 total_time 724.0\n",
      "episode 4070, reward 1057.0, memory_length 2000, epsilon 1.4523251617721503e-09 total_time 725.0\n",
      "Saving Model 4070\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4071, reward 1810.0, memory_length 2000, epsilon 1.4450816598088221e-09 total_time 725.0\n",
      "episode 4072, reward 1037.0, memory_length 2000, epsilon 1.4378742849622538e-09 total_time 726.0\n",
      "episode 4073, reward 1261.0, memory_length 2000, epsilon 1.430702857047694e-09 total_time 726.0\n",
      "episode 4074, reward 863.0, memory_length 2000, epsilon 1.4235671967790811e-09 total_time 730.0\n",
      "episode 4075, reward 1528.0, memory_length 2000, epsilon 1.416467125764532e-09 total_time 721.0\n",
      "episode 4076, reward 1734.0, memory_length 2000, epsilon 1.4094024665019013e-09 total_time 727.0\n",
      "episode 4077, reward 1206.0, memory_length 2000, epsilon 1.4023730423743346e-09 total_time 724.0\n",
      "episode 4078, reward 1513.0, memory_length 2000, epsilon 1.3953786776458726e-09 total_time 724.0\n",
      "episode 4079, reward 1292.0, memory_length 2000, epsilon 1.3884191974570276e-09 total_time 729.0\n",
      "episode 4080, reward 609.0, memory_length 2000, epsilon 1.381494427820428e-09 total_time 721.0\n",
      "Saving Model 4080\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4081, reward 497.0, memory_length 2000, epsilon 1.3746041956164815e-09 total_time 727.0\n",
      "episode 4082, reward 1452.0, memory_length 2000, epsilon 1.3677483285890195e-09 total_time 731.0\n",
      "episode 4083, reward 950.0, memory_length 2000, epsilon 1.360926655341009e-09 total_time 721.0\n",
      "episode 4084, reward 996.0, memory_length 2000, epsilon 1.3541390053302592e-09 total_time 722.0\n",
      "episode 4085, reward 1250.0, memory_length 2000, epsilon 1.3473852088651754e-09 total_time 726.0\n",
      "episode 4086, reward 1773.0, memory_length 2000, epsilon 1.3406650971004894e-09 total_time 725.0\n",
      "episode 4087, reward 1466.0, memory_length 2000, epsilon 1.3339785020330575e-09 total_time 722.0\n",
      "episode 4088, reward 953.0, memory_length 2000, epsilon 1.3273252564976496e-09 total_time 722.0\n",
      "episode 4089, reward 1151.0, memory_length 2000, epsilon 1.3207051941627907e-09 total_time 723.0\n",
      "episode 4090, reward 1166.0, memory_length 2000, epsilon 1.3141181495265727e-09 total_time 735.0\n",
      "Saving Model 4090\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4091, reward 973.0, memory_length 2000, epsilon 1.3075639579125316e-09 total_time 721.0\n",
      "episode 4092, reward 1388.0, memory_length 2000, epsilon 1.3010424554655455e-09 total_time 730.0\n",
      "episode 4093, reward 1134.0, memory_length 2000, epsilon 1.2945534791477087e-09 total_time 721.0\n",
      "episode 4094, reward 1459.0, memory_length 2000, epsilon 1.2880968667342753e-09 total_time 725.0\n",
      "episode 4095, reward 1218.0, memory_length 2000, epsilon 1.281672456809594e-09 total_time 731.0\n",
      "episode 4096, reward 1077.0, memory_length 2000, epsilon 1.2752800887630916e-09 total_time 729.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4097, reward 1235.0, memory_length 2000, epsilon 1.268919602785229e-09 total_time 726.0\n",
      "episode 4098, reward 1449.0, memory_length 2000, epsilon 1.2625908398635209e-09 total_time 723.0\n",
      "episode 4099, reward 1362.0, memory_length 2000, epsilon 1.2562936417785743e-09 total_time 726.0\n",
      "episode 4100, reward 1495.0, memory_length 2000, epsilon 1.250027851100104e-09 total_time 730.0\n",
      "Saving Model 4100\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4101, reward 1187.0, memory_length 2000, epsilon 1.243793311183017e-09 total_time 721.0\n",
      "episode 4102, reward 2103.0, memory_length 2000, epsilon 1.2375898661634858e-09 total_time 728.0\n",
      "episode 4103, reward 697.0, memory_length 2000, epsilon 1.2314173609550711e-09 total_time 728.0\n",
      "episode 4104, reward 1015.0, memory_length 2000, epsilon 1.2252756412448168e-09 total_time 722.0\n",
      "episode 4105, reward 810.0, memory_length 2000, epsilon 1.2191645534894055e-09 total_time 729.0\n",
      "episode 4106, reward 1477.0, memory_length 2000, epsilon 1.2130839449113341e-09 total_time 723.0\n",
      "episode 4107, reward 1395.0, memory_length 2000, epsilon 1.207033663495067e-09 total_time 724.0\n",
      "episode 4108, reward 1350.0, memory_length 2000, epsilon 1.2010135579832535e-09 total_time 727.0\n",
      "episode 4109, reward 812.0, memory_length 2000, epsilon 1.1950234778729386e-09 total_time 724.0\n",
      "episode 4110, reward 1343.0, memory_length 2000, epsilon 1.1890632734118153e-09 total_time 729.0\n",
      "Saving Model 4110\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4111, reward 1006.0, memory_length 2000, epsilon 1.1831327955944577e-09 total_time 721.0\n",
      "episode 4112, reward 957.0, memory_length 2000, epsilon 1.1772318961586116e-09 total_time 723.0\n",
      "episode 4113, reward 730.0, memory_length 2000, epsilon 1.1713604275814794e-09 total_time 723.0\n",
      "episode 4114, reward 976.0, memory_length 2000, epsilon 1.1655182430760495e-09 total_time 723.0\n",
      "episode 4115, reward 717.0, memory_length 2000, epsilon 1.1597051965874005e-09 total_time 724.0\n",
      "episode 4116, reward 1231.0, memory_length 2000, epsilon 1.1539211427890634e-09 total_time 722.0\n",
      "episode 4117, reward 1030.0, memory_length 2000, epsilon 1.1481659370794005e-09 total_time 723.0\n",
      "episode 4118, reward 1417.0, memory_length 2000, epsilon 1.1424394355779644e-09 total_time 727.0\n",
      "episode 4119, reward 1272.0, memory_length 2000, epsilon 1.1367414951219203e-09 total_time 721.0\n",
      "episode 4120, reward 1239.0, memory_length 2000, epsilon 1.1310719732624555e-09 total_time 727.0\n",
      "Saving Model 4120\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4121, reward 838.0, memory_length 2000, epsilon 1.1254307282612362e-09 total_time 722.0\n",
      "episode 4122, reward 1167.0, memory_length 2000, epsilon 1.1198176190868397e-09 total_time 724.0\n",
      "episode 4123, reward 1218.0, memory_length 2000, epsilon 1.1142325054112402e-09 total_time 728.0\n",
      "episode 4124, reward 796.0, memory_length 2000, epsilon 1.1086752476063129e-09 total_time 724.0\n",
      "episode 4125, reward 1171.0, memory_length 2000, epsilon 1.1031457067403196e-09 total_time 729.0\n",
      "episode 4126, reward 1114.0, memory_length 2000, epsilon 1.09764374457445e-09 total_time 727.0\n",
      "episode 4127, reward 1287.0, memory_length 2000, epsilon 1.09216922355936e-09 total_time 722.0\n",
      "episode 4128, reward 1082.0, memory_length 2000, epsilon 1.086722006831747e-09 total_time 726.0\n",
      "episode 4129, reward 1146.0, memory_length 2000, epsilon 1.0813019582109047e-09 total_time 726.0\n",
      "episode 4130, reward 1406.0, memory_length 2000, epsilon 1.0759089421953317e-09 total_time 723.0\n",
      "Saving Model 4130\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4131, reward 1592.0, memory_length 2000, epsilon 1.0705428239593542e-09 total_time 727.0\n",
      "episode 4132, reward 822.0, memory_length 2000, epsilon 1.0652034693497334e-09 total_time 726.0\n",
      "episode 4133, reward 1101.0, memory_length 2000, epsilon 1.0598907448823258e-09 total_time 723.0\n",
      "episode 4134, reward 1094.0, memory_length 2000, epsilon 1.054604517738739e-09 total_time 722.0\n",
      "episode 4135, reward 997.0, memory_length 2000, epsilon 1.049344655763027e-09 total_time 729.0\n",
      "episode 4136, reward 1387.0, memory_length 2000, epsilon 1.0441110274583623e-09 total_time 721.0\n",
      "episode 4137, reward 1381.0, memory_length 2000, epsilon 1.0389035019837649e-09 total_time 730.0\n",
      "episode 4138, reward 1091.0, memory_length 2000, epsilon 1.0337219491508228e-09 total_time 728.0\n",
      "episode 4139, reward 1028.0, memory_length 2000, epsilon 1.0285662394204534e-09 total_time 721.0\n",
      "episode 4140, reward 1459.0, memory_length 2000, epsilon 1.0234362438996404e-09 total_time 725.0\n",
      "Saving Model 4140\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4141, reward 1008.0, memory_length 2000, epsilon 1.0183318343382253e-09 total_time 728.0\n",
      "episode 4142, reward 1321.0, memory_length 2000, epsilon 1.0132528831257102e-09 total_time 721.0\n",
      "episode 4143, reward 858.0, memory_length 2000, epsilon 1.008199263288047e-09 total_time 722.0\n",
      "episode 4144, reward 996.0, memory_length 2000, epsilon 1.0031708484844767e-09 total_time 728.0\n",
      "episode 4145, reward 988.0, memory_length 2000, epsilon 9.981675130043632e-10 total_time 724.0\n",
      "episode 4146, reward 1220.0, memory_length 2000, epsilon 9.931891317640663e-10 total_time 729.0\n",
      "episode 4147, reward 759.0, memory_length 2000, epsilon 9.882355803037923e-10 total_time 729.0\n",
      "episode 4148, reward 1119.0, memory_length 2000, epsilon 9.83306734784493e-10 total_time 725.0\n",
      "episode 4149, reward 1610.0, memory_length 2000, epsilon 9.784024719847807e-10 total_time 725.0\n",
      "episode 4150, reward 1268.0, memory_length 2000, epsilon 9.735226692978265e-10 total_time 727.0\n",
      "Saving Model 4150\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4151, reward 1218.0, memory_length 2000, epsilon 9.686672047283092e-10 total_time 723.0\n",
      "episode 4152, reward 1194.0, memory_length 2000, epsilon 9.638359568893578e-10 total_time 730.0\n",
      "episode 4153, reward 865.0, memory_length 2000, epsilon 9.590288049995321e-10 total_time 735.0\n",
      "episode 4154, reward 818.0, memory_length 2000, epsilon 9.54245628879781e-10 total_time 730.0\n",
      "episode 4155, reward 1445.0, memory_length 2000, epsilon 9.494863089504487e-10 total_time 726.0\n",
      "episode 4156, reward 879.0, memory_length 2000, epsilon 9.447507262282959e-10 total_time 722.0\n",
      "episode 4157, reward 992.0, memory_length 2000, epsilon 9.40038762323505e-10 total_time 735.0\n",
      "episode 4158, reward 1042.0, memory_length 2000, epsilon 9.353502994367322e-10 total_time 733.0\n",
      "episode 4159, reward 1073.0, memory_length 2000, epsilon 9.306852203561581e-10 total_time 723.0\n",
      "episode 4160, reward 1116.0, memory_length 2000, epsilon 9.260434084545697e-10 total_time 722.0\n",
      "Saving Model 4160\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4161, reward 1177.0, memory_length 2000, epsilon 9.214247476864241e-10 total_time 723.0\n",
      "episode 4162, reward 1794.0, memory_length 2000, epsilon 9.168291225849615e-10 total_time 727.0\n",
      "episode 4163, reward 1414.0, memory_length 2000, epsilon 9.122564182593118e-10 total_time 723.0\n",
      "episode 4164, reward 1461.0, memory_length 2000, epsilon 9.077065203916353e-10 total_time 724.0\n",
      "episode 4165, reward 1667.0, memory_length 2000, epsilon 9.031793152342451e-10 total_time 722.0\n",
      "episode 4166, reward 1670.0, memory_length 2000, epsilon 8.98674689606773e-10 total_time 726.0\n",
      "episode 4167, reward 1403.0, memory_length 2000, epsilon 8.941925308933503e-10 total_time 725.0\n",
      "episode 4168, reward 1393.0, memory_length 2000, epsilon 8.897327270397725e-10 total_time 729.0\n",
      "episode 4169, reward 1034.0, memory_length 2000, epsilon 8.85295166550711e-10 total_time 729.0\n",
      "episode 4170, reward 1100.0, memory_length 2000, epsilon 8.808797384869193e-10 total_time 722.0\n",
      "Saving Model 4170\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4171, reward 1383.0, memory_length 2000, epsilon 8.764863324624721e-10 total_time 721.0\n",
      "episode 4172, reward 989.0, memory_length 2000, epsilon 8.721148386419868e-10 total_time 726.0\n",
      "episode 4173, reward 1580.0, memory_length 2000, epsilon 8.677651477378873e-10 total_time 735.0\n",
      "episode 4174, reward 997.0, memory_length 2000, epsilon 8.634371510076803e-10 total_time 738.0\n",
      "episode 4175, reward 812.0, memory_length 2000, epsilon 8.591307402512192e-10 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4176, reward 1155.0, memory_length 2000, epsilon 8.548458078080108e-10 total_time 730.0\n",
      "episode 4177, reward 1161.0, memory_length 2000, epsilon 8.505822465545179e-10 total_time 721.0\n",
      "episode 4178, reward 812.0, memory_length 2000, epsilon 8.463399499014931e-10 total_time 724.0\n",
      "episode 4179, reward 890.0, memory_length 2000, epsilon 8.421188117912961e-10 total_time 723.0\n",
      "episode 4180, reward 1338.0, memory_length 2000, epsilon 8.379187266952512e-10 total_time 727.0\n",
      "Saving Model 4180\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4181, reward 1430.0, memory_length 2000, epsilon 8.337395896110183e-10 total_time 730.0\n",
      "episode 4182, reward 1506.0, memory_length 2000, epsilon 8.295812960599497e-10 total_time 722.0\n",
      "episode 4183, reward 1582.0, memory_length 2000, epsilon 8.2544374208449e-10 total_time 731.0\n",
      "episode 4184, reward 890.0, memory_length 2000, epsilon 8.213268242455713e-10 total_time 724.0\n",
      "episode 4185, reward 801.0, memory_length 2000, epsilon 8.172304396200391e-10 total_time 730.0\n",
      "episode 4186, reward 1149.0, memory_length 2000, epsilon 8.131544857980615e-10 total_time 723.0\n",
      "episode 4187, reward 874.0, memory_length 2000, epsilon 8.090988608805808e-10 total_time 721.0\n",
      "episode 4188, reward 1314.0, memory_length 2000, epsilon 8.050634634767599e-10 total_time 728.0\n",
      "episode 4189, reward 1187.0, memory_length 2000, epsilon 8.010481927014591e-10 total_time 728.0\n",
      "episode 4190, reward 1179.0, memory_length 2000, epsilon 7.970529481726971e-10 total_time 724.0\n",
      "Saving Model 4190\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4191, reward 1411.0, memory_length 2000, epsilon 7.930776300091499e-10 total_time 729.0\n",
      "episode 4192, reward 1042.0, memory_length 2000, epsilon 7.891221388276617e-10 total_time 724.0\n",
      "episode 4193, reward 1111.0, memory_length 2000, epsilon 7.851863757407446e-10 total_time 733.0\n",
      "episode 4194, reward 1021.0, memory_length 2000, epsilon 7.81270242354116e-10 total_time 723.0\n",
      "episode 4195, reward 799.0, memory_length 2000, epsilon 7.773736407642348e-10 total_time 728.0\n",
      "episode 4196, reward 1131.0, memory_length 2000, epsilon 7.734964735558636e-10 total_time 729.0\n",
      "episode 4197, reward 1218.0, memory_length 2000, epsilon 7.696386437996177e-10 total_time 723.0\n",
      "episode 4198, reward 1645.0, memory_length 2000, epsilon 7.658000550495494e-10 total_time 722.0\n",
      "episode 4199, reward 1525.0, memory_length 2000, epsilon 7.619806113407454e-10 total_time 722.0\n",
      "episode 4200, reward 1546.0, memory_length 2000, epsilon 7.581802171869116e-10 total_time 721.0\n",
      "Saving Model 4200\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4201, reward 1387.0, memory_length 2000, epsilon 7.54398777577996e-10 total_time 726.0\n",
      "episode 4202, reward 1439.0, memory_length 2000, epsilon 7.506361979778088e-10 total_time 724.0\n",
      "episode 4203, reward 1057.0, memory_length 2000, epsilon 7.468923843216694e-10 total_time 721.0\n",
      "episode 4204, reward 1030.0, memory_length 2000, epsilon 7.431672430140386e-10 total_time 722.0\n",
      "episode 4205, reward 1138.0, memory_length 2000, epsilon 7.394606809261873e-10 total_time 721.0\n",
      "episode 4206, reward 1223.0, memory_length 2000, epsilon 7.357726053938753e-10 total_time 727.0\n",
      "episode 4207, reward 1453.0, memory_length 2000, epsilon 7.321029242150199e-10 total_time 724.0\n",
      "episode 4208, reward 1996.0, memory_length 2000, epsilon 7.284515456474e-10 total_time 722.0\n",
      "episode 4209, reward 946.0, memory_length 2000, epsilon 7.24818378406359e-10 total_time 723.0\n",
      "episode 4210, reward 1322.0, memory_length 2000, epsilon 7.212033316625317e-10 total_time 722.0\n",
      "Saving Model 4210\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4211, reward 933.0, memory_length 2000, epsilon 7.176063150395588e-10 total_time 729.0\n",
      "episode 4212, reward 1311.0, memory_length 2000, epsilon 7.14027238611837e-10 total_time 727.0\n",
      "episode 4213, reward 1184.0, memory_length 2000, epsilon 7.104660129022671e-10 total_time 721.0\n",
      "episode 4214, reward 1259.0, memory_length 2000, epsilon 7.069225488800257e-10 total_time 724.0\n",
      "episode 4215, reward 1196.0, memory_length 2000, epsilon 7.033967579583252e-10 total_time 729.0\n",
      "episode 4216, reward 1600.0, memory_length 2000, epsilon 6.998885519922065e-10 total_time 726.0\n",
      "episode 4217, reward 1441.0, memory_length 2000, epsilon 6.963978432763427e-10 total_time 726.0\n",
      "episode 4218, reward 1242.0, memory_length 2000, epsilon 6.929245445428314e-10 total_time 726.0\n",
      "episode 4219, reward 1645.0, memory_length 2000, epsilon 6.894685689590235e-10 total_time 728.0\n",
      "episode 4220, reward 1151.0, memory_length 2000, epsilon 6.860298301253472e-10 total_time 725.0\n",
      "Saving Model 4220\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4221, reward 1403.0, memory_length 2000, epsilon 6.82608242073157e-10 total_time 725.0\n",
      "episode 4222, reward 1238.0, memory_length 2000, epsilon 6.792037192625713e-10 total_time 722.0\n",
      "episode 4223, reward 1070.0, memory_length 2000, epsilon 6.758161765803399e-10 total_time 724.0\n",
      "episode 4224, reward 1236.0, memory_length 2000, epsilon 6.724455293377243e-10 total_time 723.0\n",
      "episode 4225, reward 911.0, memory_length 2000, epsilon 6.690916932683652e-10 total_time 724.0\n",
      "episode 4226, reward 1060.0, memory_length 2000, epsilon 6.657545845261866e-10 total_time 725.0\n",
      "episode 4227, reward 973.0, memory_length 2000, epsilon 6.624341196832933e-10 total_time 722.0\n",
      "episode 4228, reward 1081.0, memory_length 2000, epsilon 6.591302157278965e-10 total_time 723.0\n",
      "episode 4229, reward 973.0, memory_length 2000, epsilon 6.558427900622223e-10 total_time 722.0\n",
      "episode 4230, reward 1620.0, memory_length 2000, epsilon 6.525717605004561e-10 total_time 731.0\n",
      "Saving Model 4230\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4231, reward 1392.0, memory_length 2000, epsilon 6.493170452666927e-10 total_time 726.0\n",
      "episode 4232, reward 1167.0, memory_length 2000, epsilon 6.460785629928798e-10 total_time 735.0\n",
      "episode 4233, reward 1413.0, memory_length 2000, epsilon 6.428562327167915e-10 total_time 730.0\n",
      "episode 4234, reward 1824.0, memory_length 2000, epsilon 6.39649973880001e-10 total_time 724.0\n",
      "episode 4235, reward 952.0, memory_length 2000, epsilon 6.364597063258749e-10 total_time 723.0\n",
      "episode 4236, reward 646.0, memory_length 2000, epsilon 6.33285350297556e-10 total_time 729.0\n",
      "episode 4237, reward 1266.0, memory_length 2000, epsilon 6.301268264359781e-10 total_time 727.0\n",
      "episode 4238, reward 1215.0, memory_length 2000, epsilon 6.269840557778779e-10 total_time 724.0\n",
      "episode 4239, reward 1175.0, memory_length 2000, epsilon 6.2385695975383e-10 total_time 725.0\n",
      "episode 4240, reward 1035.0, memory_length 2000, epsilon 6.207454601862685e-10 total_time 727.0\n",
      "Saving Model 4240\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4241, reward 902.0, memory_length 2000, epsilon 6.176494792875398e-10 total_time 729.0\n",
      "episode 4242, reward 1524.0, memory_length 2000, epsilon 6.145689396579649e-10 total_time 724.0\n",
      "episode 4243, reward 1227.0, memory_length 2000, epsilon 6.115037642838902e-10 total_time 723.0\n",
      "episode 4244, reward 1302.0, memory_length 2000, epsilon 6.084538765357719e-10 total_time 722.0\n",
      "episode 4245, reward 1305.0, memory_length 2000, epsilon 6.05419200166255e-10 total_time 731.0\n",
      "episode 4246, reward 1099.0, memory_length 2000, epsilon 6.023996593082768e-10 total_time 721.0\n",
      "episode 4247, reward 922.0, memory_length 2000, epsilon 5.993951784731563e-10 total_time 721.0\n",
      "episode 4248, reward 966.0, memory_length 2000, epsilon 5.96405682548714e-10 total_time 722.0\n",
      "episode 4249, reward 901.0, memory_length 2000, epsilon 5.934310967974004e-10 total_time 727.0\n",
      "episode 4250, reward 1180.0, memory_length 2000, epsilon 5.904713468544145e-10 total_time 721.0\n",
      "Saving Model 4250\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4251, reward 1811.0, memory_length 2000, epsilon 5.875263587258538e-10 total_time 723.0\n",
      "episode 4252, reward 1348.0, memory_length 2000, epsilon 5.845960587868596e-10 total_time 728.0\n",
      "episode 4253, reward 914.0, memory_length 2000, epsilon 5.816803737797847e-10 total_time 728.0\n",
      "episode 4254, reward 1509.0, memory_length 2000, epsilon 5.787792308123503e-10 total_time 724.0\n",
      "episode 4255, reward 1190.0, memory_length 2000, epsilon 5.758925573558289e-10 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4256, reward 1242.0, memory_length 2000, epsilon 5.730202812432378e-10 total_time 722.0\n",
      "episode 4257, reward 1139.0, memory_length 2000, epsilon 5.701623306675228e-10 total_time 729.0\n",
      "episode 4258, reward 718.0, memory_length 2000, epsilon 5.673186341797703e-10 total_time 721.0\n",
      "episode 4259, reward 1511.0, memory_length 2000, epsilon 5.644891206874183e-10 total_time 726.0\n",
      "episode 4260, reward 1970.0, memory_length 2000, epsilon 5.616737194524858e-10 total_time 725.0\n",
      "Saving Model 4260\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4261, reward 1445.0, memory_length 2000, epsilon 5.588723600897936e-10 total_time 723.0\n",
      "episode 4262, reward 1144.0, memory_length 2000, epsilon 5.560849725652116e-10 total_time 725.0\n",
      "episode 4263, reward 1138.0, memory_length 2000, epsilon 5.533114871939045e-10 total_time 722.0\n",
      "episode 4264, reward 1044.0, memory_length 2000, epsilon 5.505518346385975e-10 total_time 722.0\n",
      "episode 4265, reward 1062.0, memory_length 2000, epsilon 5.478059459078312e-10 total_time 726.0\n",
      "episode 4266, reward 630.0, memory_length 2000, epsilon 5.450737523542421e-10 total_time 727.0\n",
      "episode 4267, reward 1353.0, memory_length 2000, epsilon 5.423551856728531e-10 total_time 733.0\n",
      "episode 4268, reward 1436.0, memory_length 2000, epsilon 5.396501778993537e-10 total_time 722.0\n",
      "episode 4269, reward 1385.0, memory_length 2000, epsilon 5.369586614084085e-10 total_time 723.0\n",
      "episode 4270, reward 1125.0, memory_length 2000, epsilon 5.342805689119631e-10 total_time 723.0\n",
      "Saving Model 4270\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4271, reward 985.0, memory_length 2000, epsilon 5.316158334575698e-10 total_time 728.0\n",
      "episode 4272, reward 1121.0, memory_length 2000, epsilon 5.289643884267011e-10 total_time 728.0\n",
      "episode 4273, reward 964.0, memory_length 2000, epsilon 5.263261675330916e-10 total_time 728.0\n",
      "episode 4274, reward 1404.0, memory_length 2000, epsilon 5.23701104821085e-10 total_time 725.0\n",
      "episode 4275, reward 1422.0, memory_length 2000, epsilon 5.21089134663975e-10 total_time 724.0\n",
      "episode 4276, reward 1082.0, memory_length 2000, epsilon 5.184901917623719e-10 total_time 721.0\n",
      "episode 4277, reward 1415.0, memory_length 2000, epsilon 5.159042111425656e-10 total_time 723.0\n",
      "episode 4278, reward 1548.0, memory_length 2000, epsilon 5.133311281549097e-10 total_time 722.0\n",
      "episode 4279, reward 1270.0, memory_length 2000, epsilon 5.107708784721938e-10 total_time 721.0\n",
      "episode 4280, reward 1183.0, memory_length 2000, epsilon 5.082233980880405e-10 total_time 727.0\n",
      "Saving Model 4280\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4281, reward 1216.0, memory_length 2000, epsilon 5.056886233153111e-10 total_time 724.0\n",
      "episode 4282, reward 1485.0, memory_length 2000, epsilon 5.031664907845028e-10 total_time 729.0\n",
      "episode 4283, reward 1391.0, memory_length 2000, epsilon 5.006569374421705e-10 total_time 726.0\n",
      "episode 4284, reward 1101.0, memory_length 2000, epsilon 4.981599005493485e-10 total_time 722.0\n",
      "episode 4285, reward 706.0, memory_length 2000, epsilon 4.956753176799877e-10 total_time 729.0\n",
      "episode 4286, reward 971.0, memory_length 2000, epsilon 4.932031267193855e-10 total_time 726.0\n",
      "episode 4287, reward 1298.0, memory_length 2000, epsilon 4.907432658626389e-10 total_time 723.0\n",
      "episode 4288, reward 1022.0, memory_length 2000, epsilon 4.882956736130968e-10 total_time 721.0\n",
      "episode 4289, reward 1330.0, memory_length 2000, epsilon 4.858602887808287e-10 total_time 723.0\n",
      "episode 4290, reward 1476.0, memory_length 2000, epsilon 4.834370504810855e-10 total_time 725.0\n",
      "Saving Model 4290\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4291, reward 1435.0, memory_length 2000, epsilon 4.810258981327814e-10 total_time 725.0\n",
      "episode 4292, reward 965.0, memory_length 2000, epsilon 4.78626771456986e-10 total_time 724.0\n",
      "episode 4293, reward 1490.0, memory_length 2000, epsilon 4.762396104754054e-10 total_time 725.0\n",
      "episode 4294, reward 1212.0, memory_length 2000, epsilon 4.73864355508891e-10 total_time 721.0\n",
      "episode 4295, reward 1197.0, memory_length 2000, epsilon 4.71500947175943e-10 total_time 732.0\n",
      "episode 4296, reward 1518.0, memory_length 2000, epsilon 4.691493263912335e-10 total_time 722.0\n",
      "episode 4297, reward 1526.0, memory_length 2000, epsilon 4.668094343641186e-10 total_time 723.0\n",
      "episode 4298, reward 847.0, memory_length 2000, epsilon 4.644812125971742e-10 total_time 723.0\n",
      "episode 4299, reward 1066.0, memory_length 2000, epsilon 4.6216460288473805e-10 total_time 721.0\n",
      "episode 4300, reward 1604.0, memory_length 2000, epsilon 4.5985954731144516e-10 total_time 725.0\n",
      "Saving Model 4300\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4301, reward 1467.0, memory_length 2000, epsilon 4.5756598825078605e-10 total_time 723.0\n",
      "episode 4302, reward 1357.0, memory_length 2000, epsilon 4.552838683636633e-10 total_time 725.0\n",
      "episode 4303, reward 1230.0, memory_length 2000, epsilon 4.5301313059696385e-10 total_time 722.0\n",
      "episode 4304, reward 1022.0, memory_length 2000, epsilon 4.5075371818212383e-10 total_time 724.0\n",
      "episode 4305, reward 1400.0, memory_length 2000, epsilon 4.485055746337135e-10 total_time 725.0\n",
      "episode 4306, reward 1293.0, memory_length 2000, epsilon 4.462686437480303e-10 total_time 723.0\n",
      "episode 4307, reward 1349.0, memory_length 2000, epsilon 4.44042869601684e-10 total_time 725.0\n",
      "episode 4308, reward 1236.0, memory_length 2000, epsilon 4.41828196550205e-10 total_time 728.0\n",
      "episode 4309, reward 1145.0, memory_length 2000, epsilon 4.396245692266501e-10 total_time 727.0\n",
      "episode 4310, reward 1442.0, memory_length 2000, epsilon 4.3743193254022454e-10 total_time 722.0\n",
      "Saving Model 4310\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4311, reward 848.0, memory_length 2000, epsilon 4.352502316748954e-10 total_time 727.0\n",
      "episode 4312, reward 1303.0, memory_length 2000, epsilon 4.3307941208802744e-10 total_time 722.0\n",
      "episode 4313, reward 1360.0, memory_length 2000, epsilon 4.3091941950901645e-10 total_time 722.0\n",
      "episode 4314, reward 1313.0, memory_length 2000, epsilon 4.2877019993793837e-10 total_time 721.0\n",
      "episode 4315, reward 1465.0, memory_length 2000, epsilon 4.2663169964419056e-10 total_time 725.0\n",
      "episode 4316, reward 1389.0, memory_length 2000, epsilon 4.2450386516515274e-10 total_time 722.0\n",
      "episode 4317, reward 1081.0, memory_length 2000, epsilon 4.2238664330485523e-10 total_time 721.0\n",
      "episode 4318, reward 1228.0, memory_length 2000, epsilon 4.202799811326396e-10 total_time 725.0\n",
      "episode 4319, reward 923.0, memory_length 2000, epsilon 4.1818382598184186e-10 total_time 724.0\n",
      "episode 4320, reward 1340.0, memory_length 2000, epsilon 4.1609812544847263e-10 total_time 729.0\n",
      "Saving Model 4320\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4321, reward 1577.0, memory_length 2000, epsilon 4.1402282738991293e-10 total_time 722.0\n",
      "episode 4322, reward 1146.0, memory_length 2000, epsilon 4.1195787992360166e-10 total_time 727.0\n",
      "episode 4323, reward 1017.0, memory_length 2000, epsilon 4.0990323142574315e-10 total_time 727.0\n",
      "episode 4324, reward 687.0, memory_length 2000, epsilon 4.0785883053002087e-10 total_time 729.0\n",
      "episode 4325, reward 1317.0, memory_length 2000, epsilon 4.0582462612630456e-10 total_time 721.0\n",
      "episode 4326, reward 867.0, memory_length 2000, epsilon 4.038005673593781e-10 total_time 728.0\n",
      "episode 4327, reward 1512.0, memory_length 2000, epsilon 4.0178660362766553e-10 total_time 728.0\n",
      "episode 4328, reward 1607.0, memory_length 2000, epsilon 3.9978268458197136e-10 total_time 729.0\n",
      "episode 4329, reward 1629.0, memory_length 2000, epsilon 3.9778876012421387e-10 total_time 724.0\n",
      "episode 4330, reward 999.0, memory_length 2000, epsilon 3.9580478040617625e-10 total_time 726.0\n",
      "Saving Model 4330\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4331, reward 1414.0, memory_length 2000, epsilon 3.93830695828265e-10 total_time 725.0\n",
      "episode 4332, reward 763.0, memory_length 2000, epsilon 3.9186645703826153e-10 total_time 723.0\n",
      "episode 4333, reward 1260.0, memory_length 2000, epsilon 3.8991201493009376e-10 total_time 722.0\n",
      "episode 4334, reward 1040.0, memory_length 2000, epsilon 3.8796732064260576e-10 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4335, reward 975.0, memory_length 2000, epsilon 3.860323255583419e-10 total_time 724.0\n",
      "episode 4336, reward 1269.0, memory_length 2000, epsilon 3.8410698130232274e-10 total_time 723.0\n",
      "episode 4337, reward 1285.0, memory_length 2000, epsilon 3.821912397408418e-10 total_time 722.0\n",
      "episode 4338, reward 1685.0, memory_length 2000, epsilon 3.802850529802588e-10 total_time 726.0\n",
      "episode 4339, reward 1260.0, memory_length 2000, epsilon 3.7838837336580825e-10 total_time 724.0\n",
      "episode 4340, reward 1052.0, memory_length 2000, epsilon 3.765011534803996e-10 total_time 727.0\n",
      "Saving Model 4340\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4341, reward 1366.0, memory_length 2000, epsilon 3.74623346143436e-10 total_time 721.0\n",
      "episode 4342, reward 890.0, memory_length 2000, epsilon 3.7275490440963904e-10 total_time 727.0\n",
      "episode 4343, reward 926.0, memory_length 2000, epsilon 3.708957815678666e-10 total_time 723.0\n",
      "episode 4344, reward 1387.0, memory_length 2000, epsilon 3.690459311399509e-10 total_time 726.0\n",
      "episode 4345, reward 1086.0, memory_length 2000, epsilon 3.672053068795335e-10 total_time 722.0\n",
      "episode 4346, reward 1428.0, memory_length 2000, epsilon 3.653738627709147e-10 total_time 727.0\n",
      "episode 4347, reward 1406.0, memory_length 2000, epsilon 3.6355155302789513e-10 total_time 725.0\n",
      "episode 4348, reward 1244.0, memory_length 2000, epsilon 3.617383320926349e-10 total_time 726.0\n",
      "episode 4349, reward 1398.0, memory_length 2000, epsilon 3.5993415463451885e-10 total_time 726.0\n",
      "episode 4350, reward 1154.0, memory_length 2000, epsilon 3.581389755490153e-10 total_time 731.0\n",
      "Saving Model 4350\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4351, reward 1062.0, memory_length 2000, epsilon 3.5635274995655344e-10 total_time 724.0\n",
      "episode 4352, reward 1120.0, memory_length 2000, epsilon 3.545754332013993e-10 total_time 721.0\n",
      "episode 4353, reward 1083.0, memory_length 2000, epsilon 3.52806980850544e-10 total_time 729.0\n",
      "episode 4354, reward 1824.0, memory_length 2000, epsilon 3.510473486925854e-10 total_time 727.0\n",
      "episode 4355, reward 1916.0, memory_length 2000, epsilon 3.492964927366265e-10 total_time 721.0\n",
      "episode 4356, reward 1109.0, memory_length 2000, epsilon 3.475543692111798e-10 total_time 727.0\n",
      "episode 4357, reward 1234.0, memory_length 2000, epsilon 3.4582093456306524e-10 total_time 726.0\n",
      "episode 4358, reward 1309.0, memory_length 2000, epsilon 3.4409614545632625e-10 total_time 723.0\n",
      "episode 4359, reward 910.0, memory_length 2000, epsilon 3.4237995877114414e-10 total_time 724.0\n",
      "episode 4360, reward 1484.0, memory_length 2000, epsilon 3.406723316027648e-10 total_time 721.0\n",
      "Saving Model 4360\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4361, reward 1159.0, memory_length 2000, epsilon 3.3897322126041893e-10 total_time 721.0\n",
      "episode 4362, reward 1182.0, memory_length 2000, epsilon 3.3728258526625945e-10 total_time 729.0\n",
      "episode 4363, reward 1170.0, memory_length 2000, epsilon 3.356003813542972e-10 total_time 725.0\n",
      "episode 4364, reward 1472.0, memory_length 2000, epsilon 3.339265674693492e-10 total_time 724.0\n",
      "episode 4365, reward 1102.0, memory_length 2000, epsilon 3.3226110176598e-10 total_time 723.0\n",
      "episode 4366, reward 1481.0, memory_length 2000, epsilon 3.3060394260745905e-10 total_time 721.0\n",
      "episode 4367, reward 953.0, memory_length 2000, epsilon 3.289550485647234e-10 total_time 721.0\n",
      "episode 4368, reward 1711.0, memory_length 2000, epsilon 3.2731437841533495e-10 total_time 728.0\n",
      "episode 4369, reward 1195.0, memory_length 2000, epsilon 3.256818911424545e-10 total_time 727.0\n",
      "episode 4370, reward 1378.0, memory_length 2000, epsilon 3.2405754593381416e-10 total_time 721.0\n",
      "Saving Model 4370\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4371, reward 1199.0, memory_length 2000, epsilon 3.224413021807013e-10 total_time 726.0\n",
      "episode 4372, reward 1254.0, memory_length 2000, epsilon 3.2083311947693674e-10 total_time 722.0\n",
      "episode 4373, reward 1250.0, memory_length 2000, epsilon 3.1923295761786805e-10 total_time 721.0\n",
      "episode 4374, reward 1832.0, memory_length 2000, epsilon 3.1764077659936766e-10 total_time 730.0\n",
      "episode 4375, reward 1447.0, memory_length 2000, epsilon 3.160565366168261e-10 total_time 723.0\n",
      "episode 4376, reward 1189.0, memory_length 2000, epsilon 3.1448019806416125e-10 total_time 723.0\n",
      "episode 4377, reward 1143.0, memory_length 2000, epsilon 3.129117215328261e-10 total_time 725.0\n",
      "episode 4378, reward 885.0, memory_length 2000, epsilon 3.1135106781082776e-10 total_time 721.0\n",
      "episode 4379, reward 642.0, memory_length 2000, epsilon 3.09798197881741e-10 total_time 722.0\n",
      "episode 4380, reward 1416.0, memory_length 2000, epsilon 3.082530729237355e-10 total_time 726.0\n",
      "Saving Model 4380\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4381, reward 1083.0, memory_length 2000, epsilon 3.067156543086091e-10 total_time 721.0\n",
      "episode 4382, reward 1337.0, memory_length 2000, epsilon 3.0518590360081517e-10 total_time 740.0\n",
      "episode 4383, reward 1429.0, memory_length 2000, epsilon 3.036637825565063e-10 total_time 730.0\n",
      "episode 4384, reward 1256.0, memory_length 2000, epsilon 3.0214925312257616e-10 total_time 723.0\n",
      "episode 4385, reward 941.0, memory_length 2000, epsilon 3.0064227743571216e-10 total_time 727.0\n",
      "episode 4386, reward 727.0, memory_length 2000, epsilon 2.991428178214424e-10 total_time 731.0\n",
      "episode 4387, reward 1146.0, memory_length 2000, epsilon 2.9765083679319863e-10 total_time 723.0\n",
      "episode 4388, reward 1629.0, memory_length 2000, epsilon 2.961662970513763e-10 total_time 724.0\n",
      "episode 4389, reward 1410.0, memory_length 2000, epsilon 2.9468916148240663e-10 total_time 723.0\n",
      "episode 4390, reward 894.0, memory_length 2000, epsilon 2.932193931578224e-10 total_time 724.0\n",
      "Saving Model 4390\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4391, reward 1044.0, memory_length 2000, epsilon 2.9175695533333793e-10 total_time 721.0\n",
      "episode 4392, reward 1431.0, memory_length 2000, epsilon 2.9030181144793357e-10 total_time 733.0\n",
      "episode 4393, reward 1151.0, memory_length 2000, epsilon 2.888539251229352e-10 total_time 727.0\n",
      "episode 4394, reward 1003.0, memory_length 2000, epsilon 2.8741326016110954e-10 total_time 725.0\n",
      "episode 4395, reward 711.0, memory_length 2000, epsilon 2.859797805457562e-10 total_time 724.0\n",
      "episode 4396, reward 1169.0, memory_length 2000, epsilon 2.8455345043981243e-10 total_time 723.0\n",
      "episode 4397, reward 1743.0, memory_length 2000, epsilon 2.8313423418495007e-10 total_time 725.0\n",
      "episode 4398, reward 1077.0, memory_length 2000, epsilon 2.8172209630068796e-10 total_time 724.0\n",
      "episode 4399, reward 1317.0, memory_length 2000, epsilon 2.8031700148350743e-10 total_time 726.0\n",
      "episode 4400, reward 957.0, memory_length 2000, epsilon 2.7891891460596376e-10 total_time 723.0\n",
      "Saving Model 4400\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4401, reward 1548.0, memory_length 2000, epsilon 2.7752780071581237e-10 total_time 730.0\n",
      "episode 4402, reward 1140.0, memory_length 2000, epsilon 2.7614362503513244e-10 total_time 721.0\n",
      "episode 4403, reward 964.0, memory_length 2000, epsilon 2.747663529594618e-10 total_time 722.0\n",
      "episode 4404, reward 1077.0, memory_length 2000, epsilon 2.73395950056926e-10 total_time 722.0\n",
      "episode 4405, reward 1426.0, memory_length 2000, epsilon 2.7203238206738e-10 total_time 724.0\n",
      "episode 4406, reward 909.0, memory_length 2000, epsilon 2.70675614901555e-10 total_time 721.0\n",
      "episode 4407, reward 916.0, memory_length 2000, epsilon 2.6932561464020026e-10 total_time 722.0\n",
      "episode 4408, reward 1514.0, memory_length 2000, epsilon 2.679823475332389e-10 total_time 723.0\n",
      "episode 4409, reward 1357.0, memory_length 2000, epsilon 2.6664577999892236e-10 total_time 722.0\n",
      "episode 4410, reward 901.0, memory_length 2000, epsilon 2.653158786229945e-10 total_time 728.0\n",
      "Saving Model 4410\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4411, reward 1240.0, memory_length 2000, epsilon 2.6399261015785086e-10 total_time 727.0\n",
      "episode 4412, reward 1528.0, memory_length 2000, epsilon 2.6267594152171074e-10 total_time 729.0\n",
      "episode 4413, reward 1297.0, memory_length 2000, epsilon 2.6136583979778875e-10 total_time 728.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4414, reward 1009.0, memory_length 2000, epsilon 2.600622722334755e-10 total_time 724.0\n",
      "episode 4415, reward 1017.0, memory_length 2000, epsilon 2.58765206239513e-10 total_time 728.0\n",
      "episode 4416, reward 1561.0, memory_length 2000, epsilon 2.574746093891829e-10 total_time 726.0\n",
      "episode 4417, reward 1177.0, memory_length 2000, epsilon 2.561904494174986e-10 total_time 722.0\n",
      "episode 4418, reward 1490.0, memory_length 2000, epsilon 2.54912694220393e-10 total_time 723.0\n",
      "episode 4419, reward 1247.0, memory_length 2000, epsilon 2.5364131185391964e-10 total_time 732.0\n",
      "episode 4420, reward 1642.0, memory_length 2000, epsilon 2.5237627053345223e-10 total_time 728.0\n",
      "Saving Model 4420\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4421, reward 1224.0, memory_length 2000, epsilon 2.5111753863289364e-10 total_time 728.0\n",
      "episode 4422, reward 1382.0, memory_length 2000, epsilon 2.498650846838799e-10 total_time 722.0\n",
      "episode 4423, reward 1654.0, memory_length 2000, epsilon 2.4861887737499624e-10 total_time 729.0\n",
      "episode 4424, reward 931.0, memory_length 2000, epsilon 2.473788855509967e-10 total_time 726.0\n",
      "episode 4425, reward 1075.0, memory_length 2000, epsilon 2.461450782120203e-10 total_time 726.0\n",
      "episode 4426, reward 861.0, memory_length 2000, epsilon 2.4491742451281923e-10 total_time 733.0\n",
      "episode 4427, reward 694.0, memory_length 2000, epsilon 2.436958937619863e-10 total_time 726.0\n",
      "episode 4428, reward 982.0, memory_length 2000, epsilon 2.4248045542119074e-10 total_time 722.0\n",
      "episode 4429, reward 1259.0, memory_length 2000, epsilon 2.4127107910440994e-10 total_time 725.0\n",
      "episode 4430, reward 975.0, memory_length 2000, epsilon 2.4006773457717207e-10 total_time 725.0\n",
      "Saving Model 4430\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4431, reward 966.0, memory_length 2000, epsilon 2.388703917558031e-10 total_time 721.0\n",
      "episode 4432, reward 1405.0, memory_length 2000, epsilon 2.376790207066691e-10 total_time 731.0\n",
      "episode 4433, reward 912.0, memory_length 2000, epsilon 2.364935916454319e-10 total_time 721.0\n",
      "episode 4434, reward 1718.0, memory_length 2000, epsilon 2.3531407493630243e-10 total_time 724.0\n",
      "episode 4435, reward 807.0, memory_length 2000, epsilon 2.341404410913032e-10 total_time 727.0\n",
      "episode 4436, reward 1421.0, memory_length 2000, epsilon 2.3297266076952595e-10 total_time 724.0\n",
      "episode 4437, reward 1077.0, memory_length 2000, epsilon 2.3181070477640203e-10 total_time 729.0\n",
      "episode 4438, reward 1538.0, memory_length 2000, epsilon 2.3065454406297014e-10 total_time 727.0\n",
      "episode 4439, reward 1604.0, memory_length 2000, epsilon 2.2950414972515395e-10 total_time 724.0\n",
      "episode 4440, reward 1594.0, memory_length 2000, epsilon 2.2835949300303421e-10 total_time 724.0\n",
      "Saving Model 4440\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4441, reward 1307.0, memory_length 2000, epsilon 2.2722054528013248e-10 total_time 724.0\n",
      "episode 4442, reward 1001.0, memory_length 2000, epsilon 2.2608727808269799e-10 total_time 727.0\n",
      "episode 4443, reward 1403.0, memory_length 2000, epsilon 2.249596630789909e-10 total_time 728.0\n",
      "episode 4444, reward 1353.0, memory_length 2000, epsilon 2.2383767207857748e-10 total_time 725.0\n",
      "episode 4445, reward 1335.0, memory_length 2000, epsilon 2.2272127703162347e-10 total_time 721.0\n",
      "episode 4446, reward 1262.0, memory_length 2000, epsilon 2.216104500281961e-10 total_time 722.0\n",
      "episode 4447, reward 994.0, memory_length 2000, epsilon 2.2050516329756168e-10 total_time 723.0\n",
      "episode 4448, reward 1488.0, memory_length 2000, epsilon 2.1940538920749352e-10 total_time 732.0\n",
      "episode 4449, reward 1249.0, memory_length 2000, epsilon 2.1831110026358375e-10 total_time 721.0\n",
      "episode 4450, reward 1237.0, memory_length 2000, epsilon 2.1722226910855092e-10 total_time 726.0\n",
      "Saving Model 4450\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4451, reward 1216.0, memory_length 2000, epsilon 2.1613886852155946e-10 total_time 731.0\n",
      "episode 4452, reward 1348.0, memory_length 2000, epsilon 2.1506087141753753e-10 total_time 726.0\n",
      "episode 4453, reward 745.0, memory_length 2000, epsilon 2.139882508465029e-10 total_time 723.0\n",
      "episode 4454, reward 1021.0, memory_length 2000, epsilon 2.1292097999288467e-10 total_time 725.0\n",
      "episode 4455, reward 1524.0, memory_length 2000, epsilon 2.1185903217485514e-10 total_time 730.0\n",
      "episode 4456, reward 997.0, memory_length 2000, epsilon 2.1080238084366507e-10 total_time 725.0\n",
      "episode 4457, reward 1391.0, memory_length 2000, epsilon 2.097509995829754e-10 total_time 722.0\n",
      "episode 4458, reward 965.0, memory_length 2000, epsilon 2.0870486210819981e-10 total_time 723.0\n",
      "episode 4459, reward 1084.0, memory_length 2000, epsilon 2.0766394226584628e-10 total_time 723.0\n",
      "episode 4460, reward 1643.0, memory_length 2000, epsilon 2.0662821403286598e-10 total_time 727.0\n",
      "Saving Model 4460\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4461, reward 1131.0, memory_length 2000, epsilon 2.0559765151599836e-10 total_time 727.0\n",
      "episode 4462, reward 1300.0, memory_length 2000, epsilon 2.0457222895112687e-10 total_time 727.0\n",
      "episode 4463, reward 1693.0, memory_length 2000, epsilon 2.0355192070263325e-10 total_time 722.0\n",
      "episode 4464, reward 1111.0, memory_length 2000, epsilon 2.0253670126275956e-10 total_time 727.0\n",
      "episode 4465, reward 1755.0, memory_length 2000, epsilon 2.0152654525096628e-10 total_time 725.0\n",
      "episode 4466, reward 1855.0, memory_length 2000, epsilon 2.005214274132997e-10 total_time 729.0\n",
      "episode 4467, reward 1302.0, memory_length 2000, epsilon 1.9952132262176305e-10 total_time 723.0\n",
      "episode 4468, reward 1246.0, memory_length 2000, epsilon 1.9852620587368366e-10 total_time 728.0\n",
      "episode 4469, reward 1123.0, memory_length 2000, epsilon 1.97536052291091e-10 total_time 723.0\n",
      "episode 4470, reward 1013.0, memory_length 2000, epsilon 1.965508371200933e-10 total_time 722.0\n",
      "Saving Model 4470\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4471, reward 1121.0, memory_length 2000, epsilon 1.9557053573026134e-10 total_time 728.0\n",
      "episode 4472, reward 974.0, memory_length 2000, epsilon 1.9459512361400856e-10 total_time 721.0\n",
      "episode 4473, reward 1214.0, memory_length 2000, epsilon 1.9362457638598065e-10 total_time 727.0\n",
      "episode 4474, reward 1442.0, memory_length 2000, epsilon 1.926588697824477e-10 total_time 722.0\n",
      "episode 4475, reward 1602.0, memory_length 2000, epsilon 1.916979796606936e-10 total_time 727.0\n",
      "episode 4476, reward 1772.0, memory_length 2000, epsilon 1.9074188199841535e-10 total_time 728.0\n",
      "episode 4477, reward 1223.0, memory_length 2000, epsilon 1.8979055289312082e-10 total_time 727.0\n",
      "episode 4478, reward 1431.0, memory_length 2000, epsilon 1.8884396856153425e-10 total_time 727.0\n",
      "episode 4479, reward 1382.0, memory_length 2000, epsilon 1.8790210533899732e-10 total_time 725.0\n",
      "episode 4480, reward 1294.0, memory_length 2000, epsilon 1.869649396788798e-10 total_time 722.0\n",
      "Saving Model 4480\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4481, reward 1205.0, memory_length 2000, epsilon 1.8603244815199267e-10 total_time 725.0\n",
      "episode 4482, reward 1034.0, memory_length 2000, epsilon 1.8510460744599853e-10 total_time 725.0\n",
      "episode 4483, reward 986.0, memory_length 2000, epsilon 1.8418139436483144e-10 total_time 723.0\n",
      "episode 4484, reward 846.0, memory_length 2000, epsilon 1.832627858281156e-10 total_time 726.0\n",
      "episode 4485, reward 1155.0, memory_length 2000, epsilon 1.8234875887059104e-10 total_time 728.0\n",
      "episode 4486, reward 1162.0, memory_length 2000, epsilon 1.8143929064153558e-10 total_time 723.0\n",
      "episode 4487, reward 1078.0, memory_length 2000, epsilon 1.8053435840419616e-10 total_time 724.0\n",
      "episode 4488, reward 1053.0, memory_length 2000, epsilon 1.79633939535219e-10 total_time 729.0\n",
      "episode 4489, reward 1251.0, memory_length 2000, epsilon 1.7873801152408684e-10 total_time 721.0\n",
      "episode 4490, reward 1214.0, memory_length 2000, epsilon 1.7784655197255204e-10 total_time 728.0\n",
      "Saving Model 4490\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4491, reward 991.0, memory_length 2000, epsilon 1.769595385940788e-10 total_time 722.0\n",
      "episode 4492, reward 1375.0, memory_length 2000, epsilon 1.7607694921328766e-10 total_time 725.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4493, reward 1222.0, memory_length 2000, epsilon 1.7519876176539754e-10 total_time 727.0\n",
      "episode 4494, reward 1209.0, memory_length 2000, epsilon 1.7432495429567651e-10 total_time 726.0\n",
      "episode 4495, reward 1424.0, memory_length 2000, epsilon 1.7345550495889165e-10 total_time 726.0\n",
      "episode 4496, reward 1816.0, memory_length 2000, epsilon 1.7259039201876556e-10 total_time 723.0\n",
      "episode 4497, reward 1491.0, memory_length 2000, epsilon 1.7172959384742901e-10 total_time 728.0\n",
      "episode 4498, reward 1159.0, memory_length 2000, epsilon 1.7087308892488233e-10 total_time 726.0\n",
      "episode 4499, reward 685.0, memory_length 2000, epsilon 1.70020855838459e-10 total_time 729.0\n",
      "episode 4500, reward 945.0, memory_length 2000, epsilon 1.691728732822869e-10 total_time 721.0\n",
      "Saving Model 4500\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4501, reward 1640.0, memory_length 2000, epsilon 1.6832912005675791e-10 total_time 724.0\n",
      "episode 4502, reward 1595.0, memory_length 2000, epsilon 1.6748957506799694e-10 total_time 727.0\n",
      "episode 4503, reward 1119.0, memory_length 2000, epsilon 1.6665421732733668e-10 total_time 721.0\n",
      "episode 4504, reward 905.0, memory_length 2000, epsilon 1.658230259507895e-10 total_time 729.0\n",
      "episode 4505, reward 1059.0, memory_length 2000, epsilon 1.6499598015852713e-10 total_time 721.0\n",
      "episode 4506, reward 1445.0, memory_length 2000, epsilon 1.6417305927436286e-10 total_time 722.0\n",
      "episode 4507, reward 1499.0, memory_length 2000, epsilon 1.6335424272523116e-10 total_time 723.0\n",
      "episode 4508, reward 1513.0, memory_length 2000, epsilon 1.625395100406756e-10 total_time 724.0\n",
      "episode 4509, reward 1924.0, memory_length 2000, epsilon 1.617288408523361e-10 total_time 725.0\n",
      "episode 4510, reward 1525.0, memory_length 2000, epsilon 1.6092221489344186e-10 total_time 723.0\n",
      "Saving Model 4510\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4511, reward 1259.0, memory_length 2000, epsilon 1.6011961199830133e-10 total_time 723.0\n",
      "episode 4512, reward 1362.0, memory_length 2000, epsilon 1.593210121018003e-10 total_time 723.0\n",
      "episode 4513, reward 1882.0, memory_length 2000, epsilon 1.5852639523889929e-10 total_time 721.0\n",
      "episode 4514, reward 1368.0, memory_length 2000, epsilon 1.5773574154413637e-10 total_time 723.0\n",
      "episode 4515, reward 1626.0, memory_length 2000, epsilon 1.5694903125112746e-10 total_time 728.0\n",
      "episode 4516, reward 1947.0, memory_length 2000, epsilon 1.561662446920737e-10 total_time 721.0\n",
      "episode 4517, reward 1572.0, memory_length 2000, epsilon 1.5538736229727145e-10 total_time 727.0\n",
      "episode 4518, reward 1838.0, memory_length 2000, epsilon 1.5461236459461976e-10 total_time 728.0\n",
      "episode 4519, reward 1406.0, memory_length 2000, epsilon 1.5384123220913566e-10 total_time 729.0\n",
      "episode 4520, reward 1110.0, memory_length 2000, epsilon 1.5307394586246883e-10 total_time 728.0\n",
      "Saving Model 4520\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4521, reward 1101.0, memory_length 2000, epsilon 1.5231048637242168e-10 total_time 721.0\n",
      "episode 4522, reward 1197.0, memory_length 2000, epsilon 1.5155083465246672e-10 total_time 733.0\n",
      "episode 4523, reward 1356.0, memory_length 2000, epsilon 1.5079497171127078e-10 total_time 731.0\n",
      "episode 4524, reward 1256.0, memory_length 2000, epsilon 1.5004287865222206e-10 total_time 724.0\n",
      "episode 4525, reward 1261.0, memory_length 2000, epsilon 1.4929453667295443e-10 total_time 721.0\n",
      "episode 4526, reward 1207.0, memory_length 2000, epsilon 1.4854992706487935e-10 total_time 725.0\n",
      "episode 4527, reward 1438.0, memory_length 2000, epsilon 1.4780903121271737e-10 total_time 729.0\n",
      "episode 4528, reward 1387.0, memory_length 2000, epsilon 1.470718305940346e-10 total_time 725.0\n",
      "episode 4529, reward 1128.0, memory_length 2000, epsilon 1.4633830677877674e-10 total_time 721.0\n",
      "episode 4530, reward 1152.0, memory_length 2000, epsilon 1.4560844142880955e-10 total_time 722.0\n",
      "Saving Model 4530\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4531, reward 1308.0, memory_length 2000, epsilon 1.4488221629746243e-10 total_time 722.0\n",
      "episode 4532, reward 1639.0, memory_length 2000, epsilon 1.4415961322906867e-10 total_time 726.0\n",
      "episode 4533, reward 1370.0, memory_length 2000, epsilon 1.4344061415851397e-10 total_time 721.0\n",
      "episode 4534, reward 1249.0, memory_length 2000, epsilon 1.4272520111078357e-10 total_time 727.0\n",
      "episode 4535, reward 1127.0, memory_length 2000, epsilon 1.4201335620051508e-10 total_time 725.0\n",
      "episode 4536, reward 1294.0, memory_length 2000, epsilon 1.4130506163154812e-10 total_time 721.0\n",
      "episode 4537, reward 1325.0, memory_length 2000, epsilon 1.406002996964816e-10 total_time 725.0\n",
      "episode 4538, reward 964.0, memory_length 2000, epsilon 1.3989905277622996e-10 total_time 722.0\n",
      "episode 4539, reward 1418.0, memory_length 2000, epsilon 1.3920130333958463e-10 total_time 728.0\n",
      "episode 4540, reward 908.0, memory_length 2000, epsilon 1.3850703394277286e-10 total_time 727.0\n",
      "Saving Model 4540\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4541, reward 1292.0, memory_length 2000, epsilon 1.3781622722902307e-10 total_time 722.0\n",
      "episode 4542, reward 1042.0, memory_length 2000, epsilon 1.371288659281324e-10 total_time 729.0\n",
      "episode 4543, reward 1541.0, memory_length 2000, epsilon 1.3644493285603213e-10 total_time 724.0\n",
      "episode 4544, reward 749.0, memory_length 2000, epsilon 1.3576441091435974e-10 total_time 722.0\n",
      "episode 4545, reward 1314.0, memory_length 2000, epsilon 1.350872830900308e-10 total_time 724.0\n",
      "episode 4546, reward 1117.0, memory_length 2000, epsilon 1.3441353245481536e-10 total_time 723.0\n",
      "episode 4547, reward 1591.0, memory_length 2000, epsilon 1.3374314216491204e-10 total_time 729.0\n",
      "episode 4548, reward 1128.0, memory_length 2000, epsilon 1.3307609546052815e-10 total_time 726.0\n",
      "episode 4549, reward 807.0, memory_length 2000, epsilon 1.324123756654623e-10 total_time 722.0\n",
      "episode 4550, reward 929.0, memory_length 2000, epsilon 1.3175196618668458e-10 total_time 727.0\n",
      "Saving Model 4550\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4551, reward 1601.0, memory_length 2000, epsilon 1.310948505139236e-10 total_time 724.0\n",
      "episode 4552, reward 1537.0, memory_length 2000, epsilon 1.304410122192529e-10 total_time 722.0\n",
      "episode 4553, reward 1392.0, memory_length 2000, epsilon 1.297904349566819e-10 total_time 728.0\n",
      "episode 4554, reward 1464.0, memory_length 2000, epsilon 1.2914310246174475e-10 total_time 721.0\n",
      "episode 4555, reward 1463.0, memory_length 2000, epsilon 1.2849899855109492e-10 total_time 726.0\n",
      "episode 4556, reward 1302.0, memory_length 2000, epsilon 1.2785810712210198e-10 total_time 727.0\n",
      "episode 4557, reward 1391.0, memory_length 2000, epsilon 1.2722041215244637e-10 total_time 723.0\n",
      "episode 4558, reward 1679.0, memory_length 2000, epsilon 1.2658589769972064e-10 total_time 727.0\n",
      "episode 4559, reward 1396.0, memory_length 2000, epsilon 1.2595454790102996e-10 total_time 728.0\n",
      "episode 4560, reward 987.0, memory_length 2000, epsilon 1.253263469725974e-10 total_time 723.0\n",
      "Saving Model 4560\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4561, reward 999.0, memory_length 2000, epsilon 1.247012792093666e-10 total_time 725.0\n",
      "episode 4562, reward 1270.0, memory_length 2000, epsilon 1.2407932898461087e-10 total_time 728.0\n",
      "episode 4563, reward 1369.0, memory_length 2000, epsilon 1.234604807495418e-10 total_time 721.0\n",
      "episode 4564, reward 1612.0, memory_length 2000, epsilon 1.228447190329221e-10 total_time 721.0\n",
      "episode 4565, reward 1675.0, memory_length 2000, epsilon 1.2223202844067645e-10 total_time 724.0\n",
      "episode 4566, reward 1440.0, memory_length 2000, epsilon 1.2162239365550762e-10 total_time 724.0\n",
      "episode 4567, reward 1344.0, memory_length 2000, epsilon 1.2101579943651512e-10 total_time 726.0\n",
      "episode 4568, reward 1414.0, memory_length 2000, epsilon 1.2041223061881142e-10 total_time 729.0\n",
      "episode 4569, reward 1052.0, memory_length 2000, epsilon 1.198116721131447e-10 total_time 721.0\n",
      "episode 4570, reward 815.0, memory_length 2000, epsilon 1.1921410890552055e-10 total_time 723.0\n",
      "Saving Model 4570\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4571, reward 1261.0, memory_length 2000, epsilon 1.1861952605682855e-10 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4572, reward 1191.0, memory_length 2000, epsilon 1.1802790870246606e-10 total_time 726.0\n",
      "episode 4573, reward 1664.0, memory_length 2000, epsilon 1.1743924205196803e-10 total_time 725.0\n",
      "episode 4574, reward 703.0, memory_length 2000, epsilon 1.1685351138863833e-10 total_time 731.0\n",
      "episode 4575, reward 1329.0, memory_length 2000, epsilon 1.1627070206917947e-10 total_time 727.0\n",
      "episode 4576, reward 1003.0, memory_length 2000, epsilon 1.1569079952332814e-10 total_time 729.0\n",
      "episode 4577, reward 1189.0, memory_length 2000, epsilon 1.1511378925349002e-10 total_time 729.0\n",
      "episode 4578, reward 1746.0, memory_length 2000, epsilon 1.1453965683437917e-10 total_time 725.0\n",
      "episode 4579, reward 973.0, memory_length 2000, epsilon 1.1396838791265478e-10 total_time 721.0\n",
      "episode 4580, reward 965.0, memory_length 2000, epsilon 1.1339996820656368e-10 total_time 724.0\n",
      "Saving Model 4580\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4581, reward 1264.0, memory_length 2000, epsilon 1.1283438350558439e-10 total_time 725.0\n",
      "episode 4582, reward 1380.0, memory_length 2000, epsilon 1.1227161967006953e-10 total_time 722.0\n",
      "episode 4583, reward 943.0, memory_length 2000, epsilon 1.1171166263089391e-10 total_time 725.0\n",
      "episode 4584, reward 1143.0, memory_length 2000, epsilon 1.11154498389102e-10 total_time 725.0\n",
      "episode 4585, reward 1915.0, memory_length 2000, epsilon 1.106001130155595e-10 total_time 727.0\n",
      "episode 4586, reward 1464.0, memory_length 2000, epsilon 1.1004849265060283e-10 total_time 727.0\n",
      "episode 4587, reward 967.0, memory_length 2000, epsilon 1.094996235036941e-10 total_time 727.0\n",
      "episode 4588, reward 1426.0, memory_length 2000, epsilon 1.089534918530757e-10 total_time 722.0\n",
      "episode 4589, reward 1283.0, memory_length 2000, epsilon 1.0841008404542867e-10 total_time 726.0\n",
      "episode 4590, reward 1299.0, memory_length 2000, epsilon 1.0786938649552914e-10 total_time 728.0\n",
      "Saving Model 4590\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4591, reward 825.0, memory_length 2000, epsilon 1.0733138568590982e-10 total_time 723.0\n",
      "episode 4592, reward 1397.0, memory_length 2000, epsilon 1.0679606816652322e-10 total_time 728.0\n",
      "episode 4593, reward 1233.0, memory_length 2000, epsilon 1.0626342055440307e-10 total_time 730.0\n",
      "episode 4594, reward 1206.0, memory_length 2000, epsilon 1.0573342953333134e-10 total_time 725.0\n",
      "episode 4595, reward 1551.0, memory_length 2000, epsilon 1.0520608185350452e-10 total_time 726.0\n",
      "episode 4596, reward 1842.0, memory_length 2000, epsilon 1.046813643312039e-10 total_time 721.0\n",
      "episode 4597, reward 1591.0, memory_length 2000, epsilon 1.0415926384846372e-10 total_time 732.0\n",
      "episode 4598, reward 1265.0, memory_length 2000, epsilon 1.0363976735274434e-10 total_time 731.0\n",
      "episode 4599, reward 1053.0, memory_length 2000, epsilon 1.0312286185660708e-10 total_time 728.0\n",
      "episode 4600, reward 1307.0, memory_length 2000, epsilon 1.026085344373872e-10 total_time 721.0\n",
      "Saving Model 4600\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4601, reward 1405.0, memory_length 2000, epsilon 1.0209677223687246e-10 total_time 726.0\n",
      "episode 4602, reward 1178.0, memory_length 2000, epsilon 1.0158756246098082e-10 total_time 724.0\n",
      "episode 4603, reward 1082.0, memory_length 2000, epsilon 1.0108089237944209e-10 total_time 721.0\n",
      "episode 4604, reward 1360.0, memory_length 2000, epsilon 1.005767493254775e-10 total_time 728.0\n",
      "episode 4605, reward 902.0, memory_length 2000, epsilon 1.0007512069548404e-10 total_time 727.0\n",
      "episode 4606, reward 1586.0, memory_length 2000, epsilon 9.957599394872059e-11 total_time 721.0\n",
      "episode 4607, reward 1375.0, memory_length 2000, epsilon 9.90793566069921e-11 total_time 723.0\n",
      "episode 4608, reward 1270.0, memory_length 2000, epsilon 9.858519625433917e-11 total_time 728.0\n",
      "episode 4609, reward 1655.0, memory_length 2000, epsilon 9.80935005367269e-11 total_time 727.0\n",
      "episode 4610, reward 1231.0, memory_length 2000, epsilon 9.760425716173746e-11 total_time 730.0\n",
      "Saving Model 4610\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4611, reward 1125.0, memory_length 2000, epsilon 9.71174538982606e-11 total_time 721.0\n",
      "episode 4612, reward 1264.0, memory_length 2000, epsilon 9.66330785761894e-11 total_time 722.0\n",
      "episode 4613, reward 1219.0, memory_length 2000, epsilon 9.615111908611525e-11 total_time 722.0\n",
      "episode 4614, reward 1322.0, memory_length 2000, epsilon 9.567156337902647e-11 total_time 721.0\n",
      "episode 4615, reward 1715.0, memory_length 2000, epsilon 9.519439946600505e-11 total_time 725.0\n",
      "episode 4616, reward 1075.0, memory_length 2000, epsilon 9.4719615417928e-11 total_time 726.0\n",
      "episode 4617, reward 1098.0, memory_length 2000, epsilon 9.424719936517005e-11 total_time 730.0\n",
      "episode 4618, reward 1363.0, memory_length 2000, epsilon 9.377713949730493e-11 total_time 730.0\n",
      "episode 4619, reward 524.0, memory_length 2000, epsilon 9.330942406281148e-11 total_time 721.0\n",
      "episode 4620, reward 985.0, memory_length 2000, epsilon 9.284404136877915e-11 total_time 723.0\n",
      "Saving Model 4620\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4621, reward 1528.0, memory_length 2000, epsilon 9.238097978061699e-11 total_time 722.0\n",
      "episode 4622, reward 1342.0, memory_length 2000, epsilon 9.192022772176086e-11 total_time 732.0\n",
      "episode 4623, reward 1359.0, memory_length 2000, epsilon 9.146177367338496e-11 total_time 727.0\n",
      "episode 4624, reward 1566.0, memory_length 2000, epsilon 9.100560617411486e-11 total_time 721.0\n",
      "episode 4625, reward 1069.0, memory_length 2000, epsilon 9.0551713819739e-11 total_time 728.0\n",
      "episode 4626, reward 1210.0, memory_length 2000, epsilon 9.010008526292486e-11 total_time 725.0\n",
      "episode 4627, reward 1211.0, memory_length 2000, epsilon 8.965070921293469e-11 total_time 723.0\n",
      "episode 4628, reward 1486.0, memory_length 2000, epsilon 8.920357443534448e-11 total_time 722.0\n",
      "episode 4629, reward 1659.0, memory_length 2000, epsilon 8.875866975176118e-11 total_time 726.0\n",
      "episode 4630, reward 1397.0, memory_length 2000, epsilon 8.831598403954422e-11 total_time 726.0\n",
      "Saving Model 4630\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4631, reward 1389.0, memory_length 2000, epsilon 8.787550623152833e-11 total_time 721.0\n",
      "episode 4632, reward 1323.0, memory_length 2000, epsilon 8.74372253157451e-11 total_time 732.0\n",
      "episode 4633, reward 1149.0, memory_length 2000, epsilon 8.700113033514878e-11 total_time 723.0\n",
      "episode 4634, reward 1155.0, memory_length 2000, epsilon 8.656721038734185e-11 total_time 731.0\n",
      "episode 4635, reward 1263.0, memory_length 2000, epsilon 8.613545462430362e-11 total_time 733.0\n",
      "episode 4636, reward 1156.0, memory_length 2000, epsilon 8.570585225211722e-11 total_time 722.0\n",
      "episode 4637, reward 970.0, memory_length 2000, epsilon 8.527839253070098e-11 total_time 734.0\n",
      "episode 4638, reward 1518.0, memory_length 2000, epsilon 8.485306477353928e-11 total_time 721.0\n",
      "episode 4639, reward 1482.0, memory_length 2000, epsilon 8.442985834741665e-11 total_time 724.0\n",
      "episode 4640, reward 1311.0, memory_length 2000, epsilon 8.400876267215012e-11 total_time 722.0\n",
      "Saving Model 4640\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4641, reward 1587.0, memory_length 2000, epsilon 8.358976722032553e-11 total_time 725.0\n",
      "episode 4642, reward 1186.0, memory_length 2000, epsilon 8.31728615170354e-11 total_time 726.0\n",
      "episode 4643, reward 1390.0, memory_length 2000, epsilon 8.275803513961513e-11 total_time 723.0\n",
      "episode 4644, reward 1304.0, memory_length 2000, epsilon 8.234527771738366e-11 total_time 726.0\n",
      "episode 4645, reward 1395.0, memory_length 2000, epsilon 8.193457893138363e-11 total_time 723.0\n",
      "episode 4646, reward 918.0, memory_length 2000, epsilon 8.152592851412464e-11 total_time 721.0\n",
      "episode 4647, reward 1052.0, memory_length 2000, epsilon 8.111931624932461e-11 total_time 723.0\n",
      "episode 4648, reward 1218.0, memory_length 2000, epsilon 8.071473197165552e-11 total_time 724.0\n",
      "episode 4649, reward 1432.0, memory_length 2000, epsilon 8.03121655664899e-11 total_time 723.0\n",
      "episode 4650, reward 1568.0, memory_length 2000, epsilon 7.991160696964636e-11 total_time 724.0\n",
      "Saving Model 4650\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4651, reward 882.0, memory_length 2000, epsilon 7.951304616713915e-11 total_time 721.0\n",
      "episode 4652, reward 1218.0, memory_length 2000, epsilon 7.911647319492712e-11 total_time 722.0\n",
      "episode 4653, reward 1117.0, memory_length 2000, epsilon 7.872187813866591e-11 total_time 740.0\n",
      "episode 4654, reward 807.0, memory_length 2000, epsilon 7.832925113345827e-11 total_time 723.0\n",
      "episode 4655, reward 1200.0, memory_length 2000, epsilon 7.793858236360832e-11 total_time 721.0\n",
      "episode 4656, reward 1259.0, memory_length 2000, epsilon 7.754986206237706e-11 total_time 725.0\n",
      "episode 4657, reward 1144.0, memory_length 2000, epsilon 7.716308051173643e-11 total_time 734.0\n",
      "episode 4658, reward 1587.0, memory_length 2000, epsilon 7.677822804212747e-11 total_time 730.0\n",
      "episode 4659, reward 1179.0, memory_length 2000, epsilon 7.639529503221819e-11 total_time 726.0\n",
      "episode 4660, reward 1303.0, memory_length 2000, epsilon 7.601427190866391e-11 total_time 723.0\n",
      "Saving Model 4660\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4661, reward 1373.0, memory_length 2000, epsilon 7.563514914586642e-11 total_time 724.0\n",
      "episode 4662, reward 1201.0, memory_length 2000, epsilon 7.525791726573692e-11 total_time 723.0\n",
      "episode 4663, reward 1337.0, memory_length 2000, epsilon 7.488256683745845e-11 total_time 725.0\n",
      "episode 4664, reward 1815.0, memory_length 2000, epsilon 7.450908847725135e-11 total_time 729.0\n",
      "episode 4665, reward 970.0, memory_length 2000, epsilon 7.413747284813686e-11 total_time 723.0\n",
      "episode 4666, reward 1253.0, memory_length 2000, epsilon 7.376771065970464e-11 total_time 724.0\n",
      "episode 4667, reward 2066.0, memory_length 2000, epsilon 7.339979266788125e-11 total_time 728.0\n",
      "episode 4668, reward 1379.0, memory_length 2000, epsilon 7.303370967469746e-11 total_time 729.0\n",
      "episode 4669, reward 1560.0, memory_length 2000, epsilon 7.266945252805937e-11 total_time 727.0\n",
      "episode 4670, reward 1486.0, memory_length 2000, epsilon 7.230701212151911e-11 total_time 723.0\n",
      "Saving Model 4670\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4671, reward 1171.0, memory_length 2000, epsilon 7.194637939404813e-11 total_time 724.0\n",
      "episode 4672, reward 1172.0, memory_length 2000, epsilon 7.158754532980921e-11 total_time 726.0\n",
      "episode 4673, reward 968.0, memory_length 2000, epsilon 7.123050095793181e-11 total_time 728.0\n",
      "episode 4674, reward 1289.0, memory_length 2000, epsilon 7.087523735228852e-11 total_time 729.0\n",
      "episode 4675, reward 1035.0, memory_length 2000, epsilon 7.05217456312705e-11 total_time 727.0\n",
      "episode 4676, reward 1062.0, memory_length 2000, epsilon 7.017001695756622e-11 total_time 727.0\n",
      "episode 4677, reward 892.0, memory_length 2000, epsilon 6.982004253794036e-11 total_time 728.0\n",
      "episode 4678, reward 1788.0, memory_length 2000, epsilon 6.947181362301463e-11 total_time 725.0\n",
      "episode 4679, reward 995.0, memory_length 2000, epsilon 6.912532150704783e-11 total_time 726.0\n",
      "episode 4680, reward 1078.0, memory_length 2000, epsilon 6.878055752771871e-11 total_time 727.0\n",
      "Saving Model 4680\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4681, reward 959.0, memory_length 2000, epsilon 6.843751306591039e-11 total_time 724.0\n",
      "episode 4682, reward 1309.0, memory_length 2000, epsilon 6.809617954549315e-11 total_time 723.0\n",
      "episode 4683, reward 1530.0, memory_length 2000, epsilon 6.775654843311123e-11 total_time 728.0\n",
      "episode 4684, reward 799.0, memory_length 2000, epsilon 6.741861123796888e-11 total_time 726.0\n",
      "episode 4685, reward 977.0, memory_length 2000, epsilon 6.708235951161912e-11 total_time 728.0\n",
      "episode 4686, reward 1027.0, memory_length 2000, epsilon 6.674778484775102e-11 total_time 721.0\n",
      "episode 4687, reward 1090.0, memory_length 2000, epsilon 6.641487888198057e-11 total_time 722.0\n",
      "episode 4688, reward 746.0, memory_length 2000, epsilon 6.608363329164102e-11 total_time 729.0\n",
      "episode 4689, reward 1052.0, memory_length 2000, epsilon 6.57540397955759e-11 total_time 721.0\n",
      "episode 4690, reward 1109.0, memory_length 2000, epsilon 6.542609015393033e-11 total_time 729.0\n",
      "Saving Model 4690\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4691, reward 1280.0, memory_length 2000, epsilon 6.509977616794598e-11 total_time 729.0\n",
      "episode 4692, reward 1252.0, memory_length 2000, epsilon 6.47750896797567e-11 total_time 727.0\n",
      "episode 4693, reward 1604.0, memory_length 2000, epsilon 6.445202257218311e-11 total_time 721.0\n",
      "episode 4694, reward 1028.0, memory_length 2000, epsilon 6.41305667685307e-11 total_time 725.0\n",
      "episode 4695, reward 1427.0, memory_length 2000, epsilon 6.38107142323874e-11 total_time 724.0\n",
      "episode 4696, reward 1152.0, memory_length 2000, epsilon 6.349245696742363e-11 total_time 730.0\n",
      "episode 4697, reward 1319.0, memory_length 2000, epsilon 6.317578701719096e-11 total_time 725.0\n",
      "episode 4698, reward 766.0, memory_length 2000, epsilon 6.286069646492387e-11 total_time 723.0\n",
      "episode 4699, reward 1018.0, memory_length 2000, epsilon 6.254717743334264e-11 total_time 721.0\n",
      "episode 4700, reward 1108.0, memory_length 2000, epsilon 6.223522208445493e-11 total_time 728.0\n",
      "Saving Model 4700\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4701, reward 1226.0, memory_length 2000, epsilon 6.192482261936073e-11 total_time 724.0\n",
      "episode 4702, reward 1417.0, memory_length 2000, epsilon 6.161597127805706e-11 total_time 726.0\n",
      "episode 4703, reward 1136.0, memory_length 2000, epsilon 6.130866033924472e-11 total_time 723.0\n",
      "episode 4704, reward 1277.0, memory_length 2000, epsilon 6.100288212013403e-11 total_time 734.0\n",
      "episode 4705, reward 1064.0, memory_length 2000, epsilon 6.069862897625335e-11 total_time 728.0\n",
      "episode 4706, reward 987.0, memory_length 2000, epsilon 6.03958933012587e-11 total_time 726.0\n",
      "episode 4707, reward 944.0, memory_length 2000, epsilon 6.009466752674219e-11 total_time 730.0\n",
      "episode 4708, reward 1275.0, memory_length 2000, epsilon 5.979494412204377e-11 total_time 735.0\n",
      "episode 4709, reward 1032.0, memory_length 2000, epsilon 5.949671559406253e-11 total_time 723.0\n",
      "episode 4710, reward 1893.0, memory_length 2000, epsilon 5.919997448707015e-11 total_time 721.0\n",
      "Saving Model 4710\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4711, reward 1109.0, memory_length 2000, epsilon 5.890471338252326e-11 total_time 725.0\n",
      "episode 4712, reward 1496.0, memory_length 2000, epsilon 5.86109248988789e-11 total_time 732.0\n",
      "episode 4713, reward 1627.0, memory_length 2000, epsilon 5.831860169140946e-11 total_time 726.0\n",
      "episode 4714, reward 1013.0, memory_length 2000, epsilon 5.8027736452019945e-11 total_time 723.0\n",
      "episode 4715, reward 1148.0, memory_length 2000, epsilon 5.7738321909064e-11 total_time 721.0\n",
      "episode 4716, reward 986.0, memory_length 2000, epsilon 5.745035082716279e-11 total_time 723.0\n",
      "episode 4717, reward 1702.0, memory_length 2000, epsilon 5.7163816007024675e-11 total_time 730.0\n",
      "episode 4718, reward 1653.0, memory_length 2000, epsilon 5.687871028526402e-11 total_time 721.0\n",
      "episode 4719, reward 1168.0, memory_length 2000, epsilon 5.659502653422292e-11 total_time 728.0\n",
      "episode 4720, reward 1299.0, memory_length 2000, epsilon 5.6312757661792647e-11 total_time 729.0\n",
      "Saving Model 4720\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4721, reward 1386.0, memory_length 2000, epsilon 5.603189661123707e-11 total_time 723.0\n",
      "episode 4722, reward 1709.0, memory_length 2000, epsilon 5.575243636101511e-11 total_time 723.0\n",
      "episode 4723, reward 1133.0, memory_length 2000, epsilon 5.547436992460575e-11 total_time 721.0\n",
      "episode 4724, reward 1346.0, memory_length 2000, epsilon 5.5197690350333994e-11 total_time 724.0\n",
      "episode 4725, reward 1252.0, memory_length 2000, epsilon 5.492239072119588e-11 total_time 725.0\n",
      "episode 4726, reward 1605.0, memory_length 2000, epsilon 5.464846415468634e-11 total_time 721.0\n",
      "episode 4727, reward 902.0, memory_length 2000, epsilon 5.437590380262674e-11 total_time 723.0\n",
      "episode 4728, reward 922.0, memory_length 2000, epsilon 5.410470285099449e-11 total_time 726.0\n",
      "episode 4729, reward 816.0, memory_length 2000, epsilon 5.3834854519751474e-11 total_time 727.0\n",
      "episode 4730, reward 1060.0, memory_length 2000, epsilon 5.3566352062675155e-11 total_time 722.0\n",
      "Saving Model 4730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4731, reward 1437.0, memory_length 2000, epsilon 5.329918876719051e-11 total_time 731.0\n",
      "episode 4732, reward 987.0, memory_length 2000, epsilon 5.303335795420104e-11 total_time 723.0\n",
      "episode 4733, reward 1242.0, memory_length 2000, epsilon 5.2768852977922594e-11 total_time 734.0\n",
      "episode 4734, reward 757.0, memory_length 2000, epsilon 5.250566722571678e-11 total_time 726.0\n",
      "episode 4735, reward 1090.0, memory_length 2000, epsilon 5.224379411792647e-11 total_time 728.0\n",
      "episode 4736, reward 1327.0, memory_length 2000, epsilon 5.198322710771015e-11 total_time 729.0\n",
      "episode 4737, reward 1012.0, memory_length 2000, epsilon 5.1723959680878975e-11 total_time 726.0\n",
      "episode 4738, reward 1418.0, memory_length 2000, epsilon 5.146598535573359e-11 total_time 723.0\n",
      "episode 4739, reward 811.0, memory_length 2000, epsilon 5.120929768290282e-11 total_time 733.0\n",
      "episode 4740, reward 1493.0, memory_length 2000, epsilon 5.0953890245181263e-11 total_time 725.0\n",
      "Saving Model 4740\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4741, reward 1771.0, memory_length 2000, epsilon 5.069975665736951e-11 total_time 727.0\n",
      "episode 4742, reward 1049.0, memory_length 2000, epsilon 5.0446890566114985e-11 total_time 728.0\n",
      "episode 4743, reward 1372.0, memory_length 2000, epsilon 5.019528564975206e-11 total_time 726.0\n",
      "episode 4744, reward 1055.0, memory_length 2000, epsilon 4.994493561814472e-11 total_time 722.0\n",
      "episode 4745, reward 1298.0, memory_length 2000, epsilon 4.969583421252895e-11 total_time 728.0\n",
      "episode 4746, reward 1190.0, memory_length 2000, epsilon 4.9447975205357e-11 total_time 723.0\n",
      "episode 4747, reward 1547.0, memory_length 2000, epsilon 4.920135240014061e-11 total_time 729.0\n",
      "episode 4748, reward 1431.0, memory_length 2000, epsilon 4.8955959631296603e-11 total_time 724.0\n",
      "episode 4749, reward 1505.0, memory_length 2000, epsilon 4.871179076399336e-11 total_time 726.0\n",
      "episode 4750, reward 1393.0, memory_length 2000, epsilon 4.8468839693996285e-11 total_time 726.0\n",
      "Saving Model 4750\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4751, reward 1123.0, memory_length 2000, epsilon 4.822710034751598e-11 total_time 727.0\n",
      "episode 4752, reward 854.0, memory_length 2000, epsilon 4.7986566681056025e-11 total_time 722.0\n",
      "episode 4753, reward 943.0, memory_length 2000, epsilon 4.774723268126257e-11 total_time 725.0\n",
      "episode 4754, reward 1515.0, memory_length 2000, epsilon 4.7509092364772974e-11 total_time 727.0\n",
      "episode 4755, reward 1093.0, memory_length 2000, epsilon 4.727213977806678e-11 total_time 723.0\n",
      "episode 4756, reward 830.0, memory_length 2000, epsilon 4.703636899731728e-11 total_time 724.0\n",
      "episode 4757, reward 1192.0, memory_length 2000, epsilon 4.680177412824254e-11 total_time 723.0\n",
      "episode 4758, reward 1476.0, memory_length 2000, epsilon 4.656834930595859e-11 total_time 722.0\n",
      "episode 4759, reward 1245.0, memory_length 2000, epsilon 4.633608869483257e-11 total_time 721.0\n",
      "episode 4760, reward 1305.0, memory_length 2000, epsilon 4.610498648833741e-11 total_time 726.0\n",
      "Saving Model 4760\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4761, reward 882.0, memory_length 2000, epsilon 4.587503690890578e-11 total_time 722.0\n",
      "episode 4762, reward 1481.0, memory_length 2000, epsilon 4.5646234207786196e-11 total_time 726.0\n",
      "episode 4763, reward 1473.0, memory_length 2000, epsilon 4.5418572664899046e-11 total_time 731.0\n",
      "episode 4764, reward 1258.0, memory_length 2000, epsilon 4.519204658869424e-11 total_time 725.0\n",
      "episode 4765, reward 1655.0, memory_length 2000, epsilon 4.49666503160079e-11 total_time 734.0\n",
      "episode 4766, reward 1198.0, memory_length 2000, epsilon 4.4742378211921316e-11 total_time 726.0\n",
      "episode 4767, reward 1725.0, memory_length 2000, epsilon 4.4519224669620525e-11 total_time 737.0\n",
      "episode 4768, reward 1107.0, memory_length 2000, epsilon 4.429718411025518e-11 total_time 727.0\n",
      "episode 4769, reward 917.0, memory_length 2000, epsilon 4.407625098279975e-11 total_time 733.0\n",
      "episode 4770, reward 1403.0, memory_length 2000, epsilon 4.385641976391436e-11 total_time 726.0\n",
      "Saving Model 4770\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4771, reward 1119.0, memory_length 2000, epsilon 4.363768495780743e-11 total_time 729.0\n",
      "episode 4772, reward 1270.0, memory_length 2000, epsilon 4.342004109609723e-11 total_time 725.0\n",
      "episode 4773, reward 1816.0, memory_length 2000, epsilon 4.3203482737675745e-11 total_time 722.0\n",
      "episode 4774, reward 1798.0, memory_length 2000, epsilon 4.2988004468573043e-11 total_time 722.0\n",
      "episode 4775, reward 1219.0, memory_length 2000, epsilon 4.277360090182101e-11 total_time 731.0\n",
      "episode 4776, reward 1593.0, memory_length 2000, epsilon 4.2560266677319317e-11 total_time 723.0\n",
      "episode 4777, reward 1550.0, memory_length 2000, epsilon 4.234799646170109e-11 total_time 727.0\n",
      "episode 4778, reward 1257.0, memory_length 2000, epsilon 4.213678494820018e-11 total_time 730.0\n",
      "episode 4779, reward 1158.0, memory_length 2000, epsilon 4.192662685651761e-11 total_time 727.0\n",
      "episode 4780, reward 829.0, memory_length 2000, epsilon 4.171751693268997e-11 total_time 726.0\n",
      "Saving Model 4780\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4781, reward 1216.0, memory_length 2000, epsilon 4.1509449948958594e-11 total_time 724.0\n",
      "episode 4782, reward 1108.0, memory_length 2000, epsilon 4.130242070363789e-11 total_time 724.0\n",
      "episode 4783, reward 958.0, memory_length 2000, epsilon 4.109642402098595e-11 total_time 723.0\n",
      "episode 4784, reward 885.0, memory_length 2000, epsilon 4.0891454751074826e-11 total_time 732.0\n",
      "episode 4785, reward 1135.0, memory_length 2000, epsilon 4.0687507769662395e-11 total_time 727.0\n",
      "episode 4786, reward 640.0, memory_length 2000, epsilon 4.048457797806334e-11 total_time 724.0\n",
      "episode 4787, reward 1183.0, memory_length 2000, epsilon 4.028266030302217e-11 total_time 721.0\n",
      "episode 4788, reward 1168.0, memory_length 2000, epsilon 4.008174969658678e-11 total_time 725.0\n",
      "episode 4789, reward 791.0, memory_length 2000, epsilon 3.9881841135981396e-11 total_time 721.0\n",
      "episode 4790, reward 877.0, memory_length 2000, epsilon 3.9682929623481587e-11 total_time 729.0\n",
      "Saving Model 4790\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4791, reward 946.0, memory_length 2000, epsilon 3.948501018628905e-11 total_time 731.0\n",
      "episode 4792, reward 1195.0, memory_length 2000, epsilon 3.928807787640782e-11 total_time 724.0\n",
      "episode 4793, reward 813.0, memory_length 2000, epsilon 3.909212777051976e-11 total_time 728.0\n",
      "episode 4794, reward 1230.0, memory_length 2000, epsilon 3.8897154969862006e-11 total_time 726.0\n",
      "episode 4795, reward 1147.0, memory_length 2000, epsilon 3.870315460010426e-11 total_time 721.0\n",
      "episode 4796, reward 1101.0, memory_length 2000, epsilon 3.851012181122745e-11 total_time 723.0\n",
      "episode 4797, reward 1278.0, memory_length 2000, epsilon 3.831805177740165e-11 total_time 726.0\n",
      "episode 4798, reward 1640.0, memory_length 2000, epsilon 3.8126939696865886e-11 total_time 728.0\n",
      "episode 4799, reward 1062.0, memory_length 2000, epsilon 3.793678079180845e-11 total_time 729.0\n",
      "episode 4800, reward 1715.0, memory_length 2000, epsilon 3.77475703082467e-11 total_time 723.0\n",
      "Saving Model 4800\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4801, reward 1204.0, memory_length 2000, epsilon 3.7559303515908666e-11 total_time 731.0\n",
      "episode 4802, reward 1314.0, memory_length 2000, epsilon 3.737197570811462e-11 total_time 730.0\n",
      "episode 4803, reward 1593.0, memory_length 2000, epsilon 3.718558220165986e-11 total_time 723.0\n",
      "episode 4804, reward 706.0, memory_length 2000, epsilon 3.70001183366969e-11 total_time 721.0\n",
      "episode 4805, reward 1251.0, memory_length 2000, epsilon 3.681557947661931e-11 total_time 723.0\n",
      "episode 4806, reward 1455.0, memory_length 2000, epsilon 3.6631961007946254e-11 total_time 730.0\n",
      "episode 4807, reward 984.0, memory_length 2000, epsilon 3.6449258340206305e-11 total_time 722.0\n",
      "episode 4808, reward 1172.0, memory_length 2000, epsilon 3.6267466905823264e-11 total_time 724.0\n",
      "episode 4809, reward 1319.0, memory_length 2000, epsilon 3.6086582160001675e-11 total_time 726.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4810, reward 1394.0, memory_length 2000, epsilon 3.590659958061372e-11 total_time 721.0\n",
      "Saving Model 4810\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4811, reward 1402.0, memory_length 2000, epsilon 3.5727514668085426e-11 total_time 721.0\n",
      "episode 4812, reward 1405.0, memory_length 2000, epsilon 3.554932294528451e-11 total_time 725.0\n",
      "episode 4813, reward 1619.0, memory_length 2000, epsilon 3.5372019957408877e-11 total_time 727.0\n",
      "episode 4814, reward 819.0, memory_length 2000, epsilon 3.5195601271874485e-11 total_time 722.0\n",
      "episode 4815, reward 1218.0, memory_length 2000, epsilon 3.5020062478204986e-11 total_time 723.0\n",
      "episode 4816, reward 1349.0, memory_length 2000, epsilon 3.4845399187921284e-11 total_time 727.0\n",
      "episode 4817, reward 1774.0, memory_length 2000, epsilon 3.4671607034432264e-11 total_time 724.0\n",
      "episode 4818, reward 807.0, memory_length 2000, epsilon 3.4498681672924926e-11 total_time 724.0\n",
      "episode 4819, reward 1112.0, memory_length 2000, epsilon 3.4326618780256225e-11 total_time 724.0\n",
      "episode 4820, reward 1061.0, memory_length 2000, epsilon 3.415541405484474e-11 total_time 724.0\n",
      "Saving Model 4820\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4821, reward 1413.0, memory_length 2000, epsilon 3.3985063216563694e-11 total_time 722.0\n",
      "episode 4822, reward 1214.0, memory_length 2000, epsilon 3.3815562006633106e-11 total_time 722.0\n",
      "episode 4823, reward 1147.0, memory_length 2000, epsilon 3.364690618751379e-11 total_time 732.0\n",
      "episode 4824, reward 1706.0, memory_length 2000, epsilon 3.3479091542801736e-11 total_time 722.0\n",
      "episode 4825, reward 1003.0, memory_length 2000, epsilon 3.3312113877121956e-11 total_time 722.0\n",
      "episode 4826, reward 1098.0, memory_length 2000, epsilon 3.3145969016024107e-11 total_time 727.0\n",
      "episode 4827, reward 1025.0, memory_length 2000, epsilon 3.2980652805877895e-11 total_time 733.0\n",
      "episode 4828, reward 892.0, memory_length 2000, epsilon 3.281616111376969e-11 total_time 721.0\n",
      "episode 4829, reward 1032.0, memory_length 2000, epsilon 3.2652489827398504e-11 total_time 727.0\n",
      "episode 4830, reward 1554.0, memory_length 2000, epsilon 3.248963485497354e-11 total_time 721.0\n",
      "Saving Model 4830\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4831, reward 1427.0, memory_length 2000, epsilon 3.2327592125112236e-11 total_time 725.0\n",
      "episode 4832, reward 1355.0, memory_length 2000, epsilon 3.2166357586737795e-11 total_time 730.0\n",
      "episode 4833, reward 1202.0, memory_length 2000, epsilon 3.200592720897835e-11 total_time 723.0\n",
      "episode 4834, reward 1004.0, memory_length 2000, epsilon 3.1846296981066e-11 total_time 724.0\n",
      "episode 4835, reward 978.0, memory_length 2000, epsilon 3.1687462912236943e-11 total_time 731.0\n",
      "episode 4836, reward 1147.0, memory_length 2000, epsilon 3.1529421031631085e-11 total_time 723.0\n",
      "episode 4837, reward 1548.0, memory_length 2000, epsilon 3.1372167388193064e-11 total_time 721.0\n",
      "episode 4838, reward 1120.0, memory_length 2000, epsilon 3.121569805057383e-11 total_time 724.0\n",
      "episode 4839, reward 1053.0, memory_length 2000, epsilon 3.106000910703168e-11 total_time 734.0\n",
      "episode 4840, reward 1797.0, memory_length 2000, epsilon 3.0905096665334906e-11 total_time 724.0\n",
      "Saving Model 4840\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4841, reward 1400.0, memory_length 2000, epsilon 3.075095685266431e-11 total_time 731.0\n",
      "episode 4842, reward 1201.0, memory_length 2000, epsilon 3.059758581551675e-11 total_time 721.0\n",
      "episode 4843, reward 1133.0, memory_length 2000, epsilon 3.04449797196082e-11 total_time 726.0\n",
      "episode 4844, reward 1475.0, memory_length 2000, epsilon 3.0293134749778323e-11 total_time 723.0\n",
      "episode 4845, reward 1271.0, memory_length 2000, epsilon 3.0142047109894845e-11 total_time 722.0\n",
      "episode 4846, reward 1277.0, memory_length 2000, epsilon 2.999171302275912e-11 total_time 728.0\n",
      "episode 4847, reward 1222.0, memory_length 2000, epsilon 2.984212873001104e-11 total_time 725.0\n",
      "episode 4848, reward 1462.0, memory_length 2000, epsilon 2.969329049203538e-11 total_time 729.0\n",
      "episode 4849, reward 759.0, memory_length 2000, epsilon 2.954519458786866e-11 total_time 721.0\n",
      "episode 4850, reward 1201.0, memory_length 2000, epsilon 2.939783731510544e-11 total_time 731.0\n",
      "Saving Model 4850\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4851, reward 1106.0, memory_length 2000, epsilon 2.925121498980624e-11 total_time 725.0\n",
      "episode 4852, reward 883.0, memory_length 2000, epsilon 2.9105323946405183e-11 total_time 736.0\n",
      "episode 4853, reward 976.0, memory_length 2000, epsilon 2.89601605376188e-11 total_time 725.0\n",
      "episode 4854, reward 1390.0, memory_length 2000, epsilon 2.881572113435419e-11 total_time 726.0\n",
      "episode 4855, reward 1143.0, memory_length 2000, epsilon 2.8672002125618664e-11 total_time 721.0\n",
      "episode 4856, reward 887.0, memory_length 2000, epsilon 2.8528999918429712e-11 total_time 728.0\n",
      "episode 4857, reward 1140.0, memory_length 2000, epsilon 2.8386710937724605e-11 total_time 721.0\n",
      "episode 4858, reward 934.0, memory_length 2000, epsilon 2.8245131626271418e-11 total_time 731.0\n",
      "episode 4859, reward 1028.0, memory_length 2000, epsilon 2.8104258444579892e-11 total_time 727.0\n",
      "episode 4860, reward 827.0, memory_length 2000, epsilon 2.7964087870813343e-11 total_time 735.0\n",
      "Saving Model 4860\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4861, reward 1101.0, memory_length 2000, epsilon 2.782461640070003e-11 total_time 726.0\n",
      "episode 4862, reward 911.0, memory_length 2000, epsilon 2.7685840547445836e-11 total_time 722.0\n",
      "episode 4863, reward 862.0, memory_length 2000, epsilon 2.7547756841647395e-11 total_time 723.0\n",
      "episode 4864, reward 1580.0, memory_length 2000, epsilon 2.741036183120478e-11 total_time 725.0\n",
      "episode 4865, reward 895.0, memory_length 2000, epsilon 2.7273652081235564e-11 total_time 722.0\n",
      "episode 4866, reward 1356.0, memory_length 2000, epsilon 2.713762417398879e-11 total_time 722.0\n",
      "episode 4867, reward 1203.0, memory_length 2000, epsilon 2.700227470875988e-11 total_time 723.0\n",
      "episode 4868, reward 1040.0, memory_length 2000, epsilon 2.686760030180506e-11 total_time 728.0\n",
      "episode 4869, reward 1467.0, memory_length 2000, epsilon 2.6733597586257137e-11 total_time 728.0\n",
      "episode 4870, reward 1146.0, memory_length 2000, epsilon 2.6600263212041156e-11 total_time 722.0\n",
      "Saving Model 4870\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4871, reward 1337.0, memory_length 2000, epsilon 2.6467593845790997e-11 total_time 724.0\n",
      "episode 4872, reward 1423.0, memory_length 2000, epsilon 2.633558617076551e-11 total_time 722.0\n",
      "episode 4873, reward 1034.0, memory_length 2000, epsilon 2.620423688676584e-11 total_time 723.0\n",
      "episode 4874, reward 1380.0, memory_length 2000, epsilon 2.607354271005324e-11 total_time 729.0\n",
      "episode 4875, reward 1923.0, memory_length 2000, epsilon 2.594350037326639e-11 total_time 723.0\n",
      "episode 4876, reward 1567.0, memory_length 2000, epsilon 2.5814106625340098e-11 total_time 723.0\n",
      "episode 4877, reward 1309.0, memory_length 2000, epsilon 2.568535823142383e-11 total_time 723.0\n",
      "episode 4878, reward 1410.0, memory_length 2000, epsilon 2.555725197280122e-11 total_time 728.0\n",
      "episode 4879, reward 1286.0, memory_length 2000, epsilon 2.5429784646809034e-11 total_time 726.0\n",
      "episode 4880, reward 1470.0, memory_length 2000, epsilon 2.5302953066757402e-11 total_time 723.0\n",
      "Saving Model 4880\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4881, reward 1071.0, memory_length 2000, epsilon 2.5176754061850395e-11 total_time 725.0\n",
      "episode 4882, reward 1388.0, memory_length 2000, epsilon 2.5051184477106218e-11 total_time 724.0\n",
      "episode 4883, reward 1238.0, memory_length 2000, epsilon 2.4926241173278725e-11 total_time 721.0\n",
      "episode 4884, reward 1193.0, memory_length 2000, epsilon 2.4801921026778714e-11 total_time 721.0\n",
      "episode 4885, reward 1257.0, memory_length 2000, epsilon 2.4678220929596228e-11 total_time 722.0\n",
      "episode 4886, reward 1315.0, memory_length 2000, epsilon 2.455513778922231e-11 total_time 728.0\n",
      "episode 4887, reward 1607.0, memory_length 2000, epsilon 2.4432668528571948e-11 total_time 725.0\n",
      "episode 4888, reward 975.0, memory_length 2000, epsilon 2.4310810085907424e-11 total_time 722.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4889, reward 1548.0, memory_length 2000, epsilon 2.418955941476124e-11 total_time 733.0\n",
      "episode 4890, reward 1130.0, memory_length 2000, epsilon 2.406891348386029e-11 total_time 730.0\n",
      "Saving Model 4890\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4891, reward 898.0, memory_length 2000, epsilon 2.3948869277049947e-11 total_time 726.0\n",
      "episode 4892, reward 1215.0, memory_length 2000, epsilon 2.3829423793218955e-11 total_time 724.0\n",
      "episode 4893, reward 1015.0, memory_length 2000, epsilon 2.3710574046223906e-11 total_time 721.0\n",
      "episode 4894, reward 1362.0, memory_length 2000, epsilon 2.359231706481494e-11 total_time 728.0\n",
      "episode 4895, reward 1497.0, memory_length 2000, epsilon 2.347464989256128e-11 total_time 721.0\n",
      "episode 4896, reward 1081.0, memory_length 2000, epsilon 2.3357569587777654e-11 total_time 729.0\n",
      "episode 4897, reward 1682.0, memory_length 2000, epsilon 2.3241073223450268e-11 total_time 723.0\n",
      "episode 4898, reward 544.0, memory_length 2000, epsilon 2.3125157887163855e-11 total_time 721.0\n",
      "episode 4899, reward 680.0, memory_length 2000, epsilon 2.3009820681029142e-11 total_time 723.0\n",
      "episode 4900, reward 502.0, memory_length 2000, epsilon 2.2895058721609884e-11 total_time 721.0\n",
      "Saving Model 4900\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4901, reward 1076.0, memory_length 2000, epsilon 2.2780869139851115e-11 total_time 723.0\n",
      "episode 4902, reward 1609.0, memory_length 2000, epsilon 2.266724908100727e-11 total_time 724.0\n",
      "episode 4903, reward 884.0, memory_length 2000, epsilon 2.2554195704571114e-11 total_time 725.0\n",
      "episode 4904, reward 915.0, memory_length 2000, epsilon 2.2441706184202274e-11 total_time 730.0\n",
      "episode 4905, reward 1043.0, memory_length 2000, epsilon 2.23297777076568e-11 total_time 728.0\n",
      "episode 4906, reward 1081.0, memory_length 2000, epsilon 2.2218407476717105e-11 total_time 728.0\n",
      "episode 4907, reward 1036.0, memory_length 2000, epsilon 2.2107592707121535e-11 total_time 721.0\n",
      "episode 4908, reward 1451.0, memory_length 2000, epsilon 2.1997330628495085e-11 total_time 727.0\n",
      "episode 4909, reward 1156.0, memory_length 2000, epsilon 2.1887618484279962e-11 total_time 725.0\n",
      "episode 4910, reward 1386.0, memory_length 2000, epsilon 2.1778453531667007e-11 total_time 724.0\n",
      "Saving Model 4910\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4911, reward 1016.0, memory_length 2000, epsilon 2.166983304152664e-11 total_time 723.0\n",
      "episode 4912, reward 957.0, memory_length 2000, epsilon 2.156175429834087e-11 total_time 723.0\n",
      "episode 4913, reward 1593.0, memory_length 2000, epsilon 2.1454214600135642e-11 total_time 725.0\n",
      "episode 4914, reward 1144.0, memory_length 2000, epsilon 2.1347211258412828e-11 total_time 726.0\n",
      "episode 4915, reward 1267.0, memory_length 2000, epsilon 2.124074159808331e-11 total_time 722.0\n",
      "episode 4916, reward 1317.0, memory_length 2000, epsilon 2.1134802957399955e-11 total_time 724.0\n",
      "episode 4917, reward 1037.0, memory_length 2000, epsilon 2.1029392687891387e-11 total_time 723.0\n",
      "episode 4918, reward 1576.0, memory_length 2000, epsilon 2.0924508154295297e-11 total_time 730.0\n",
      "episode 4919, reward 843.0, memory_length 2000, epsilon 2.082014673449288e-11 total_time 723.0\n",
      "episode 4920, reward 1160.0, memory_length 2000, epsilon 2.0716305819443136e-11 total_time 730.0\n",
      "Saving Model 4920\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4921, reward 1482.0, memory_length 2000, epsilon 2.0612982813117928e-11 total_time 724.0\n",
      "episode 4922, reward 1220.0, memory_length 2000, epsilon 2.0510175132436637e-11 total_time 729.0\n",
      "episode 4923, reward 1163.0, memory_length 2000, epsilon 2.040788020720183e-11 total_time 724.0\n",
      "episode 4924, reward 976.0, memory_length 2000, epsilon 2.0306095480035182e-11 total_time 722.0\n",
      "episode 4925, reward 1089.0, memory_length 2000, epsilon 2.0204818406313147e-11 total_time 729.0\n",
      "episode 4926, reward 1491.0, memory_length 2000, epsilon 2.010404645410361e-11 total_time 732.0\n",
      "episode 4927, reward 1134.0, memory_length 2000, epsilon 2.0003777104102433e-11 total_time 721.0\n",
      "episode 4928, reward 880.0, memory_length 2000, epsilon 1.9904007849570796e-11 total_time 725.0\n",
      "episode 4929, reward 1449.0, memory_length 2000, epsilon 1.9804736196272068e-11 total_time 728.0\n",
      "episode 4930, reward 1162.0, memory_length 2000, epsilon 1.9705959662409672e-11 total_time 721.0\n",
      "Saving Model 4930\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4931, reward 1696.0, memory_length 2000, epsilon 1.9607675778565262e-11 total_time 723.0\n",
      "episode 4932, reward 915.0, memory_length 2000, epsilon 1.9509882087636544e-11 total_time 725.0\n",
      "episode 4933, reward 1550.0, memory_length 2000, epsilon 1.9412576144776164e-11 total_time 727.0\n",
      "episode 4934, reward 1424.0, memory_length 2000, epsilon 1.9315755517330403e-11 total_time 724.0\n",
      "episode 4935, reward 913.0, memory_length 2000, epsilon 1.9219417784778677e-11 total_time 728.0\n",
      "episode 4936, reward 1209.0, memory_length 2000, epsilon 1.9123560538672582e-11 total_time 727.0\n",
      "episode 4937, reward 917.0, memory_length 2000, epsilon 1.9028181382575904e-11 total_time 725.0\n",
      "episode 4938, reward 942.0, memory_length 2000, epsilon 1.893327793200491e-11 total_time 728.0\n",
      "episode 4939, reward 1399.0, memory_length 2000, epsilon 1.8838847814368325e-11 total_time 730.0\n",
      "episode 4940, reward 1076.0, memory_length 2000, epsilon 1.874488866890829e-11 total_time 729.0\n",
      "Saving Model 4940\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4941, reward 1089.0, memory_length 2000, epsilon 1.8651398146641206e-11 total_time 723.0\n",
      "episode 4942, reward 902.0, memory_length 2000, epsilon 1.8558373910299287e-11 total_time 724.0\n",
      "episode 4943, reward 1843.0, memory_length 2000, epsilon 1.8465813634271704e-11 total_time 730.0\n",
      "episode 4944, reward 1566.0, memory_length 2000, epsilon 1.8373715004546746e-11 total_time 726.0\n",
      "episode 4945, reward 950.0, memory_length 2000, epsilon 1.8282075718653795e-11 total_time 734.0\n",
      "episode 4946, reward 1500.0, memory_length 2000, epsilon 1.819089348560607e-11 total_time 724.0\n",
      "episode 4947, reward 1066.0, memory_length 2000, epsilon 1.8100166025842928e-11 total_time 721.0\n",
      "episode 4948, reward 1169.0, memory_length 2000, epsilon 1.8009891071173085e-11 total_time 727.0\n",
      "episode 4949, reward 1265.0, memory_length 2000, epsilon 1.79200663647181e-11 total_time 723.0\n",
      "episode 4950, reward 1417.0, memory_length 2000, epsilon 1.7830689660855573e-11 total_time 724.0\n",
      "Saving Model 4950\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4951, reward 1409.0, memory_length 2000, epsilon 1.774175872516325e-11 total_time 729.0\n",
      "episode 4952, reward 1279.0, memory_length 2000, epsilon 1.7653271334363044e-11 total_time 724.0\n",
      "episode 4953, reward 982.0, memory_length 2000, epsilon 1.75652252762657e-11 total_time 723.0\n",
      "episode 4954, reward 1233.0, memory_length 2000, epsilon 1.747761834971512e-11 total_time 723.0\n",
      "episode 4955, reward 1292.0, memory_length 2000, epsilon 1.7390448364533514e-11 total_time 728.0\n",
      "episode 4956, reward 1260.0, memory_length 2000, epsilon 1.7303713141466838e-11 total_time 723.0\n",
      "episode 4957, reward 1089.0, memory_length 2000, epsilon 1.7217410512129933e-11 total_time 728.0\n",
      "episode 4958, reward 1006.0, memory_length 2000, epsilon 1.713153831895257e-11 total_time 723.0\n",
      "episode 4959, reward 1071.0, memory_length 2000, epsilon 1.704609441512539e-11 total_time 726.0\n",
      "episode 4960, reward 1114.0, memory_length 2000, epsilon 1.696107666454647e-11 total_time 727.0\n",
      "Saving Model 4960\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4961, reward 1348.0, memory_length 2000, epsilon 1.6876482941767548e-11 total_time 721.0\n",
      "episode 4962, reward 1164.0, memory_length 2000, epsilon 1.67923111319411e-11 total_time 722.0\n",
      "episode 4963, reward 939.0, memory_length 2000, epsilon 1.6708559130767605e-11 total_time 721.0\n",
      "episode 4964, reward 1604.0, memory_length 2000, epsilon 1.6625224844442622e-11 total_time 722.0\n",
      "episode 4965, reward 1267.0, memory_length 2000, epsilon 1.6542306189604645e-11 total_time 721.0\n",
      "episode 4966, reward 1505.0, memory_length 2000, epsilon 1.645980109328293e-11 total_time 723.0\n",
      "episode 4967, reward 1685.0, memory_length 2000, epsilon 1.6377707492845887e-11 total_time 727.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4968, reward 1176.0, memory_length 2000, epsilon 1.6296023335949172e-11 total_time 723.0\n",
      "episode 4969, reward 1181.0, memory_length 2000, epsilon 1.6214746580484607e-11 total_time 724.0\n",
      "episode 4970, reward 1420.0, memory_length 2000, epsilon 1.6133875194529016e-11 total_time 724.0\n",
      "Saving Model 4970\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4971, reward 1736.0, memory_length 2000, epsilon 1.605340715629365e-11 total_time 722.0\n",
      "episode 4972, reward 1517.0, memory_length 2000, epsilon 1.597334045407331e-11 total_time 727.0\n",
      "episode 4973, reward 915.0, memory_length 2000, epsilon 1.5893673086196207e-11 total_time 726.0\n",
      "episode 4974, reward 1313.0, memory_length 2000, epsilon 1.5814403060974117e-11 total_time 722.0\n",
      "episode 4975, reward 1319.0, memory_length 2000, epsilon 1.5735528396652215e-11 total_time 723.0\n",
      "episode 4976, reward 1336.0, memory_length 2000, epsilon 1.565704712135979e-11 total_time 724.0\n",
      "episode 4977, reward 1009.0, memory_length 2000, epsilon 1.5578957273060813e-11 total_time 721.0\n",
      "episode 4978, reward 1590.0, memory_length 2000, epsilon 1.5501256899505126e-11 total_time 734.0\n",
      "episode 4979, reward 1558.0, memory_length 2000, epsilon 1.5423944058179282e-11 total_time 722.0\n",
      "episode 4980, reward 1160.0, memory_length 2000, epsilon 1.534701681625817e-11 total_time 722.0\n",
      "Saving Model 4980\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4981, reward 1244.0, memory_length 2000, epsilon 1.527047325055684e-11 total_time 726.0\n",
      "episode 4982, reward 1129.0, memory_length 2000, epsilon 1.5194311447482118e-11 total_time 723.0\n",
      "episode 4983, reward 791.0, memory_length 2000, epsilon 1.5118529502984952e-11 total_time 722.0\n",
      "episode 4984, reward 1387.0, memory_length 2000, epsilon 1.504312552251273e-11 total_time 721.0\n",
      "episode 4985, reward 1334.0, memory_length 2000, epsilon 1.496809762096212e-11 total_time 724.0\n",
      "episode 4986, reward 1258.0, memory_length 2000, epsilon 1.4893443922631623e-11 total_time 721.0\n",
      "episode 4987, reward 1264.0, memory_length 2000, epsilon 1.481916256117484e-11 total_time 726.0\n",
      "episode 4988, reward 1475.0, memory_length 2000, epsilon 1.4745251679553972e-11 total_time 722.0\n",
      "episode 4989, reward 1163.0, memory_length 2000, epsilon 1.4671709429993075e-11 total_time 727.0\n",
      "episode 4990, reward 1169.0, memory_length 2000, epsilon 1.459853397393208e-11 total_time 730.0\n",
      "Saving Model 4990\n",
      "INFO:tensorflow:Assets written to: model_weights.pkl/assets\n",
      "episode 4991, reward 1256.0, memory_length 2000, epsilon 1.4525723481980722e-11 total_time 721.0\n",
      "episode 4992, reward 1595.0, memory_length 2000, epsilon 1.4453276133873014e-11 total_time 728.0\n",
      "episode 4993, reward 1365.0, memory_length 2000, epsilon 1.438119011842143e-11 total_time 725.0\n",
      "episode 4994, reward 1191.0, memory_length 2000, epsilon 1.4309463633471825e-11 total_time 726.0\n",
      "episode 4995, reward 786.0, memory_length 2000, epsilon 1.4238094885858292e-11 total_time 724.0\n",
      "episode 4996, reward 1406.0, memory_length 2000, epsilon 1.4167082091358525e-11 total_time 721.0\n",
      "episode 4997, reward 1156.0, memory_length 2000, epsilon 1.409642347464891e-11 total_time 726.0\n",
      "episode 4998, reward 1374.0, memory_length 2000, epsilon 1.4026117269260301e-11 total_time 726.0\n",
      "episode 4999, reward 1333.0, memory_length 2000, epsilon 1.3956161717534001e-11 total_time 723.0\n",
      "17037.15041089058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    \n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    total_time=0\n",
    "    terminal_state = False\n",
    "    env = CabDriver()\n",
    "    action_space, state_space, state = env.reset()\n",
    "    \n",
    "    # Saving the initial state such that Reward can be tracked if initial state is [0,0,0]\n",
    "    initial_state = env.state_init\n",
    "    \n",
    "    count=0\n",
    "    total_reward = 0\n",
    "    while not terminal_state:\n",
    "        count+=1\n",
    "        possible_actions_index,actions=env.requests(state)\n",
    "        action = agent.get_action(state, possible_actions_index)\n",
    "        reward = env.reward_func(state,env.action_space[action], Time_matrix)\n",
    "        next_state,total_time_elapsed = env.next_state_func(state, env.action_space[action], Time_matrix)\n",
    "        \n",
    "        total_time += total_time_elapsed\n",
    "        \n",
    "        if total_time > episode_time:\n",
    "            terminal_state=True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "                \n",
    "        # 3. Append the experience to the memory\n",
    "        agent.append_sample(state, action, reward, next_state)\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "            \n",
    "        if count%20 == 0:\n",
    "            # 4. Train the model by calling function agent.train_model\n",
    "            # 5. Keep a track of rewards, Q-values, loss\n",
    "            agent.train_model()\n",
    "            \n",
    "    rewards_per_episode.append(total_reward) \n",
    "    episodes.append(episode)\n",
    "    #Epsilon value based on epsilon decay rate , new epsilon value is getting assigned to Agent object of DQNAgent class\n",
    "    agent.epsilon = (1 - 0.0001) * np.exp(agent.epsilon_decay * episode)\n",
    "    \n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3} total_time {4}\".format(episode,\n",
    "                                                                         total_reward,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time))\n",
    "    if ((episode + 1) % 5 == 0):            \n",
    "            agent.save_tracking_states()\n",
    "    \n",
    "    if (episode%10 ==0):\n",
    "        #saving model and weights every 100th episode\n",
    "        print(\"Saving Model {}\".format(episode))\n",
    "        agent.model.save_weights(\"model_weights.h5\")\n",
    "        agent.save(name=\"model_weights.pkl\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.20806,\n",
       " 471.11908,\n",
       " 1012.0354,\n",
       " 727.4973,\n",
       " 439.68338,\n",
       " 266.6029,\n",
       " 214.20538,\n",
       " 197.86847,\n",
       " 199.00885,\n",
       " 266.3648,\n",
       " 245.3345,\n",
       " 248.66574,\n",
       " 258.05414,\n",
       " 217.51408,\n",
       " 236.89003,\n",
       " 247.72359,\n",
       " 284.79514,\n",
       " 270.34015,\n",
       " 304.0873,\n",
       " 356.0923,\n",
       " 261.72937,\n",
       " 330.87723,\n",
       " 492.62946,\n",
       " 353.21722,\n",
       " 385.91647,\n",
       " 395.14297,\n",
       " 694.1699,\n",
       " 586.3237,\n",
       " 692.4972,\n",
       " 428.60593,\n",
       " 454.4073,\n",
       " 520.42816,\n",
       " 467.19785,\n",
       " 635.79706,\n",
       " 452.31003,\n",
       " 464.28363,\n",
       " 477.0906,\n",
       " 485.22552,\n",
       " 558.3089,\n",
       " 671.45526,\n",
       " 652.7935,\n",
       " 721.5083,\n",
       " 1386.385,\n",
       " 3124.165,\n",
       " 2678.649,\n",
       " 2872.1636,\n",
       " 1397.8065,\n",
       " 760.0901,\n",
       " 550.0281,\n",
       " 470.26666,\n",
       " 439.45386,\n",
       " 427.26663,\n",
       " 407.2672,\n",
       " 388.4875,\n",
       " 387.39124,\n",
       " 390.5004,\n",
       " 394.00772,\n",
       " 397.3357,\n",
       " 407.73135,\n",
       " 411.67575,\n",
       " 416.31052,\n",
       " 413.0378,\n",
       " 403.36298,\n",
       " 391.2764,\n",
       " 387.31412,\n",
       " 394.52234,\n",
       " 410.40533,\n",
       " 431.5375,\n",
       " 450.84592,\n",
       " 463.9952,\n",
       " 483.59256,\n",
       " 491.7103,\n",
       " 494.8264,\n",
       " 475.2223,\n",
       " 449.38635,\n",
       " 438.19196,\n",
       " 449.9212,\n",
       " 470.13058,\n",
       " 499.29523,\n",
       " 504.73444,\n",
       " 501.32867,\n",
       " 483.17523,\n",
       " 443.94104,\n",
       " 432.74026,\n",
       " 451.37134,\n",
       " 471.73764,\n",
       " 471.00797,\n",
       " 458.8192,\n",
       " 483.65128,\n",
       " 541.43665,\n",
       " 571.4,\n",
       " 495.72983,\n",
       " 451.43253,\n",
       " 450.70184,\n",
       " 453.60477,\n",
       " 474.2969,\n",
       " 485.81842,\n",
       " 494.10745,\n",
       " 495.3393,\n",
       " 493.32474,\n",
       " 474.55563,\n",
       " 490.79037,\n",
       " 510.71283,\n",
       " 524.7101,\n",
       " 529.76447,\n",
       " 508.20654,\n",
       " 500.75177,\n",
       " 477.30722,\n",
       " 484.05545,\n",
       " 542.5692,\n",
       " 517.14484,\n",
       " 489.24756,\n",
       " 491.16708,\n",
       " 505.85052,\n",
       " 511.05408,\n",
       " 511.15536,\n",
       " 475.6659,\n",
       " 481.47726,\n",
       " 516.7449,\n",
       " 526.93646,\n",
       " 500.4259,\n",
       " 487.1622,\n",
       " 509.51495,\n",
       " 519.1488,\n",
       " 528.3209,\n",
       " 589.7358,\n",
       " 509.78183,\n",
       " 476.49103,\n",
       " 553.7707,\n",
       " 519.4262,\n",
       " 458.99054,\n",
       " 520.5534,\n",
       " 634.8725,\n",
       " 591.92236,\n",
       " 463.5604,\n",
       " 553.3853,\n",
       " 539.27515,\n",
       " 443.82068,\n",
       " 564.70105,\n",
       " 560.2555,\n",
       " 463.77313,\n",
       " 542.3339,\n",
       " 590.1201,\n",
       " 538.9073,\n",
       " 579.9764,\n",
       " 576.1763,\n",
       " 575.8084,\n",
       " 543.1316,\n",
       " 541.40314,\n",
       " 527.1895,\n",
       " 515.5627,\n",
       " 535.2159,\n",
       " 555.4095,\n",
       " 567.3881,\n",
       " 504.9484,\n",
       " 581.334,\n",
       " 551.2397,\n",
       " 552.5617,\n",
       " 642.1633,\n",
       " 500.13632,\n",
       " 544.9893,\n",
       " 544.701,\n",
       " 553.1025,\n",
       " 580.07306,\n",
       " 612.51056,\n",
       " 533.47504,\n",
       " 575.2275,\n",
       " 590.3459,\n",
       " 557.30585,\n",
       " 520.0705,\n",
       " 521.5196,\n",
       " 603.8473,\n",
       " 525.03015,\n",
       " 569.1719,\n",
       " 558.6473,\n",
       " 629.7878,\n",
       " 563.3839,\n",
       " 523.5515,\n",
       " 694.44293,\n",
       " 530.04456,\n",
       " 587.3088,\n",
       " 539.5226,\n",
       " 585.4459,\n",
       " 450.04846,\n",
       " 592.916,\n",
       " 533.7806,\n",
       " 569.09875,\n",
       " 551.4318,\n",
       " 642.1909,\n",
       " 525.5118,\n",
       " 573.522,\n",
       " 593.3722,\n",
       " 603.57074,\n",
       " 676.22064,\n",
       " 661.7656,\n",
       " 552.25024,\n",
       " 669.846,\n",
       " 524.99817,\n",
       " 661.93445,\n",
       " 531.24896,\n",
       " 565.17206,\n",
       " 638.48126,\n",
       " 575.90015,\n",
       " 606.6704,\n",
       " 564.87,\n",
       " 726.88495,\n",
       " 588.52106,\n",
       " 554.72174,\n",
       " 588.2401,\n",
       " 621.31384,\n",
       " 638.9643,\n",
       " 508.53418,\n",
       " 650.25116,\n",
       " 677.58374,\n",
       " 719.94794,\n",
       " 706.1475,\n",
       " 747.46735,\n",
       " 568.6574,\n",
       " 689.0536,\n",
       " 607.522,\n",
       " 626.4824,\n",
       " 547.99243,\n",
       " 611.2711,\n",
       " 671.85535,\n",
       " 554.9068,\n",
       " 583.69385,\n",
       " 643.15125,\n",
       " 705.9403,\n",
       " 668.3563,\n",
       " 576.75836,\n",
       " 642.2551,\n",
       " 632.00275,\n",
       " 540.6746,\n",
       " 640.66675,\n",
       " 520.7596,\n",
       " 725.62897,\n",
       " 642.2452,\n",
       " 583.809,\n",
       " 693.1562,\n",
       " 674.68756,\n",
       " 613.5617,\n",
       " 624.47345,\n",
       " 627.18176,\n",
       " 639.16656,\n",
       " 547.4199,\n",
       " 577.56104,\n",
       " 581.7191,\n",
       " 760.4394,\n",
       " 622.83936,\n",
       " 661.8087,\n",
       " 525.57495,\n",
       " 599.7851,\n",
       " 598.3691,\n",
       " 576.1019,\n",
       " 683.5975,\n",
       " 729.38715,\n",
       " 625.3681,\n",
       " 602.7612,\n",
       " 615.61066,\n",
       " 637.29297,\n",
       " 647.01636,\n",
       " 656.95404,\n",
       " 604.7647,\n",
       " 711.1193,\n",
       " 644.1896,\n",
       " 580.0006,\n",
       " 603.7534,\n",
       " 875.5345,\n",
       " 724.7294,\n",
       " 640.8119,\n",
       " 632.37756,\n",
       " 618.31506,\n",
       " 704.71344,\n",
       " 576.3685,\n",
       " 565.10956,\n",
       " 579.07117,\n",
       " 627.20154,\n",
       " 786.3232,\n",
       " 738.1273,\n",
       " 738.21075,\n",
       " 641.0728,\n",
       " 579.99176,\n",
       " 752.7744,\n",
       " 502.32886,\n",
       " 644.3562,\n",
       " 652.6279,\n",
       " 512.3865,\n",
       " 697.995,\n",
       " 719.6363,\n",
       " 795.7716,\n",
       " 858.797,\n",
       " 890.23804,\n",
       " 498.97232,\n",
       " 620.0729,\n",
       " 529.3537,\n",
       " 584.8261,\n",
       " 640.9815,\n",
       " 553.1566,\n",
       " 629.5728,\n",
       " 582.8352,\n",
       " 604.9027,\n",
       " 569.5394,\n",
       " 552.2271,\n",
       " 582.6074,\n",
       " 625.665,\n",
       " 644.59546,\n",
       " 526.6967,\n",
       " 779.37213,\n",
       " 849.85,\n",
       " 890.5597,\n",
       " 615.4785,\n",
       " 765.03723,\n",
       " 573.3122,\n",
       " 558.6719,\n",
       " 667.74615,\n",
       " 517.627,\n",
       " 824.8818,\n",
       " 560.1426,\n",
       " 556.86786,\n",
       " 582.37054,\n",
       " 633.3619,\n",
       " 650.2842,\n",
       " 622.92847,\n",
       " 626.6456,\n",
       " 576.67615,\n",
       " 759.65,\n",
       " 573.57855,\n",
       " 764.1299,\n",
       " 661.17975,\n",
       " 563.288,\n",
       " 618.4549,\n",
       " 604.83484,\n",
       " 554.7687,\n",
       " 615.6504,\n",
       " 686.67395,\n",
       " 549.7134,\n",
       " 644.3722,\n",
       " 583.8724,\n",
       " 676.29803,\n",
       " 586.25995,\n",
       " 740.3657,\n",
       " 580.5563,\n",
       " 647.97363,\n",
       " 658.122,\n",
       " 572.61676,\n",
       " 706.0424,\n",
       " 649.2648,\n",
       " 901.08014,\n",
       " 856.6512,\n",
       " 878.0967,\n",
       " 684.5424,\n",
       " 641.8349,\n",
       " 597.1268,\n",
       " 640.06256,\n",
       " 548.42615,\n",
       " 620.26605,\n",
       " 580.1822,\n",
       " 609.0454,\n",
       " 604.8471,\n",
       " 556.4615,\n",
       " 687.8876,\n",
       " 723.3608,\n",
       " 535.76044,\n",
       " 579.9052,\n",
       " 606.2777,\n",
       " 606.05414,\n",
       " 532.3709,\n",
       " 774.0504,\n",
       " 818.3799,\n",
       " 584.9906,\n",
       " 633.9119,\n",
       " 704.9046,\n",
       " 611.2482,\n",
       " 664.4666,\n",
       " 660.8291,\n",
       " 596.7254,\n",
       " 754.32544,\n",
       " 633.40015,\n",
       " 690.7006,\n",
       " 600.0421,\n",
       " 537.6735,\n",
       " 601.477,\n",
       " 652.4163,\n",
       " 636.6874,\n",
       " 755.4989,\n",
       " 731.0109,\n",
       " 709.13385,\n",
       " 560.40393,\n",
       " 585.2334,\n",
       " 531.94635,\n",
       " 486.2185,\n",
       " 541.2527,\n",
       " 601.5292,\n",
       " 623.22546,\n",
       " 596.81256,\n",
       " 604.743,\n",
       " 536.99005,\n",
       " 604.1178,\n",
       " 552.136,\n",
       " 683.19836,\n",
       " 713.1461,\n",
       " 832.17163,\n",
       " 901.0686,\n",
       " 1094.0253,\n",
       " 760.70905,\n",
       " 809.92706,\n",
       " 646.1784,\n",
       " 496.41876,\n",
       " 558.50006,\n",
       " 611.73566,\n",
       " 545.0509,\n",
       " 559.1723,\n",
       " 649.1938,\n",
       " 579.5908,\n",
       " 598.431,\n",
       " 590.12585,\n",
       " 584.1449,\n",
       " 683.1735,\n",
       " 610.3696,\n",
       " 577.07635,\n",
       " 641.08655,\n",
       " 543.76733,\n",
       " 666.49097,\n",
       " 587.6863,\n",
       " 641.57465,\n",
       " 547.7237,\n",
       " 621.38196,\n",
       " 686.6056,\n",
       " 600.9788,\n",
       " 593.159,\n",
       " 618.8364,\n",
       " 549.32294,\n",
       " 628.382,\n",
       " 603.67303,\n",
       " 624.42377,\n",
       " 515.9969,\n",
       " 596.48047,\n",
       " 624.0894,\n",
       " 596.84064,\n",
       " 586.27094,\n",
       " 698.3781,\n",
       " 562.8653,\n",
       " 542.9617,\n",
       " 639.20667,\n",
       " 630.3716,\n",
       " 593.7741,\n",
       " 590.6211,\n",
       " 574.7371,\n",
       " 630.7258,\n",
       " 561.9727,\n",
       " 646.24335,\n",
       " 631.1445,\n",
       " 668.59406,\n",
       " 595.0853,\n",
       " 563.94745,\n",
       " 627.80786,\n",
       " 608.1866,\n",
       " 581.87964,\n",
       " 546.7879,\n",
       " 642.5642,\n",
       " 641.29175,\n",
       " 682.2825,\n",
       " 545.64966,\n",
       " 688.42456,\n",
       " 804.7531,\n",
       " 666.78284,\n",
       " 692.4436,\n",
       " 630.4335,\n",
       " 554.3431,\n",
       " 523.2249,\n",
       " 624.90173,\n",
       " 540.84235,\n",
       " 607.2222,\n",
       " 651.84204,\n",
       " 675.25995,\n",
       " 592.5488,\n",
       " 634.9907,\n",
       " 670.9689,\n",
       " 672.2473,\n",
       " 552.2374,\n",
       " 671.7086,\n",
       " 725.78094,\n",
       " 604.31946,\n",
       " 758.85205,\n",
       " 580.8367,\n",
       " 761.7549,\n",
       " 863.4418,\n",
       " 618.9508,\n",
       " 765.06396,\n",
       " 726.0044,\n",
       " 738.89764,\n",
       " 589.1172,\n",
       " 496.87277,\n",
       " 636.5685,\n",
       " 617.656,\n",
       " 554.696,\n",
       " 674.0325,\n",
       " 628.40643,\n",
       " 545.7157,\n",
       " 812.70264,\n",
       " 658.1632,\n",
       " 610.33923,\n",
       " 603.16425,\n",
       " 569.506,\n",
       " 604.1214,\n",
       " 593.2163,\n",
       " 630.4003,\n",
       " 687.65515,\n",
       " 703.97534,\n",
       " 816.6364,\n",
       " 625.3278,\n",
       " 506.9201,\n",
       " 609.8087,\n",
       " 576.53,\n",
       " 682.8421,\n",
       " 593.0126,\n",
       " 653.646,\n",
       " 635.40027,\n",
       " 698.043,\n",
       " 614.1696,\n",
       " 572.2288,\n",
       " 693.5879,\n",
       " 550.478,\n",
       " 646.22107,\n",
       " 597.0631,\n",
       " 582.85944,\n",
       " 766.3496,\n",
       " 693.5237,\n",
       " 558.9352,\n",
       " 606.9389,\n",
       " 508.83658,\n",
       " 745.0462,\n",
       " 639.5507,\n",
       " 587.7478,\n",
       " 551.7134,\n",
       " 592.24335,\n",
       " 538.9458,\n",
       " 584.4589,\n",
       " 549.58276,\n",
       " 588.72784,\n",
       " 597.678,\n",
       " 580.49896,\n",
       " 652.52655,\n",
       " 556.7122,\n",
       " 647.82367,\n",
       " 631.18445,\n",
       " 611.0999,\n",
       " 607.6381,\n",
       " 557.1101,\n",
       " 678.8372,\n",
       " 488.0454,\n",
       " 624.0039,\n",
       " 591.4565,\n",
       " 643.4268,\n",
       " 608.4635,\n",
       " 595.9569,\n",
       " 634.1829,\n",
       " 677.4567,\n",
       " 572.91724,\n",
       " 691.151,\n",
       " 585.4741,\n",
       " 601.932,\n",
       " 610.1072,\n",
       " 577.4794,\n",
       " 601.3407,\n",
       " 601.7605,\n",
       " 610.6882,\n",
       " 689.7274,\n",
       " 628.3887,\n",
       " 652.3409,\n",
       " 620.9119,\n",
       " 516.71094,\n",
       " 620.7906,\n",
       " 634.0593,\n",
       " 549.62775,\n",
       " 636.0051,\n",
       " 542.55133,\n",
       " 529.9054,\n",
       " 661.4563,\n",
       " 539.3593,\n",
       " 746.3998,\n",
       " 607.12335,\n",
       " 560.3153,\n",
       " 644.5915,\n",
       " 620.7464,\n",
       " 739.78033,\n",
       " 589.25146,\n",
       " 739.2629,\n",
       " 579.97516,\n",
       " 605.3806,\n",
       " 615.8035,\n",
       " 729.8895,\n",
       " 559.0164,\n",
       " 584.9404,\n",
       " 679.73865,\n",
       " 666.49316,\n",
       " 540.6516,\n",
       " 710.6162,\n",
       " 702.9832,\n",
       " 735.92645,\n",
       " 698.0897,\n",
       " 606.4714,\n",
       " 633.04004,\n",
       " 603.0723,\n",
       " 723.00635,\n",
       " 567.8939,\n",
       " 588.5253,\n",
       " 659.5215,\n",
       " 672.8098,\n",
       " 576.4368,\n",
       " 676.9186,\n",
       " 561.55774,\n",
       " 687.3292,\n",
       " 664.6491,\n",
       " 668.9817,\n",
       " 781.3216,\n",
       " 645.1756,\n",
       " 685.0528,\n",
       " 602.95197,\n",
       " 663.0235,\n",
       " 690.0645,\n",
       " 609.24365,\n",
       " 606.84717,\n",
       " 680.2328,\n",
       " 584.372,\n",
       " 615.13745,\n",
       " 633.54865,\n",
       " 652.82385,\n",
       " 614.22107,\n",
       " 691.30255,\n",
       " 597.158,\n",
       " 617.0396,\n",
       " 660.06836,\n",
       " 581.04236,\n",
       " 753.3557,\n",
       " 658.4093,\n",
       " 639.4127,\n",
       " 595.4489,\n",
       " 645.2235,\n",
       " 592.30145,\n",
       " 604.0529,\n",
       " 789.3997,\n",
       " 684.34827,\n",
       " 636.8246,\n",
       " 739.4703,\n",
       " 629.86346,\n",
       " 604.2282,\n",
       " 616.26794,\n",
       " 695.2505,\n",
       " 631.7485,\n",
       " 774.5596,\n",
       " 870.2747,\n",
       " 871.82825,\n",
       " 741.3328,\n",
       " 500.62186,\n",
       " 516.7456,\n",
       " 609.64734,\n",
       " 553.007,\n",
       " 588.3341,\n",
       " 649.25305,\n",
       " 553.3374,\n",
       " 570.7817,\n",
       " 690.5782,\n",
       " 596.09326,\n",
       " 631.68567,\n",
       " 589.4846,\n",
       " 598.50916,\n",
       " 651.62885,\n",
       " 639.589,\n",
       " 701.5638,\n",
       " 595.8068,\n",
       " 785.7534,\n",
       " 674.59753,\n",
       " 695.4456,\n",
       " 630.05676,\n",
       " 669.08844,\n",
       " 682.907,\n",
       " 652.9678,\n",
       " 757.45667,\n",
       " 660.9694,\n",
       " 678.4117,\n",
       " 711.283,\n",
       " 646.6495,\n",
       " 717.874,\n",
       " 685.4852,\n",
       " 653.1758,\n",
       " 658.7672,\n",
       " 677.51984,\n",
       " 690.1071,\n",
       " 707.0691,\n",
       " 714.2779,\n",
       " 691.8652,\n",
       " 672.62854,\n",
       " 665.5934,\n",
       " 695.44385,\n",
       " 703.3438,\n",
       " 654.6705,\n",
       " 790.94684,\n",
       " 608.7102,\n",
       " 709.9265,\n",
       " 633.4029,\n",
       " 646.01025,\n",
       " 701.81244,\n",
       " 624.538,\n",
       " 664.49554,\n",
       " 690.7944,\n",
       " 640.2633,\n",
       " 723.0447,\n",
       " 716.126,\n",
       " 767.6855,\n",
       " 609.4983,\n",
       " 753.53906,\n",
       " 744.25995,\n",
       " 704.9518,\n",
       " 820.7097,\n",
       " 567.57935,\n",
       " 628.23254,\n",
       " 810.49164,\n",
       " 656.122,\n",
       " 715.10504,\n",
       " 786.4727,\n",
       " 659.65137,\n",
       " 697.5622,\n",
       " 698.1236,\n",
       " 674.0769,\n",
       " 798.55225,\n",
       " 694.43604,\n",
       " 685.98016,\n",
       " 803.0733,\n",
       " 744.99786,\n",
       " 722.61786,\n",
       " 691.7246,\n",
       " 758.7501,\n",
       " 644.3518,\n",
       " 720.90314,\n",
       " 734.9019,\n",
       " 696.98553,\n",
       " 709.38824,\n",
       " 720.7406,\n",
       " 798.2266,\n",
       " 645.7896,\n",
       " 764.5254,\n",
       " 693.94885,\n",
       " 723.4683,\n",
       " 785.5751,\n",
       " 706.30756,\n",
       " 777.2841,\n",
       " 718.4657,\n",
       " 661.6756,\n",
       " 833.8048,\n",
       " 844.4004,\n",
       " 810.51373,\n",
       " 768.9039,\n",
       " 689.28955,\n",
       " 828.5945,\n",
       " 716.1374,\n",
       " 737.61505,\n",
       " 799.57227,\n",
       " 663.91095,\n",
       " 708.11206,\n",
       " 795.24176,\n",
       " 714.28107,\n",
       " 779.11237,\n",
       " 876.1229,\n",
       " 661.0527,\n",
       " 708.74664,\n",
       " 907.9459,\n",
       " 805.5365,\n",
       " 650.0411,\n",
       " 766.14954,\n",
       " 668.77325,\n",
       " 776.0543,\n",
       " 663.4315,\n",
       " 721.7969,\n",
       " 707.7047,\n",
       " 820.1178,\n",
       " 797.89655,\n",
       " 687.003,\n",
       " 789.1123,\n",
       " 782.5585,\n",
       " 667.17444,\n",
       " 815.5478,\n",
       " 798.6899,\n",
       " 752.361,\n",
       " 747.38336,\n",
       " 775.33856,\n",
       " 676.2685,\n",
       " 675.58154,\n",
       " 871.171,\n",
       " 757.5475,\n",
       " 737.37756,\n",
       " 787.194,\n",
       " 728.2845,\n",
       " 827.9373,\n",
       " 765.2539,\n",
       " 677.8952,\n",
       " 742.96027,\n",
       " 784.811,\n",
       " 769.60376,\n",
       " 811.46826,\n",
       " 731.0374,\n",
       " 711.61414,\n",
       " 801.2275,\n",
       " 751.93146,\n",
       " 753.1301,\n",
       " 777.3992,\n",
       " 785.02136,\n",
       " 816.75183,\n",
       " 772.4909,\n",
       " 813.9853,\n",
       " 750.522,\n",
       " 764.30597,\n",
       " 809.82477,\n",
       " 751.53125,\n",
       " 768.204,\n",
       " 773.9217,\n",
       " 740.9813,\n",
       " 804.4056,\n",
       " 721.66614,\n",
       " 741.72437,\n",
       " 708.3668,\n",
       " 959.0935,\n",
       " 721.2848,\n",
       " 768.6002,\n",
       " 751.98816,\n",
       " 749.3568,\n",
       " 775.2605,\n",
       " 696.95166,\n",
       " 745.9433,\n",
       " 775.9482,\n",
       " 659.50854,\n",
       " 771.75653,\n",
       " 750.3157,\n",
       " 704.8315,\n",
       " 748.9574,\n",
       " 749.0732,\n",
       " 707.2633,\n",
       " 713.4203,\n",
       " 775.56964,\n",
       " 680.8201,\n",
       " 763.5937,\n",
       " 739.5199,\n",
       " 700.49805,\n",
       " 840.3893,\n",
       " 719.4936,\n",
       " 728.8763,\n",
       " 697.1004,\n",
       " 876.49756,\n",
       " 724.68616,\n",
       " 706.29065,\n",
       " 911.0062,\n",
       " 806.64624,\n",
       " 813.3023,\n",
       " 743.0939,\n",
       " 835.4288,\n",
       " 752.8919,\n",
       " 694.74805,\n",
       " 816.62445,\n",
       " 766.9983,\n",
       " 768.0182,\n",
       " 763.4722,\n",
       " 761.8109,\n",
       " 822.41724,\n",
       " 704.7947,\n",
       " 703.39484,\n",
       " 682.4281,\n",
       " 843.2474,\n",
       " 723.663,\n",
       " 805.33295,\n",
       " 704.3471,\n",
       " 718.0869,\n",
       " 782.4577,\n",
       " 666.47577,\n",
       " 687.1772,\n",
       " 791.29816,\n",
       " 707.41473,\n",
       " 792.6206,\n",
       " 681.5747,\n",
       " 788.4116,\n",
       " 751.14,\n",
       " 778.5512,\n",
       " 765.0743,\n",
       " 719.0503,\n",
       " 698.9293,\n",
       " 667.2454,\n",
       " 716.3987,\n",
       " 728.9076,\n",
       " 819.5769,\n",
       " 682.98145,\n",
       " 733.2206,\n",
       " 750.2702,\n",
       " 686.12006,\n",
       " 794.15265,\n",
       " 661.2551,\n",
       " 824.8098,\n",
       " 719.187,\n",
       " 699.70074,\n",
       " 812.9213,\n",
       " 710.1063,\n",
       " 716.6851,\n",
       " 706.55756,\n",
       " 724.96686,\n",
       " 751.8453,\n",
       " 731.68726,\n",
       " 751.7645,\n",
       " 739.66156,\n",
       " 779.0846,\n",
       " 742.37164,\n",
       " 707.9352,\n",
       " 810.8892,\n",
       " 680.4677,\n",
       " 703.6711,\n",
       " 759.161,\n",
       " 673.75714,\n",
       " 720.92303,\n",
       " 696.8821,\n",
       " 758.26984,\n",
       " 682.6719,\n",
       " 784.25507,\n",
       " 718.64185,\n",
       " 662.1554,\n",
       " 763.07117,\n",
       " 703.9694,\n",
       " 727.91693,\n",
       " 741.5246,\n",
       " 761.66364,\n",
       " 657.6341,\n",
       " 791.37115,\n",
       " 677.66797,\n",
       " 745.0835,\n",
       " 705.17957,\n",
       " 783.96497,\n",
       " 674.2176,\n",
       " 758.8957,\n",
       " 692.8471,\n",
       " 790.01587,\n",
       " 672.35004,\n",
       " 743.2132,\n",
       " 722.4682,\n",
       " 697.43506,\n",
       " 740.64465,\n",
       " 769.0133,\n",
       " 722.83777,\n",
       " 819.9642,\n",
       " 644.57684,\n",
       " 765.4985,\n",
       " 728.0194,\n",
       " 760.75494,\n",
       " 718.69495,\n",
       " 736.1489,\n",
       " 702.5464,\n",
       " 700.8972,\n",
       " 804.83856,\n",
       " 699.88,\n",
       " 799.256,\n",
       " 689.37964,\n",
       " 869.9637,\n",
       " 662.32367,\n",
       " 685.9924,\n",
       " 759.0933,\n",
       " 691.9455,\n",
       " 736.1062,\n",
       " 698.30176,\n",
       " 805.66626,\n",
       " 699.6846,\n",
       " 733.0886,\n",
       " 670.0541,\n",
       " 746.9335,\n",
       " 834.21545,\n",
       " 659.263,\n",
       " 793.377,\n",
       " 659.69244,\n",
       " 750.8763,\n",
       " 758.7504,\n",
       " 767.04663,\n",
       " 708.877,\n",
       " 657.1605,\n",
       " 677.2921,\n",
       " 801.1946,\n",
       " 704.7999,\n",
       " 752.7214,\n",
       " 669.2463,\n",
       " 740.06433,\n",
       " 747.39215,\n",
       " 718.4791,\n",
       " 754.88873,\n",
       " 719.6564,\n",
       " 681.28345,\n",
       " 808.7453,\n",
       " 629.38806,\n",
       " 745.56805,\n",
       " 728.7737,\n",
       " 693.7716,\n",
       " 726.7903,\n",
       " 751.43,\n",
       " 696.7503,\n",
       " 795.6296,\n",
       " 755.4423,\n",
       " 703.77625,\n",
       " 800.0051]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.states_tracked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Q_value for state [0,0,0]  action (0,2)')\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.semilogy(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "plt.title('Rewards per episode')\n",
    "xaxis = np.asarray(range(0, len(rewards_per_episode)))\n",
    "plt.plot(xaxis,np.asarray(rewards_per_episode))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,5000)\n",
    "epsilon = []\n",
    "for i in range(0,5000):\n",
    "    epsilon.append(0 + (1 - 0.0001) * np.exp(-0.005*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYqElEQVR4nO3df3RU553f8fd3ZjT6/RNJgBEgsLEdvHESRyZknWadTZxgt4XuadqFxN1skhOapt5mm0167JMed+P+s/H27Gly6t2EbHLSZLv+EbfbcLLsUm/WPkm6xUbENgYMsZCxkQAjIX5JgIQ03/4xV3gQEhrQSFf33s/rHB3d+8yjme8jDx9dP/c+c83dERGR6EuFXYCIiJSGAl1EJCYU6CIiMaFAFxGJCQW6iEhMZMJ64ebmZm9vbw/r5UVEImnXrl397t4y2WOhBXp7ezudnZ1hvbyISCSZ2RtTPaYpFxGRmFCgi4jEhAJdRCQmFOgiIjGhQBcRiYlpA93Mvmdmx81szxSPm5l908y6zGy3md1R+jJFRGQ6xRyhfx9Yd5XH7wVWBV+bgT+beVkiInKtpg10d/8ZMHCVLhuAH3jeDqDBzBaXqsCJdh4a4NG/3U8up4/9FREpVIo59CXA4YL9nqDtCma22cw6zayzr6/vul7s5cOn+NPnDnJ2ePS6fl5EJK7m9KSou29x9w5372hpmXTl6rTqKssAOHP+YilLExGJvFIEei+wtGC/LWibFfVBoJ9WoIuIXKYUgb4V+J3gape1wGl3P1qC551UvY7QRUQmNe2Hc5nZ48DdQLOZ9QD/CSgDcPdvAduA+4Au4Bzw6dkqFnSELiIylWkD3d03TfO4A/+2ZBVNQ4EuIjK5yK0UVaCLiEwucoFelU2TTpkCXURkgsgFuplRX1mmQBcRmSBygQ4o0EVEJhHJQK9ToIuIXCGSgV5fWabr0EVEJohsoOsIXUTkchEN9AxnLujDuURECkU00PNH6Pk1TSIiAhEO9LGcMzQyFnYpIiLzRmQDHbRaVESkUCQDva4iCPRzCnQRkXGRDHQdoYuIXCmSgV6nQBcRuUIkA103uRARuVI0A71KR+giIhNFMtBrshlSpkAXESkUyUBPpYy6yjLOXFCgi4iMi2Sggz7PRURkIgW6iEhMRDrQT2phkYjIJZEN9MaqLKfOjYRdhojIvBHZQG+qznJySIEuIjIusoHeUFXGmQujjI7lwi5FRGReiGygN1ZlATilE6MiIkCUA706CHTNo4uIAFEO9GD5/8CQjtBFRCDSgZ4/Qj+pI3QRESDKgR5MuehKFxGRvMgGetOlI3RNuYiIQIQDvTKbpjyT0klREZFAUYFuZuvM7ICZdZnZg5M8vszMnjWzF81st5ndV/pSr9RUnWVAUy4iIkARgW5maeAx4F5gNbDJzFZP6PYfgafc/T3ARuBPS13oZBqqsppyEREJFHOEvgbocvdudx8BngA2TOjjQF2wXQ8cKV2JU2uqLtNVLiIigWICfQlwuGC/J2gr9IfA/WbWA2wDfm+yJzKzzWbWaWadfX1911Hu5fJH6Ap0EREo3UnRTcD33b0NuA/4oZld8dzuvsXdO9y9o6WlZcYv2lhVpssWRUQCxQR6L7C0YL8taCv0WeApAHf/f0AF0FyKAq+mqSrL6fMXyeV8tl9KRGTeKybQdwKrzGyFmWXJn/TcOqHPm8CHAczsHeQDfeZzKtNoqMqSc3RvURERigh0dx8FHgC2A6+Sv5plr5k9Ymbrg25/AHzOzF4GHgd+191n/bC5KVgtqksXRUQgU0wnd99G/mRnYdvDBdv7gLtKW9r0GoIP6NKliyIiEV4pCm8foevEqIhIxANdn7goIvK2aAe65tBFRC6JdKBXBx/QpUAXEYl4oJsZzTXl9A8q0EVEIh3oAM01WfoHh8MuQ0QkdJEP9AU15ZwYUqCLiEQ/0KuznNCUi4hI9AO9ubacE4MjzMHCVBGReS3ygb6gOsvIWI4zF0bDLkVEJFSRD/TmmnIATujEqIgkXGwCXZcuikjSRT7QF9TkV4vqCF1Eki42gd6v1aIiknCRD/Smqixm0H9WR+gikmyRD/RMOkVjVVaLi0Qk8SIf6JC/dLH/rKZcRCTZYhHozVr+LyISj0BfUKPl/yIisQj05ppy+nTZoogkXCwCfUF1lrMXRhkeHQu7FBGR0MQi0Jtrx5f/a9pFRJIrFoHecmn5v6ZdRCS5YhHorXX5QH/rjAJdRJIrFoG+sK4CgLfOXAi5EhGR8MQi0BdUZ0kZHFegi0iCxSLQM+kUC2rKOa7PcxGRBItFoAMsrCvXlIuIJFp8Ar22QidFRSTRYhPorXUVHD+rI3QRSa6iAt3M1pnZATPrMrMHp+jzL81sn5ntNbO/LG2Z02utLad/cISLY7m5fmkRkXkhM10HM0sDjwH3AD3ATjPb6u77CvqsAh4C7nL3k2bWOlsFT2X80sX+wWEW11fO9cuLiISumCP0NUCXu3e7+wjwBLBhQp/PAY+5+0kAdz9e2jKnt1CLi0Qk4YoJ9CXA4YL9nqCt0M3AzWb2f81sh5mtm+yJzGyzmXWaWWdfX9/1VTwFLS4SkaQr1UnRDLAKuBvYBHzHzBomdnL3Le7e4e4dLS0tJXrpvNbgA7q0uEhEkqqYQO8FlhbstwVthXqAre5+0d1fB35FPuDnzIKa8vxqUS0uEpGEKibQdwKrzGyFmWWBjcDWCX3+N/mjc8ysmfwUTHfpypxeOmW01GpxkYgk17SB7u6jwAPAduBV4Cl332tmj5jZ+qDbduCEme0DngW+4u4nZqvoqSys0+IiEUmuaS9bBHD3bcC2CW0PF2w78KXgKzStteX0nDwfZgkiIqGJzUpRgEX1FRzTlIuIJFSsAn1xfSWnzl3k3Mho2KWIiMy5WAX6kob8CtEjp3SULiLJE6tAX1yfX1x05JTm0UUkeWIV6DcER+hHTyvQRSR5YhXoi+orMINeTbmISALFKtDL0ilaa8s5qikXEUmgWAU65KddjmjKRUQSKH6BXl/JUU25iEgCxS/QGyroPXWe/OJVEZHkiGGgVzI8mmNgaCTsUkRE5lTsAn389nNHT2vaRUSSJXaBPr5atFdXuohIwsQu0Bc35FeL6tJFEUma2AX6guos5ZmUjtBFJHFiF+hmRltjpT4XXUQSJ3aBDrCsqYo3B86FXYaIyJyKb6CfOKdr0UUkUWIZ6Eubqjg7PMrp8xfDLkVEZM7EMtCXNVUBaNpFRBIlnoG+QIEuIskTy0Bf2qhAF5HkiWWgV5dnaK7JcliBLiIJEstAh/yJUR2hi0iSxDbQdS26iCRNrAP9yKkLXBzLhV2KiMiciG2gL22qYiznunuRiCRGbAN9/Fr0QyeGQq5ERGRuxDbQVzZXA/B6vwJdRJIhtoHeUltOTXmG7r7BsEsREZkTsQ10M2NlSzXdOkIXkYQoKtDNbJ2ZHTCzLjN78Cr9/rmZuZl1lK7E67eyuZruPgW6iCTDtIFuZmngMeBeYDWwycxWT9KvFvgi8Hypi7xeN7bU0HvqPOdHxsIuRURk1hVzhL4G6HL3bncfAZ4ANkzS7z8DXwfmzXWCK1tqAJ0YFZFkKCbQlwCHC/Z7grZLzOwOYKm7//XVnsjMNptZp5l19vX1XXOx12plS/5Kl4M6MSoiCTDjk6JmlgL+BPiD6fq6+xZ373D3jpaWlpm+9LRWNFdjhubRRSQRign0XmBpwX5b0DauFvg14DkzOwSsBbbOhxOjFWVpbqivpLtfR+giEn/FBPpOYJWZrTCzLLAR2Dr+oLufdvdmd29393ZgB7De3TtnpeJrtLJFV7qISDJMG+juPgo8AGwHXgWecve9ZvaIma2f7QJn6saWGrr7BnXDaBGJvUwxndx9G7BtQtvDU/S9e+Zllc6qhTUMjYzRe+o8bcGdjERE4ii2K0XH3bqoFoADx86GXImIyOyKfaDfvDAf6PsV6CISc7EP9NqKMpY0VOoIXURiL/aBDvlpl/3HzoRdhojIrEpEoN+yqJbuviFGRnU7OhGJr8QE+mjO9REAIhJriQj0WxfVAbrSRUTiLRGBvrKlmrK06UoXEYm1RAR6WTrFjS01vHpUJ0ZFJL4SEegA71xSz57e0/oIABGJrcQE+u1t9ZwYGuHo6Xlz/w0RkZJKTKC/s60BgN09p8MtRERkliQm0G9dVEsmZbzSeyrsUkREZkViAr2iLM3NC2t1hC4isZWYQIf8PLpOjIpIXCUq0N/ZVs/JcxfpOXk+7FJEREouWYG+pB7QiVERiadEBfqti+ooz6T45Zsnwy5FRKTkEhXo2UyKdy1toPPQQNiliIiUXKICHeDO9kb2HDnDuZHRsEsRESmpxAV6R3sTYznnpcOnwi5FRKSkEhfodyxrxAw6D2keXUTiJXGBXl9Zxi0La9mpeXQRiZnEBTpAR3sjL755irGcFhiJSHwkMtDvbG9icHiUPb26Hl1E4iORgf7rNzYD8Iuu/pArEREpnUQGekttObcuquUXrynQRSQ+EhnoAP9oVTO73jjJ+ZGxsEsRESmJxAb6XTc1MzKW09UuIhIbiQ30NSuayKZTmkcXkdgoKtDNbJ2ZHTCzLjN7cJLHv2Rm+8xst5n91MyWl77U0qrKZnjv8kZ+9qu+sEsRESmJaQPdzNLAY8C9wGpgk5mtntDtRaDD3W8HngYeLXWhs+HD72hl/7GzHB44F3YpIiIzVswR+hqgy9273X0EeALYUNjB3Z919/FU3AG0lbbM2fGRdywE4Jl9b4VciYjIzBUT6EuAwwX7PUHbVD4L/M1kD5jZZjPrNLPOvr7wpzram6tZ1VqjQBeRWCjpSVEzux/oAP54ssfdfYu7d7h7R0tLSylf+rrds3ohLxwa4PS5i2GXIiIyI8UEei+wtGC/LWi7jJl9BPgqsN7dh0tT3uy7Z/VCxnLOsweOh12KiMiMFBPoO4FVZrbCzLLARmBrYQczew/wbfJhHqlkfFdbA4vqKvjJ7iNhlyIiMiPTBrq7jwIPANuBV4Gn3H2vmT1iZuuDbn8M1AA/MrOXzGzrFE8376RSxvp338BzB/o4OTQSdjkiItctU0wnd98GbJvQ9nDB9kdKXNecWv+uG9jys2627TnKJ9837y+hFxGZVGJXiha67YY6bmqt4ccvatpFRKJLgQ6YGf/s3TfwwqEBLTISkchSoAd+6442UgZP7jw8fWcRkXlIgR5Y0lDJh25p5Ymdh7k4lgu7HBGRa6ZAL3D/2uX0Dw5r5aiIRJICvcAHb25hSUMlf7HjjbBLERG5Zgr0AumUcf/a5fzDwRPsPaIbSItItCjQJ/jE+5ZRU57hz547GHYpIiLXRIE+QX1lGfevXc62V47yev9Q2OWIiBRNgT6Jz3ygnUw6xbd0lC4iEaJAn0RrbQWfWLOMp3/ZQ9fxs2GXIyJSFAX6FH7vN2+isizN1//2QNiliIgURYE+hQU15Xz+N1byzL63eOH1gbDLERGZlgL9Kj77gZUsrq/g4R/v0epREZn3FOhXUZlN87X1t7H/2Fm+8/PusMsREbkqBfo0PnrbItbdtohv/N1rdPcNhl2OiMiUFOhF+NqG26goS/PvnniR4dGxsMsREZmUAr0IC+sqePTjt7On9wyP6qoXEZmnFOhF+thti/jdX2/nu794nR+/1Bt2OSIiV1CgX4OH7ruVNSua+MrTu+k8pEsZRWR+UaBfg/JMmm/f/16WNFTyuR90sv/YmbBLEhG5RIF+jRqrs3z/03dSnknzie88r1AXkXlDgX4dli+o5vHNa8mmU2zcskMrSUVkXlCgX6cVzdU8+a/X0lSV5ZN/voOnd/WEXZKIJJwCfQaWL6jmr75wF3e2N/HlH73MV370MoPDo2GXJSIJpUCfofqqMv77Z9bwwIdu4ulf9vCPv/lzfv5aX9hliUgCKdBLoCyd4ssfu4UnN78fgH/13Rf4/A938cYJ3fFIROaOAr2E1qxoYvvvf5Avf/RmnvvVcT70X57j3z/5Eq+9pZtkiMjsM3cP5YU7Ojq8s7MzlNeeC8fPXOA7P+/mL3a8yfmLY7xvRROb1ixj3a8toqIsHXZ5IhJRZrbL3TsmfUyBPrsGhkZ4/IU3eXLnYd4cOEdVNs1v3NzCPasXcvctrTRVZ8MuUUQiRIE+D+Ryzo7uE/z1K0d5Zt9bHD87DMCq1hruXNFEx/JGVt9Qx8rmGrIZzYSJyORmHOhmtg74BpAG/tzd/2jC4+XAD4D3AieA33b3Q1d7zqQFeqFcztnde5p/ONjPC68PsOvQSc4GlzuWpY0bW2q4qbWGpU1VLG2sYmlTJW2NVbTWllOVTWNmIY9ARMIyo0A3szTwK+AeoAfYCWxy930Ffb4A3O7unzezjcBvuftvX+15kxzoE43lnK7jg+w/dob9x86y/+gZDvYNceTUeUZzl//3Kc+kaK4pZ0FNlqbqLI1VWarL01SXZ6jJZvLfy/Pfq7JpspkU2UyKsnSKbDq/fel7JkVZ2sikUqRSkDIjbYYZ+qMhMk9dLdAzRfz8GqDL3buDJ3sC2ADsK+izAfjDYPtp4L+ZmXlY8zkRk04Ztyyq5ZZFtWwoaB/LOcfOXKBn4Bw9J8/TPzjMiaER+geHGRga4cTgCAf7BhkaHmNweJSR0dLd9zRl+YBPpYyUQdrs8v2UYZbfHmfkd8b/FhT+SZj4B+JSnyJ+vvBnbcLGZH1E5rsvfngV//RdN5T8eYsJ9CXA4YL9HuB9U/Vx91EzOw0sAPoLO5nZZmAzwLJly66z5ORIp4wlDZUsaai84hc+mZHRHEPDowwOjzI0Msq5kTEujuYYGctxcSzHyGiO4dEcF8eckdG320ZzTs6dXM7JOYy54+6MBfvjj+XbCdrzX+N/si99xyfsv21in8IH/VIfn7A/fR902CARU19ZNivPW0ygl4y7bwG2QH7KZS5fOwny0yhZGnXljEgiFXM5RS+wtGC/LWibtI+ZZYB68idHRURkjhQT6DuBVWa2wsyywEZg64Q+W4FPBdsfB/5e8+ciInNr2imXYE78AWA7+csWv+fue83sEaDT3bcC3wV+aGZdwAD50BcRkTlU1By6u28Dtk1oe7hg+wLwL0pbmoiIXAstSRQRiQkFuohITCjQRURiQoEuIhIToX3aopn1AW9c5483M2EVagJozMmgMSfDTMa83N1bJnsgtECfCTPrnOrDaeJKY04GjTkZZmvMmnIREYkJBbqISExENdC3hF1ACDTmZNCYk2FWxhzJOXQREblSVI/QRURkAgW6iEhMRC7QzWydmR0wsy4zezDsembCzL5nZsfNbE9BW5OZPWNmrwXfG4N2M7NvBuPebWZ3FPzMp4L+r5nZpyZ7rfnAzJaa2bNmts/M9prZF4P2OI+5wsxeMLOXgzF/LWhfYWbPB2N7MvhoasysPNjvCh5vL3iuh4L2A2b2sZCGVDQzS5vZi2b2k2A/1mM2s0Nm9oqZvWRmnUHb3L63PbjdWBS+yH9870FgJZAFXgZWh13XDMbzQeAOYE9B26PAg8H2g8DXg+37gL8hfxvNtcDzQXsT0B18bwy2G8Me2xTjXQzcEWzXkr/5+OqYj9mAmmC7DHg+GMtTwMag/VvAvwm2vwB8K9jeCDwZbK8O3u/lwIrg30E67PFNM/YvAX8J/CTYj/WYgUNA84S2OX1vh/5LuMZf2PuB7QX7DwEPhV3XDMfUPiHQDwCLg+3FwIFg+9vApon9gE3AtwvaL+s3n7+AHwP3JGXMQBXwS/L35O0HMkH7pfc1+fsOvD/YzgT9bOJ7vbDffPwif2eznwK/CfwkGEPcxzxZoM/peztqUy6T3bB6SUi1zJaF7n402D4GLAy2pxp7JH8nwf9Wv4f8EWusxxxMPbwEHAeeIX+kecrdR4MuhfVfdsN1YPyG65EaM/Bfgf8A5IL9BcR/zA78HzPbZWabg7Y5fW/P6U2i5dq4u5tZ7K4rNbMa4H8Cv+/uZ8zs0mNxHLO7jwHvNrMG4K+AW8OtaHaZ2T8Bjrv7LjO7O+Ry5tIH3L3XzFqBZ8xsf+GDc/HejtoRejE3rI66t8xsMUDw/XjQPtXYI/U7MbMy8mH+P9z9fwXNsR7zOHc/BTxLfrqhwfI3VIfL65/qhutRGvNdwHozOwQ8QX7a5RvEe8y4e2/w/Tj5P9xrmOP3dtQCvZgbVkdd4Q23P0V+nnm8/XeCs+NrgdPB/8ptBz5qZo3BGfSPBm3zjuUPxb8LvOruf1LwUJzH3BIcmWNmleTPGbxKPtg/HnSbOObJbri+FdgYXBGyAlgFvDAng7hG7v6Qu7e5ezv5f6N/7+6fJMZjNrNqM6sd3yb/ntzDXL+3wz6RcB0nHu4jf3XEQeCrYdczw7E8DhwFLpKfK/ss+bnDnwKvAX8HNAV9DXgsGPcrQEfB83wG6Aq+Ph32uK4y3g+Qn2fcDbwUfN0X8zHfDrwYjHkP8HDQvpJ8OHUBPwLKg/aKYL8reHxlwXN9NfhdHADuDXtsRY7/bt6+yiW2Yw7G9nLwtXc8m+b6va2l/yIiMRG1KRcREZmCAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhP/H4Sf7qs0zktKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
